{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3213b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========== SPLIT 1 ==========\n",
      "Epoch 01 | Test Acc: 0.0556\n",
      "Epoch 02 | Test Acc: 0.1742\n",
      "Epoch 03 | Test Acc: 0.3444\n",
      "Epoch 04 | Test Acc: 0.5129\n",
      "Epoch 05 | Test Acc: 0.5702\n",
      "Epoch 06 | Test Acc: 0.6210\n",
      "Epoch 07 | Test Acc: 0.6685\n",
      "Epoch 08 | Test Acc: 0.6887\n",
      "Epoch 09 | Test Acc: 0.7024\n",
      "Epoch 10 | Test Acc: 0.7306\n",
      "Epoch 11 | Test Acc: 0.7202\n",
      "Epoch 12 | Test Acc: 0.7194\n",
      "Epoch 13 | Test Acc: 0.7194\n",
      "Epoch 14 | Test Acc: 0.7516\n",
      "Epoch 15 | Test Acc: 0.7315\n",
      "Epoch 16 | Test Acc: 0.7371\n",
      "Epoch 17 | Test Acc: 0.7484\n",
      "Epoch 18 | Test Acc: 0.7048\n",
      "Epoch 19 | Test Acc: 0.7315\n",
      "Epoch 20 | Test Acc: 0.7153\n",
      "Epoch 21 | Test Acc: 0.7444\n",
      "Epoch 22 | Test Acc: 0.7435\n",
      "Epoch 23 | Test Acc: 0.7032\n",
      "Epoch 24 | Test Acc: 0.7548\n",
      "Epoch 25 | Test Acc: 0.7298\n",
      "Epoch 26 | Test Acc: 0.7548\n",
      "Epoch 27 | Test Acc: 0.7540\n",
      "Epoch 28 | Test Acc: 0.7500\n",
      "Epoch 29 | Test Acc: 0.7637\n",
      "Epoch 30 | Test Acc: 0.7435\n",
      "Epoch 31 | Test Acc: 0.7516\n",
      "Epoch 32 | Test Acc: 0.7484\n",
      "Epoch 33 | Test Acc: 0.7435\n",
      "Epoch 34 | Test Acc: 0.7282\n",
      "Epoch 35 | Test Acc: 0.7605\n",
      "Epoch 36 | Test Acc: 0.7524\n",
      "Epoch 37 | Test Acc: 0.7597\n",
      "Epoch 38 | Test Acc: 0.7339\n",
      "Epoch 39 | Test Acc: 0.7605\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.7637\n",
      "\n",
      "========== SPLIT 2 ==========\n",
      "Epoch 01 | Test Acc: 0.0476\n",
      "Epoch 02 | Test Acc: 0.1605\n",
      "Epoch 03 | Test Acc: 0.3750\n",
      "Epoch 04 | Test Acc: 0.5339\n",
      "Epoch 05 | Test Acc: 0.6185\n",
      "Epoch 06 | Test Acc: 0.6895\n",
      "Epoch 07 | Test Acc: 0.7185\n",
      "Epoch 08 | Test Acc: 0.7661\n",
      "Epoch 09 | Test Acc: 0.7742\n",
      "Epoch 10 | Test Acc: 0.7782\n",
      "Epoch 11 | Test Acc: 0.8000\n",
      "Epoch 12 | Test Acc: 0.8185\n",
      "Epoch 13 | Test Acc: 0.8000\n",
      "Epoch 14 | Test Acc: 0.8024\n",
      "Epoch 15 | Test Acc: 0.8016\n",
      "Epoch 16 | Test Acc: 0.8145\n",
      "Epoch 17 | Test Acc: 0.8089\n",
      "Epoch 18 | Test Acc: 0.8347\n",
      "Epoch 19 | Test Acc: 0.8347\n",
      "Epoch 20 | Test Acc: 0.8290\n",
      "Epoch 21 | Test Acc: 0.8315\n",
      "Epoch 22 | Test Acc: 0.8403\n",
      "Epoch 23 | Test Acc: 0.8185\n",
      "Epoch 24 | Test Acc: 0.8290\n",
      "Epoch 25 | Test Acc: 0.8484\n",
      "Epoch 26 | Test Acc: 0.8395\n",
      "Epoch 27 | Test Acc: 0.8524\n",
      "Epoch 28 | Test Acc: 0.8306\n",
      "Epoch 29 | Test Acc: 0.8105\n",
      "Epoch 30 | Test Acc: 0.8468\n",
      "Epoch 31 | Test Acc: 0.8621\n",
      "Epoch 32 | Test Acc: 0.8097\n",
      "Epoch 33 | Test Acc: 0.8532\n",
      "Epoch 34 | Test Acc: 0.8718\n",
      "Epoch 35 | Test Acc: 0.8718\n",
      "Epoch 36 | Test Acc: 0.8452\n",
      "Epoch 37 | Test Acc: 0.8315\n",
      "Epoch 38 | Test Acc: 0.8129\n",
      "Epoch 39 | Test Acc: 0.8355\n",
      "Epoch 40 | Test Acc: 0.8532\n",
      "Epoch 41 | Test Acc: 0.8274\n",
      "Epoch 42 | Test Acc: 0.8444\n",
      "Epoch 43 | Test Acc: 0.8581\n",
      "Epoch 44 | Test Acc: 0.8605\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8718\n",
      "\n",
      "========== SPLIT 3 ==========\n",
      "Epoch 01 | Test Acc: 0.0565\n",
      "Epoch 02 | Test Acc: 0.1927\n",
      "Epoch 03 | Test Acc: 0.4137\n",
      "Epoch 04 | Test Acc: 0.5290\n",
      "Epoch 05 | Test Acc: 0.6161\n",
      "Epoch 06 | Test Acc: 0.6556\n",
      "Epoch 07 | Test Acc: 0.7105\n",
      "Epoch 08 | Test Acc: 0.7347\n",
      "Epoch 09 | Test Acc: 0.7452\n",
      "Epoch 10 | Test Acc: 0.7831\n",
      "Epoch 11 | Test Acc: 0.8097\n",
      "Epoch 12 | Test Acc: 0.7798\n",
      "Epoch 13 | Test Acc: 0.7419\n",
      "Epoch 14 | Test Acc: 0.7782\n",
      "Epoch 15 | Test Acc: 0.8121\n",
      "Epoch 16 | Test Acc: 0.8113\n",
      "Epoch 17 | Test Acc: 0.8113\n",
      "Epoch 18 | Test Acc: 0.8315\n",
      "Epoch 19 | Test Acc: 0.8323\n",
      "Epoch 20 | Test Acc: 0.8387\n",
      "Epoch 21 | Test Acc: 0.8315\n",
      "Epoch 22 | Test Acc: 0.8089\n",
      "Epoch 23 | Test Acc: 0.8250\n",
      "Epoch 24 | Test Acc: 0.8427\n",
      "Epoch 25 | Test Acc: 0.8452\n",
      "Epoch 26 | Test Acc: 0.8387\n",
      "Epoch 27 | Test Acc: 0.7815\n",
      "Epoch 28 | Test Acc: 0.8484\n",
      "Epoch 29 | Test Acc: 0.8339\n",
      "Epoch 30 | Test Acc: 0.8315\n",
      "Epoch 31 | Test Acc: 0.8274\n",
      "Epoch 32 | Test Acc: 0.8468\n",
      "Epoch 33 | Test Acc: 0.8573\n",
      "Epoch 34 | Test Acc: 0.8532\n",
      "Epoch 35 | Test Acc: 0.8492\n",
      "Epoch 36 | Test Acc: 0.7984\n",
      "Epoch 37 | Test Acc: 0.8097\n",
      "Epoch 38 | Test Acc: 0.8419\n",
      "Epoch 39 | Test Acc: 0.8524\n",
      "Epoch 40 | Test Acc: 0.8468\n",
      "Epoch 41 | Test Acc: 0.8573\n",
      "Epoch 42 | Test Acc: 0.8395\n",
      "Epoch 43 | Test Acc: 0.8468\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8573\n",
      "\n",
      "========== SPLIT 4 ==========\n",
      "Epoch 01 | Test Acc: 0.0419\n",
      "Epoch 02 | Test Acc: 0.1605\n",
      "Epoch 03 | Test Acc: 0.3129\n",
      "Epoch 04 | Test Acc: 0.4444\n",
      "Epoch 05 | Test Acc: 0.5798\n",
      "Epoch 06 | Test Acc: 0.6613\n",
      "Epoch 07 | Test Acc: 0.7145\n",
      "Epoch 08 | Test Acc: 0.7395\n",
      "Epoch 09 | Test Acc: 0.7613\n",
      "Epoch 10 | Test Acc: 0.7839\n",
      "Epoch 11 | Test Acc: 0.7815\n",
      "Epoch 12 | Test Acc: 0.7984\n",
      "Epoch 13 | Test Acc: 0.7992\n",
      "Epoch 14 | Test Acc: 0.8226\n",
      "Epoch 15 | Test Acc: 0.8145\n",
      "Epoch 16 | Test Acc: 0.8306\n",
      "Epoch 17 | Test Acc: 0.8347\n",
      "Epoch 18 | Test Acc: 0.8298\n",
      "Epoch 19 | Test Acc: 0.8298\n",
      "Epoch 20 | Test Acc: 0.8339\n",
      "Epoch 21 | Test Acc: 0.8306\n",
      "Epoch 22 | Test Acc: 0.8371\n",
      "Epoch 23 | Test Acc: 0.8556\n",
      "Epoch 24 | Test Acc: 0.8008\n",
      "Epoch 25 | Test Acc: 0.8508\n",
      "Epoch 26 | Test Acc: 0.8476\n",
      "Epoch 27 | Test Acc: 0.8323\n",
      "Epoch 28 | Test Acc: 0.8444\n",
      "Epoch 29 | Test Acc: 0.7798\n",
      "Epoch 30 | Test Acc: 0.8492\n",
      "Epoch 31 | Test Acc: 0.8661\n",
      "Epoch 32 | Test Acc: 0.8621\n",
      "Epoch 33 | Test Acc: 0.8710\n",
      "Epoch 34 | Test Acc: 0.8750\n",
      "Epoch 35 | Test Acc: 0.8734\n",
      "Epoch 36 | Test Acc: 0.8621\n",
      "Epoch 37 | Test Acc: 0.8718\n",
      "Epoch 38 | Test Acc: 0.8242\n",
      "Epoch 39 | Test Acc: 0.8613\n",
      "Epoch 40 | Test Acc: 0.8629\n",
      "Epoch 41 | Test Acc: 0.8621\n",
      "Epoch 42 | Test Acc: 0.8492\n",
      "Epoch 43 | Test Acc: 0.8556\n",
      "Epoch 44 | Test Acc: 0.8694\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8750\n",
      "\n",
      "========== SPLIT 5 ==========\n",
      "Epoch 01 | Test Acc: 0.0452\n",
      "Epoch 02 | Test Acc: 0.2347\n",
      "Epoch 03 | Test Acc: 0.3919\n",
      "Epoch 04 | Test Acc: 0.5508\n",
      "Epoch 05 | Test Acc: 0.6323\n",
      "Epoch 06 | Test Acc: 0.6798\n",
      "Epoch 07 | Test Acc: 0.7024\n",
      "Epoch 08 | Test Acc: 0.7500\n",
      "Epoch 09 | Test Acc: 0.7597\n",
      "Epoch 10 | Test Acc: 0.7847\n",
      "Epoch 11 | Test Acc: 0.7960\n",
      "Epoch 12 | Test Acc: 0.8000\n",
      "Epoch 13 | Test Acc: 0.7968\n",
      "Epoch 14 | Test Acc: 0.8016\n",
      "Epoch 15 | Test Acc: 0.8274\n",
      "Epoch 16 | Test Acc: 0.7976\n",
      "Epoch 17 | Test Acc: 0.8298\n",
      "Epoch 18 | Test Acc: 0.8323\n",
      "Epoch 19 | Test Acc: 0.8460\n",
      "Epoch 20 | Test Acc: 0.8339\n",
      "Epoch 21 | Test Acc: 0.8323\n",
      "Epoch 22 | Test Acc: 0.8387\n",
      "Epoch 23 | Test Acc: 0.8347\n",
      "Epoch 24 | Test Acc: 0.8435\n",
      "Epoch 25 | Test Acc: 0.8524\n",
      "Epoch 26 | Test Acc: 0.8460\n",
      "Epoch 27 | Test Acc: 0.8468\n",
      "Epoch 28 | Test Acc: 0.8500\n",
      "Epoch 29 | Test Acc: 0.8202\n",
      "Epoch 30 | Test Acc: 0.8419\n",
      "Epoch 31 | Test Acc: 0.8476\n",
      "Epoch 32 | Test Acc: 0.8645\n",
      "Epoch 33 | Test Acc: 0.8613\n",
      "Epoch 34 | Test Acc: 0.8226\n",
      "Epoch 35 | Test Acc: 0.8379\n",
      "Epoch 36 | Test Acc: 0.8581\n",
      "Epoch 37 | Test Acc: 0.8565\n",
      "Epoch 38 | Test Acc: 0.8677\n",
      "Epoch 39 | Test Acc: 0.8750\n",
      "Epoch 40 | Test Acc: 0.8524\n",
      "Epoch 41 | Test Acc: 0.8565\n",
      "Epoch 42 | Test Acc: 0.8637\n",
      "Epoch 43 | Test Acc: 0.8516\n",
      "Epoch 44 | Test Acc: 0.8419\n",
      "Epoch 45 | Test Acc: 0.8452\n",
      "Epoch 46 | Test Acc: 0.8323\n",
      "Epoch 47 | Test Acc: 0.8597\n",
      "Epoch 48 | Test Acc: 0.8581\n",
      "Epoch 49 | Test Acc: 0.8637\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8750\n",
      "\n",
      "========== SPLIT 6 ==========\n",
      "Epoch 01 | Test Acc: 0.0508\n",
      "Epoch 02 | Test Acc: 0.0863\n",
      "Epoch 03 | Test Acc: 0.2944\n",
      "Epoch 04 | Test Acc: 0.4339\n",
      "Epoch 05 | Test Acc: 0.5508\n",
      "Epoch 06 | Test Acc: 0.5984\n",
      "Epoch 07 | Test Acc: 0.6653\n",
      "Epoch 08 | Test Acc: 0.7056\n",
      "Epoch 09 | Test Acc: 0.7331\n",
      "Epoch 10 | Test Acc: 0.7677\n",
      "Epoch 11 | Test Acc: 0.7774\n",
      "Epoch 12 | Test Acc: 0.7927\n",
      "Epoch 13 | Test Acc: 0.8194\n",
      "Epoch 14 | Test Acc: 0.8129\n",
      "Epoch 15 | Test Acc: 0.8290\n",
      "Epoch 16 | Test Acc: 0.8210\n",
      "Epoch 17 | Test Acc: 0.8468\n",
      "Epoch 18 | Test Acc: 0.8129\n",
      "Epoch 19 | Test Acc: 0.8315\n",
      "Epoch 20 | Test Acc: 0.8565\n",
      "Epoch 21 | Test Acc: 0.8218\n",
      "Epoch 22 | Test Acc: 0.8589\n",
      "Epoch 23 | Test Acc: 0.8331\n",
      "Epoch 24 | Test Acc: 0.8492\n",
      "Epoch 25 | Test Acc: 0.8589\n",
      "Epoch 26 | Test Acc: 0.8508\n",
      "Epoch 27 | Test Acc: 0.8548\n",
      "Epoch 28 | Test Acc: 0.8177\n",
      "Epoch 29 | Test Acc: 0.8403\n",
      "Epoch 30 | Test Acc: 0.8597\n",
      "Epoch 31 | Test Acc: 0.8597\n",
      "Epoch 32 | Test Acc: 0.8605\n",
      "Epoch 33 | Test Acc: 0.8185\n",
      "Epoch 34 | Test Acc: 0.8435\n",
      "Epoch 35 | Test Acc: 0.8548\n",
      "Epoch 36 | Test Acc: 0.8581\n",
      "Epoch 37 | Test Acc: 0.8161\n",
      "Epoch 38 | Test Acc: 0.8532\n",
      "Epoch 39 | Test Acc: 0.8476\n",
      "Epoch 40 | Test Acc: 0.8669\n",
      "Epoch 41 | Test Acc: 0.8702\n",
      "Epoch 42 | Test Acc: 0.8661\n",
      "Epoch 43 | Test Acc: 0.8629\n",
      "Epoch 44 | Test Acc: 0.8452\n",
      "Epoch 45 | Test Acc: 0.8444\n",
      "Epoch 46 | Test Acc: 0.8581\n",
      "Epoch 47 | Test Acc: 0.8605\n",
      "Epoch 48 | Test Acc: 0.8653\n",
      "Epoch 49 | Test Acc: 0.8589\n",
      "Epoch 50 | Test Acc: 0.8653\n",
      "Best Split Accuracy: 0.8702\n",
      "\n",
      "========== SPLIT 7 ==========\n",
      "Epoch 01 | Test Acc: 0.0492\n",
      "Epoch 02 | Test Acc: 0.2129\n",
      "Epoch 03 | Test Acc: 0.3774\n",
      "Epoch 04 | Test Acc: 0.5339\n",
      "Epoch 05 | Test Acc: 0.6242\n",
      "Epoch 06 | Test Acc: 0.6605\n",
      "Epoch 07 | Test Acc: 0.7250\n",
      "Epoch 08 | Test Acc: 0.7444\n",
      "Epoch 09 | Test Acc: 0.7452\n",
      "Epoch 10 | Test Acc: 0.7726\n",
      "Epoch 11 | Test Acc: 0.7911\n",
      "Epoch 12 | Test Acc: 0.7919\n",
      "Epoch 13 | Test Acc: 0.7952\n",
      "Epoch 14 | Test Acc: 0.8242\n",
      "Epoch 15 | Test Acc: 0.8016\n",
      "Epoch 16 | Test Acc: 0.8016\n",
      "Epoch 17 | Test Acc: 0.8371\n",
      "Epoch 18 | Test Acc: 0.8395\n",
      "Epoch 19 | Test Acc: 0.8524\n",
      "Epoch 20 | Test Acc: 0.8435\n",
      "Epoch 21 | Test Acc: 0.8677\n",
      "Epoch 22 | Test Acc: 0.8605\n",
      "Epoch 23 | Test Acc: 0.8468\n",
      "Epoch 24 | Test Acc: 0.8460\n",
      "Epoch 25 | Test Acc: 0.8581\n",
      "Epoch 26 | Test Acc: 0.8460\n",
      "Epoch 27 | Test Acc: 0.8710\n",
      "Epoch 28 | Test Acc: 0.8589\n",
      "Epoch 29 | Test Acc: 0.8532\n",
      "Epoch 30 | Test Acc: 0.8661\n",
      "Epoch 31 | Test Acc: 0.8516\n",
      "Epoch 32 | Test Acc: 0.8516\n",
      "Epoch 33 | Test Acc: 0.8565\n",
      "Epoch 34 | Test Acc: 0.8677\n",
      "Epoch 35 | Test Acc: 0.8605\n",
      "Epoch 36 | Test Acc: 0.8774\n",
      "Epoch 37 | Test Acc: 0.8492\n",
      "Epoch 38 | Test Acc: 0.8589\n",
      "Epoch 39 | Test Acc: 0.8677\n",
      "Epoch 40 | Test Acc: 0.8758\n",
      "Epoch 41 | Test Acc: 0.8645\n",
      "Epoch 42 | Test Acc: 0.8742\n",
      "Epoch 43 | Test Acc: 0.8702\n",
      "Epoch 44 | Test Acc: 0.8798\n",
      "Epoch 45 | Test Acc: 0.8750\n",
      "Epoch 46 | Test Acc: 0.8145\n",
      "Epoch 47 | Test Acc: 0.8008\n",
      "Epoch 48 | Test Acc: 0.8476\n",
      "Epoch 49 | Test Acc: 0.8669\n",
      "Epoch 50 | Test Acc: 0.8798\n",
      "Best Split Accuracy: 0.8798\n",
      "\n",
      "========== SPLIT 8 ==========\n",
      "Epoch 01 | Test Acc: 0.0621\n",
      "Epoch 02 | Test Acc: 0.2226\n",
      "Epoch 03 | Test Acc: 0.4153\n",
      "Epoch 04 | Test Acc: 0.5726\n",
      "Epoch 05 | Test Acc: 0.6661\n",
      "Epoch 06 | Test Acc: 0.7137\n",
      "Epoch 07 | Test Acc: 0.7210\n",
      "Epoch 08 | Test Acc: 0.7492\n",
      "Epoch 09 | Test Acc: 0.7573\n",
      "Epoch 10 | Test Acc: 0.7669\n",
      "Epoch 11 | Test Acc: 0.7766\n",
      "Epoch 12 | Test Acc: 0.7782\n",
      "Epoch 13 | Test Acc: 0.7831\n",
      "Epoch 14 | Test Acc: 0.7871\n",
      "Epoch 15 | Test Acc: 0.8218\n",
      "Epoch 16 | Test Acc: 0.8097\n",
      "Epoch 17 | Test Acc: 0.7927\n",
      "Epoch 18 | Test Acc: 0.8169\n",
      "Epoch 19 | Test Acc: 0.8242\n",
      "Epoch 20 | Test Acc: 0.8395\n",
      "Epoch 21 | Test Acc: 0.8129\n",
      "Epoch 22 | Test Acc: 0.8274\n",
      "Epoch 23 | Test Acc: 0.8419\n",
      "Epoch 24 | Test Acc: 0.8524\n",
      "Epoch 25 | Test Acc: 0.8339\n",
      "Epoch 26 | Test Acc: 0.8210\n",
      "Epoch 27 | Test Acc: 0.8532\n",
      "Epoch 28 | Test Acc: 0.8508\n",
      "Epoch 29 | Test Acc: 0.8605\n",
      "Epoch 30 | Test Acc: 0.8508\n",
      "Epoch 31 | Test Acc: 0.8411\n",
      "Epoch 32 | Test Acc: 0.8387\n",
      "Epoch 33 | Test Acc: 0.8508\n",
      "Epoch 34 | Test Acc: 0.8298\n",
      "Epoch 35 | Test Acc: 0.8298\n",
      "Epoch 36 | Test Acc: 0.8266\n",
      "Epoch 37 | Test Acc: 0.8484\n",
      "Epoch 38 | Test Acc: 0.8581\n",
      "Epoch 39 | Test Acc: 0.8532\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8605\n",
      "\n",
      "========== SPLIT 9 ==========\n",
      "Epoch 01 | Test Acc: 0.0548\n",
      "Epoch 02 | Test Acc: 0.2024\n",
      "Epoch 03 | Test Acc: 0.3903\n",
      "Epoch 04 | Test Acc: 0.5129\n",
      "Epoch 05 | Test Acc: 0.6290\n",
      "Epoch 06 | Test Acc: 0.6968\n",
      "Epoch 07 | Test Acc: 0.7161\n",
      "Epoch 08 | Test Acc: 0.7589\n",
      "Epoch 09 | Test Acc: 0.7895\n",
      "Epoch 10 | Test Acc: 0.7911\n",
      "Epoch 11 | Test Acc: 0.8016\n",
      "Epoch 12 | Test Acc: 0.7847\n",
      "Epoch 13 | Test Acc: 0.7895\n",
      "Epoch 14 | Test Acc: 0.8202\n",
      "Epoch 15 | Test Acc: 0.8339\n",
      "Epoch 16 | Test Acc: 0.8194\n",
      "Epoch 17 | Test Acc: 0.8500\n",
      "Epoch 18 | Test Acc: 0.8468\n",
      "Epoch 19 | Test Acc: 0.8532\n",
      "Epoch 20 | Test Acc: 0.8177\n",
      "Epoch 21 | Test Acc: 0.8379\n",
      "Epoch 22 | Test Acc: 0.8347\n",
      "Epoch 23 | Test Acc: 0.8363\n",
      "Epoch 24 | Test Acc: 0.8339\n",
      "Epoch 25 | Test Acc: 0.8274\n",
      "Epoch 26 | Test Acc: 0.8371\n",
      "Epoch 27 | Test Acc: 0.8403\n",
      "Epoch 28 | Test Acc: 0.8484\n",
      "Epoch 29 | Test Acc: 0.8145\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8532\n",
      "\n",
      "========== SPLIT 10 ==========\n",
      "Epoch 01 | Test Acc: 0.0516\n",
      "Epoch 02 | Test Acc: 0.1992\n",
      "Epoch 03 | Test Acc: 0.3379\n",
      "Epoch 04 | Test Acc: 0.4855\n",
      "Epoch 05 | Test Acc: 0.5702\n",
      "Epoch 06 | Test Acc: 0.6202\n",
      "Epoch 07 | Test Acc: 0.6855\n",
      "Epoch 08 | Test Acc: 0.7089\n",
      "Epoch 09 | Test Acc: 0.7242\n",
      "Epoch 10 | Test Acc: 0.7637\n",
      "Epoch 11 | Test Acc: 0.7605\n",
      "Epoch 12 | Test Acc: 0.7565\n",
      "Epoch 13 | Test Acc: 0.7710\n",
      "Epoch 14 | Test Acc: 0.7895\n",
      "Epoch 15 | Test Acc: 0.7758\n",
      "Epoch 16 | Test Acc: 0.8097\n",
      "Epoch 17 | Test Acc: 0.8129\n",
      "Epoch 18 | Test Acc: 0.7984\n",
      "Epoch 19 | Test Acc: 0.8048\n",
      "Epoch 20 | Test Acc: 0.8266\n",
      "Epoch 21 | Test Acc: 0.8056\n",
      "Epoch 22 | Test Acc: 0.8073\n",
      "Epoch 23 | Test Acc: 0.8202\n",
      "Epoch 24 | Test Acc: 0.8234\n",
      "Epoch 25 | Test Acc: 0.8218\n",
      "Epoch 26 | Test Acc: 0.8169\n",
      "Epoch 27 | Test Acc: 0.8290\n",
      "Epoch 28 | Test Acc: 0.8250\n",
      "Epoch 29 | Test Acc: 0.8387\n",
      "Epoch 30 | Test Acc: 0.8363\n",
      "Epoch 31 | Test Acc: 0.8290\n",
      "Epoch 32 | Test Acc: 0.8065\n",
      "Epoch 33 | Test Acc: 0.7758\n",
      "Epoch 34 | Test Acc: 0.8234\n",
      "Epoch 35 | Test Acc: 0.8298\n",
      "Epoch 36 | Test Acc: 0.8218\n",
      "Epoch 37 | Test Acc: 0.8169\n",
      "Epoch 38 | Test Acc: 0.8226\n",
      "Epoch 39 | Test Acc: 0.8129\n",
      "Early stopping triggered\n",
      "Best Split Accuracy: 0.8387\n",
      "FINAL RESULT \n",
      "Average Accuracy (Margin + CE): 0.854516129032258\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        self.X = np.load(x_path)\n",
    "        self.y = np.argmax(np.load(y_path), axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "# ---------------- CNN Encoder ----------------\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(256, emb_dim)  # map CNN output to embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, channels, seq_len)\n",
    "        x = self.net(x).squeeze(-1)  # (B, 256)\n",
    "        z = F.normalize(self.fc(x), dim=1)\n",
    "        return z\n",
    "\n",
    "# ---------------- Full Model ----------------\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, emb_dim=128, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder(emb_dim)\n",
    "        self.classifier = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.classifier(z)\n",
    "        return z, logits\n",
    "\n",
    "# ---------------- Margin Embedding Loss ----------------\n",
    "class MarginEmbeddingLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        dist = torch.cdist(z, z, p=2)\n",
    "        y = y.unsqueeze(1)\n",
    "        pos_mask = (y == y.T).float()\n",
    "        neg_mask = (y != y.T).float()\n",
    "        eye = torch.eye(len(z), device=z.device)\n",
    "        pos_mask = pos_mask - eye\n",
    "        pos_loss = pos_mask * dist.pow(2)\n",
    "        neg_loss = neg_mask * F.relu(self.margin - dist).pow(2)\n",
    "        loss = (pos_loss.sum() + neg_loss.sum()) / (pos_mask.sum() + neg_mask.sum() + 1e-8)\n",
    "        return loss\n",
    "\n",
    "# ---------------- Early Stopping ----------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ---------------- Training & Evaluation ----------------\n",
    "def train_and_eval(model, train_loader, test_loader, margin_loss, alpha=1.0, epochs=50, patience=10):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            z, logits = model(x)\n",
    "            loss = ce_loss(logits, y) + alpha * margin_loss(z, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, logits = model(x)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:02d} | Test Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ---------------- Main Loop ----------------\n",
    "BASE = \"models/Data/Data/62_classes/UserDependenet\"\n",
    "margin_loss = MarginEmbeddingLoss(margin=1.0)\n",
    "all_accs = []\n",
    "\n",
    "for split in range(1, 11):\n",
    "    print(f\"\\n========== SPLIT {split} ==========\")\n",
    "    train_ds = EMGDataset(f\"{BASE}/Train/X_train_{split}.npy\", f\"{BASE}/Train/y_train_{split}.npy\")\n",
    "    test_ds = EMGDataset(f\"{BASE}/Test/X_test_{split}.npy\", f\"{BASE}/Test/y_test_{split}.npy\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = FullModel(emb_dim=128).to(device)\n",
    "\n",
    "    acc = train_and_eval(model, train_loader, test_loader, margin_loss, alpha=1.0, epochs=50, patience=10)\n",
    "    print(f\"Best Split Accuracy: {acc:.4f}\")\n",
    "    all_accs.append(acc)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"FINAL RESULT \")\n",
    "print(\"Average Accuracy (Margin + CE):\", np.mean(all_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        X = np.load(x_path)\n",
    "        y = np.argmax(np.load(y_path), axis=1)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for c in range(6):\n",
    "                X[i, :, c] = (X[i, :, c] - X[i, :, c].mean()) / (X[i, :, c].std() + 1e-8)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class CNNBiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)       \n",
    "        x = self.cnn(x)               \n",
    "        x = x.permute(0, 2, 1)        \n",
    "\n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        feat = lstm_out[:, -1, :]     \n",
    "\n",
    "        z = F.normalize(self.fc(feat), dim=1)\n",
    "        return z\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, emb_dim=128, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNBiLSTMEncoder(emb_dim)\n",
    "        self.classifier = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.classifier(z)\n",
    "        return z, logits\n",
    "\n",
    "class MarginEmbeddingLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        dist = torch.cdist(z, z, p=2)\n",
    "\n",
    "        y = y.unsqueeze(1)\n",
    "        pos_mask = (y == y.T).float()\n",
    "        neg_mask = (y != y.T).float()\n",
    "\n",
    "        eye = torch.eye(len(z), device=z.device)\n",
    "        pos_mask = pos_mask - eye\n",
    "\n",
    "        pos_loss = pos_mask * dist.pow(2)\n",
    "        neg_loss = neg_mask * F.relu(self.margin - dist).pow(2)\n",
    "\n",
    "        loss = (pos_loss.sum() + neg_loss.sum()) / (pos_mask.sum() + neg_mask.sum() + 1e-8)\n",
    "        return loss\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "def train_and_eval(model, train_loader, test_loader, margin_loss,\n",
    "                   alpha=1.0, epochs=500, patience=10):\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            z, logits = model(x)\n",
    "            loss = ce_loss(logits, y) + alpha * margin_loss(z, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, logits = model(x)\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:02d} | Test Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "BASE = \"models/Data/Data/62_classes/UserDependenet\"\n",
    "margin_loss = MarginEmbeddingLoss(margin=1.0)\n",
    "all_accs = []\n",
    "\n",
    "for split in range(1, 20):\n",
    "    print(f\"\\n========== SPLIT {split} ==========\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = FullModel(emb_dim=128, num_classes=62).to(device)\n",
    "\n",
    "    acc = train_and_eval(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        margin_loss,\n",
    "        alpha=1.0,\n",
    "        epochs=500,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    print(f\"Best Split Accuracy: {acc:.4f}\")\n",
    "    all_accs.append(acc)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nFINAL RESULT\")\n",
    "print(\"Average Accuracy (CNN+BiLSTM + CE + Margin):\", np.mean(all_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (winter_gpu)",
   "language": "python",
   "name": "winter_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
