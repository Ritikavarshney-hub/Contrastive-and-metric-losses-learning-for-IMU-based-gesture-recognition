{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46422b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "===== Split 1 =====\n",
      "Epoch 01 | Val Acc: 0.1032\n",
      "Epoch 02 | Val Acc: 0.3613\n",
      "Epoch 03 | Val Acc: 0.4323\n",
      "Epoch 04 | Val Acc: 0.4919\n",
      "Epoch 05 | Val Acc: 0.5097\n",
      "Epoch 06 | Val Acc: 0.5000\n",
      "Epoch 07 | Val Acc: 0.5274\n",
      "Epoch 08 | Val Acc: 0.5823\n",
      "Epoch 09 | Val Acc: 0.5887\n",
      "Epoch 10 | Val Acc: 0.6419\n",
      "Epoch 11 | Val Acc: 0.6355\n",
      "Epoch 12 | Val Acc: 0.6419\n",
      "Epoch 13 | Val Acc: 0.5984\n",
      "Epoch 14 | Val Acc: 0.5823\n",
      "Epoch 15 | Val Acc: 0.5968\n",
      "Epoch 16 | Val Acc: 0.6113\n",
      "Epoch 17 | Val Acc: 0.6274\n",
      "Early stopping\n",
      "Best accuracy (split 1): 0.6419 \n",
      "\n",
      "===== Split 2 =====\n",
      "Epoch 01 | Val Acc: 0.1387\n",
      "Epoch 02 | Val Acc: 0.2323\n",
      "Epoch 03 | Val Acc: 0.3452\n",
      "Epoch 04 | Val Acc: 0.3452\n",
      "Epoch 05 | Val Acc: 0.3935\n",
      "Epoch 06 | Val Acc: 0.3726\n",
      "Epoch 07 | Val Acc: 0.4403\n",
      "Epoch 08 | Val Acc: 0.4065\n",
      "Epoch 09 | Val Acc: 0.4371\n",
      "Epoch 10 | Val Acc: 0.4484\n",
      "Epoch 11 | Val Acc: 0.4419\n",
      "Epoch 12 | Val Acc: 0.4097\n",
      "Epoch 13 | Val Acc: 0.4742\n",
      "Epoch 14 | Val Acc: 0.4548\n",
      "Epoch 15 | Val Acc: 0.4790\n",
      "Epoch 16 | Val Acc: 0.4774\n",
      "Epoch 17 | Val Acc: 0.4855\n",
      "Epoch 18 | Val Acc: 0.4919\n",
      "Epoch 19 | Val Acc: 0.5016\n",
      "Epoch 20 | Val Acc: 0.4903\n",
      "Epoch 21 | Val Acc: 0.4855\n",
      "Epoch 22 | Val Acc: 0.5000\n",
      "Epoch 23 | Val Acc: 0.4484\n",
      "Epoch 24 | Val Acc: 0.5081\n",
      "Epoch 25 | Val Acc: 0.5226\n",
      "Epoch 26 | Val Acc: 0.5081\n",
      "Epoch 27 | Val Acc: 0.5339\n",
      "Epoch 28 | Val Acc: 0.5274\n",
      "Epoch 29 | Val Acc: 0.5355\n",
      "Epoch 30 | Val Acc: 0.5081\n",
      "Epoch 31 | Val Acc: 0.5016\n",
      "Epoch 32 | Val Acc: 0.4597\n",
      "Epoch 33 | Val Acc: 0.5339\n",
      "Epoch 34 | Val Acc: 0.5355\n",
      "Epoch 35 | Val Acc: 0.5484\n",
      "Epoch 36 | Val Acc: 0.5081\n",
      "Epoch 37 | Val Acc: 0.5306\n",
      "Epoch 38 | Val Acc: 0.4968\n",
      "Epoch 39 | Val Acc: 0.5435\n",
      "Epoch 40 | Val Acc: 0.5242\n",
      "Epoch 41 | Val Acc: 0.5323\n",
      "Epoch 42 | Val Acc: 0.5500\n",
      "Epoch 43 | Val Acc: 0.5403\n",
      "Epoch 44 | Val Acc: 0.5129\n",
      "Epoch 45 | Val Acc: 0.4903\n",
      "Epoch 46 | Val Acc: 0.5419\n",
      "Epoch 47 | Val Acc: 0.5290\n",
      "Epoch 48 | Val Acc: 0.5210\n",
      "Epoch 49 | Val Acc: 0.5081\n",
      "Early stopping\n",
      "Best accuracy (split 2): 0.5500 \n",
      "\n",
      "===== Split 3 =====\n",
      "Epoch 01 | Val Acc: 0.1823\n",
      "Epoch 02 | Val Acc: 0.3532\n",
      "Epoch 03 | Val Acc: 0.3758\n",
      "Epoch 04 | Val Acc: 0.4419\n",
      "Epoch 05 | Val Acc: 0.4613\n",
      "Epoch 06 | Val Acc: 0.4758\n",
      "Epoch 07 | Val Acc: 0.4855\n",
      "Epoch 08 | Val Acc: 0.5081\n",
      "Epoch 09 | Val Acc: 0.5242\n",
      "Epoch 10 | Val Acc: 0.5129\n",
      "Epoch 11 | Val Acc: 0.5306\n",
      "Epoch 12 | Val Acc: 0.5323\n",
      "Epoch 13 | Val Acc: 0.5565\n",
      "Epoch 14 | Val Acc: 0.5242\n",
      "Epoch 15 | Val Acc: 0.5210\n",
      "Epoch 16 | Val Acc: 0.5258\n",
      "Epoch 17 | Val Acc: 0.5516\n",
      "Epoch 18 | Val Acc: 0.5484\n",
      "Epoch 19 | Val Acc: 0.5371\n",
      "Epoch 20 | Val Acc: 0.5548\n",
      "Early stopping\n",
      "Best accuracy (split 3): 0.5565 \n",
      "\n",
      "===== Split 4 =====\n",
      "Epoch 01 | Val Acc: 0.1645\n",
      "Epoch 02 | Val Acc: 0.3097\n",
      "Epoch 03 | Val Acc: 0.3903\n",
      "Epoch 04 | Val Acc: 0.4742\n",
      "Epoch 05 | Val Acc: 0.5290\n",
      "Epoch 06 | Val Acc: 0.5613\n",
      "Epoch 07 | Val Acc: 0.5871\n",
      "Epoch 08 | Val Acc: 0.5565\n",
      "Epoch 09 | Val Acc: 0.5726\n",
      "Epoch 10 | Val Acc: 0.6129\n",
      "Epoch 11 | Val Acc: 0.5774\n",
      "Epoch 12 | Val Acc: 0.6419\n",
      "Epoch 13 | Val Acc: 0.6145\n",
      "Epoch 14 | Val Acc: 0.6016\n",
      "Epoch 15 | Val Acc: 0.5935\n",
      "Epoch 16 | Val Acc: 0.6565\n",
      "Epoch 17 | Val Acc: 0.6758\n",
      "Epoch 18 | Val Acc: 0.6145\n",
      "Epoch 19 | Val Acc: 0.5952\n",
      "Epoch 20 | Val Acc: 0.6016\n",
      "Epoch 21 | Val Acc: 0.5903\n",
      "Epoch 22 | Val Acc: 0.6194\n",
      "Epoch 23 | Val Acc: 0.6452\n",
      "Epoch 24 | Val Acc: 0.6048\n",
      "Early stopping\n",
      "Best accuracy (split 4): 0.6758 \n",
      "\n",
      "===== Split 5 =====\n",
      "Epoch 01 | Val Acc: 0.1419\n",
      "Epoch 02 | Val Acc: 0.0984\n",
      "Epoch 03 | Val Acc: 0.2306\n",
      "Epoch 04 | Val Acc: 0.2742\n",
      "Epoch 05 | Val Acc: 0.2661\n",
      "Epoch 06 | Val Acc: 0.2097\n",
      "Epoch 07 | Val Acc: 0.3419\n",
      "Epoch 08 | Val Acc: 0.3387\n",
      "Epoch 09 | Val Acc: 0.3742\n",
      "Epoch 10 | Val Acc: 0.3839\n",
      "Epoch 11 | Val Acc: 0.3387\n",
      "Epoch 12 | Val Acc: 0.3548\n",
      "Epoch 13 | Val Acc: 0.3371\n",
      "Epoch 14 | Val Acc: 0.3742\n",
      "Epoch 15 | Val Acc: 0.3984\n",
      "Epoch 16 | Val Acc: 0.4242\n",
      "Epoch 17 | Val Acc: 0.3984\n",
      "Epoch 18 | Val Acc: 0.4016\n",
      "Epoch 19 | Val Acc: 0.4258\n",
      "Epoch 20 | Val Acc: 0.4306\n",
      "Epoch 21 | Val Acc: 0.4419\n",
      "Epoch 22 | Val Acc: 0.4403\n",
      "Epoch 23 | Val Acc: 0.4323\n",
      "Epoch 24 | Val Acc: 0.4371\n",
      "Epoch 25 | Val Acc: 0.3823\n",
      "Epoch 26 | Val Acc: 0.3839\n",
      "Epoch 27 | Val Acc: 0.3613\n",
      "Epoch 28 | Val Acc: 0.4129\n",
      "Early stopping\n",
      "Best accuracy (split 5): 0.4419 \n",
      "\n",
      "===== Split 6 =====\n",
      "Epoch 01 | Val Acc: 0.2435\n",
      "Epoch 02 | Val Acc: 0.4097\n",
      "Epoch 03 | Val Acc: 0.4952\n",
      "Epoch 04 | Val Acc: 0.4823\n",
      "Epoch 05 | Val Acc: 0.4871\n",
      "Epoch 06 | Val Acc: 0.5419\n",
      "Epoch 07 | Val Acc: 0.5145\n",
      "Epoch 08 | Val Acc: 0.5887\n",
      "Epoch 09 | Val Acc: 0.5597\n",
      "Epoch 10 | Val Acc: 0.5694\n",
      "Epoch 11 | Val Acc: 0.5484\n",
      "Epoch 12 | Val Acc: 0.5452\n",
      "Epoch 13 | Val Acc: 0.6032\n",
      "Epoch 14 | Val Acc: 0.5613\n",
      "Epoch 15 | Val Acc: 0.5290\n",
      "Epoch 16 | Val Acc: 0.5661\n",
      "Epoch 17 | Val Acc: 0.5613\n",
      "Epoch 18 | Val Acc: 0.5306\n",
      "Epoch 19 | Val Acc: 0.5613\n",
      "Epoch 20 | Val Acc: 0.5790\n",
      "Early stopping\n",
      "Best accuracy (split 6): 0.6032 \n",
      "\n",
      "===== Split 7 =====\n",
      "Epoch 01 | Val Acc: 0.1194\n",
      "Epoch 02 | Val Acc: 0.1581\n",
      "Epoch 03 | Val Acc: 0.3081\n",
      "Epoch 04 | Val Acc: 0.3371\n",
      "Epoch 05 | Val Acc: 0.3613\n",
      "Epoch 06 | Val Acc: 0.3419\n",
      "Epoch 07 | Val Acc: 0.3710\n",
      "Epoch 08 | Val Acc: 0.3952\n",
      "Epoch 09 | Val Acc: 0.3758\n",
      "Epoch 10 | Val Acc: 0.3871\n",
      "Epoch 11 | Val Acc: 0.4226\n",
      "Epoch 12 | Val Acc: 0.4000\n",
      "Epoch 13 | Val Acc: 0.4145\n",
      "Epoch 14 | Val Acc: 0.4290\n",
      "Epoch 15 | Val Acc: 0.4371\n",
      "Epoch 16 | Val Acc: 0.3968\n",
      "Epoch 17 | Val Acc: 0.4516\n",
      "Epoch 18 | Val Acc: 0.4161\n",
      "Epoch 19 | Val Acc: 0.3726\n",
      "Epoch 20 | Val Acc: 0.3742\n",
      "Epoch 21 | Val Acc: 0.4468\n",
      "Epoch 22 | Val Acc: 0.3452\n",
      "Epoch 23 | Val Acc: 0.3919\n",
      "Epoch 24 | Val Acc: 0.3758\n",
      "Early stopping\n",
      "Best accuracy (split 7): 0.4516 \n",
      "\n",
      "===== Split 8 =====\n",
      "Epoch 01 | Val Acc: 0.1871\n",
      "Epoch 02 | Val Acc: 0.3484\n",
      "Epoch 03 | Val Acc: 0.3984\n",
      "Epoch 04 | Val Acc: 0.4581\n",
      "Epoch 05 | Val Acc: 0.4806\n",
      "Epoch 06 | Val Acc: 0.5419\n",
      "Epoch 07 | Val Acc: 0.5516\n",
      "Epoch 08 | Val Acc: 0.5048\n",
      "Epoch 09 | Val Acc: 0.5129\n",
      "Epoch 10 | Val Acc: 0.5468\n",
      "Epoch 11 | Val Acc: 0.4548\n",
      "Epoch 12 | Val Acc: 0.5145\n",
      "Epoch 13 | Val Acc: 0.5161\n",
      "Epoch 14 | Val Acc: 0.5097\n",
      "Early stopping\n",
      "Best accuracy (split 8): 0.5516 \n",
      "\n",
      "===== Split 9 =====\n",
      "Epoch 01 | Val Acc: 0.1613\n",
      "Epoch 02 | Val Acc: 0.2468\n",
      "Epoch 03 | Val Acc: 0.3290\n",
      "Epoch 04 | Val Acc: 0.3742\n",
      "Epoch 05 | Val Acc: 0.3548\n",
      "Epoch 06 | Val Acc: 0.3548\n",
      "Epoch 07 | Val Acc: 0.4048\n",
      "Epoch 08 | Val Acc: 0.4452\n",
      "Epoch 09 | Val Acc: 0.4790\n",
      "Epoch 10 | Val Acc: 0.3742\n",
      "Epoch 11 | Val Acc: 0.4935\n",
      "Epoch 12 | Val Acc: 0.4387\n",
      "Epoch 13 | Val Acc: 0.4565\n",
      "Epoch 14 | Val Acc: 0.4774\n",
      "Epoch 15 | Val Acc: 0.4726\n",
      "Epoch 16 | Val Acc: 0.4500\n",
      "Epoch 17 | Val Acc: 0.4677\n",
      "Epoch 18 | Val Acc: 0.4629\n",
      "Early stopping\n",
      "Best accuracy (split 9): 0.4935 \n",
      "\n",
      "===== Split 10 =====\n",
      "Epoch 01 | Val Acc: 0.2258\n",
      "Epoch 02 | Val Acc: 0.3016\n",
      "Epoch 03 | Val Acc: 0.4403\n",
      "Epoch 04 | Val Acc: 0.4242\n",
      "Epoch 05 | Val Acc: 0.5516\n",
      "Epoch 06 | Val Acc: 0.5726\n",
      "Epoch 07 | Val Acc: 0.5210\n",
      "Epoch 08 | Val Acc: 0.6000\n",
      "Epoch 09 | Val Acc: 0.5935\n",
      "Epoch 10 | Val Acc: 0.5887\n",
      "Epoch 11 | Val Acc: 0.6081\n",
      "Epoch 12 | Val Acc: 0.6290\n",
      "Epoch 13 | Val Acc: 0.6065\n",
      "Epoch 14 | Val Acc: 0.6048\n",
      "Epoch 15 | Val Acc: 0.6048\n",
      "Epoch 16 | Val Acc: 0.6161\n",
      "Epoch 17 | Val Acc: 0.6177\n",
      "Epoch 18 | Val Acc: 0.5968\n",
      "Epoch 19 | Val Acc: 0.6000\n",
      "Early stopping\n",
      "Best accuracy (split 10): 0.6290 \n",
      "\n",
      "===== Split 11 =====\n",
      "Epoch 01 | Val Acc: 0.1790\n",
      "Epoch 02 | Val Acc: 0.3210\n",
      "Epoch 03 | Val Acc: 0.4194\n",
      "Epoch 04 | Val Acc: 0.4903\n",
      "Epoch 05 | Val Acc: 0.4726\n",
      "Epoch 06 | Val Acc: 0.5145\n",
      "Epoch 07 | Val Acc: 0.5774\n",
      "Epoch 08 | Val Acc: 0.6194\n",
      "Epoch 09 | Val Acc: 0.5806\n",
      "Epoch 10 | Val Acc: 0.6065\n",
      "Epoch 11 | Val Acc: 0.5823\n",
      "Epoch 12 | Val Acc: 0.5887\n",
      "Epoch 13 | Val Acc: 0.6129\n",
      "Epoch 14 | Val Acc: 0.6468\n",
      "Epoch 15 | Val Acc: 0.6242\n",
      "Epoch 16 | Val Acc: 0.6177\n",
      "Epoch 17 | Val Acc: 0.5952\n",
      "Epoch 18 | Val Acc: 0.6274\n",
      "Epoch 19 | Val Acc: 0.6387\n",
      "Epoch 20 | Val Acc: 0.6597\n",
      "Epoch 21 | Val Acc: 0.6790\n",
      "Epoch 22 | Val Acc: 0.6452\n",
      "Epoch 23 | Val Acc: 0.6371\n",
      "Epoch 24 | Val Acc: 0.6484\n",
      "Epoch 25 | Val Acc: 0.5887\n",
      "Epoch 26 | Val Acc: 0.6435\n",
      "Epoch 27 | Val Acc: 0.6323\n",
      "Epoch 28 | Val Acc: 0.6581\n",
      "Early stopping\n",
      "Best accuracy (split 11): 0.6790 \n",
      "\n",
      "===== Split 12 =====\n",
      "Epoch 01 | Val Acc: 0.2242\n",
      "Epoch 02 | Val Acc: 0.3790\n",
      "Epoch 03 | Val Acc: 0.4871\n",
      "Epoch 04 | Val Acc: 0.5565\n",
      "Epoch 05 | Val Acc: 0.5968\n",
      "Epoch 06 | Val Acc: 0.6161\n",
      "Epoch 07 | Val Acc: 0.6387\n",
      "Epoch 08 | Val Acc: 0.6081\n",
      "Epoch 09 | Val Acc: 0.6710\n",
      "Epoch 10 | Val Acc: 0.6806\n",
      "Epoch 11 | Val Acc: 0.6758\n",
      "Epoch 12 | Val Acc: 0.6452\n",
      "Epoch 13 | Val Acc: 0.6774\n",
      "Epoch 14 | Val Acc: 0.6790\n",
      "Epoch 15 | Val Acc: 0.6903\n",
      "Epoch 16 | Val Acc: 0.6452\n",
      "Epoch 17 | Val Acc: 0.6952\n",
      "Epoch 18 | Val Acc: 0.6677\n",
      "Epoch 19 | Val Acc: 0.7016\n",
      "Epoch 20 | Val Acc: 0.7226\n",
      "Epoch 21 | Val Acc: 0.7113\n",
      "Epoch 22 | Val Acc: 0.7032\n",
      "Epoch 23 | Val Acc: 0.7000\n",
      "Epoch 24 | Val Acc: 0.7210\n",
      "Epoch 25 | Val Acc: 0.7016\n",
      "Epoch 26 | Val Acc: 0.6887\n",
      "Epoch 27 | Val Acc: 0.7258\n",
      "Epoch 28 | Val Acc: 0.7129\n",
      "Epoch 29 | Val Acc: 0.7242\n",
      "Epoch 30 | Val Acc: 0.7065\n",
      "Epoch 31 | Val Acc: 0.6806\n",
      "Epoch 32 | Val Acc: 0.7194\n",
      "Epoch 33 | Val Acc: 0.6984\n",
      "Epoch 34 | Val Acc: 0.7145\n",
      "Early stopping\n",
      "Best accuracy (split 12): 0.7258 \n",
      "\n",
      "===== Split 13 =====\n",
      "Epoch 01 | Val Acc: 0.1968\n",
      "Epoch 02 | Val Acc: 0.3806\n",
      "Epoch 03 | Val Acc: 0.4742\n",
      "Epoch 04 | Val Acc: 0.5226\n",
      "Epoch 05 | Val Acc: 0.5726\n",
      "Epoch 06 | Val Acc: 0.6048\n",
      "Epoch 07 | Val Acc: 0.5839\n",
      "Epoch 08 | Val Acc: 0.5984\n",
      "Epoch 09 | Val Acc: 0.6000\n",
      "Epoch 10 | Val Acc: 0.6371\n",
      "Epoch 11 | Val Acc: 0.6419\n",
      "Epoch 12 | Val Acc: 0.6177\n",
      "Epoch 13 | Val Acc: 0.6452\n",
      "Epoch 14 | Val Acc: 0.6194\n",
      "Epoch 15 | Val Acc: 0.6258\n",
      "Epoch 16 | Val Acc: 0.6081\n",
      "Epoch 17 | Val Acc: 0.6290\n",
      "Epoch 18 | Val Acc: 0.6435\n",
      "Epoch 19 | Val Acc: 0.6032\n",
      "Epoch 20 | Val Acc: 0.6403\n",
      "Early stopping\n",
      "Best accuracy (split 13): 0.6452 \n",
      "\n",
      "===== Split 14 =====\n",
      "Epoch 01 | Val Acc: 0.0613\n",
      "Epoch 02 | Val Acc: 0.1371\n",
      "Epoch 03 | Val Acc: 0.2210\n",
      "Epoch 04 | Val Acc: 0.2113\n",
      "Epoch 05 | Val Acc: 0.2758\n",
      "Epoch 06 | Val Acc: 0.3210\n",
      "Epoch 07 | Val Acc: 0.3419\n",
      "Epoch 08 | Val Acc: 0.3339\n",
      "Epoch 09 | Val Acc: 0.3871\n",
      "Epoch 10 | Val Acc: 0.3677\n",
      "Epoch 11 | Val Acc: 0.3694\n",
      "Epoch 12 | Val Acc: 0.3903\n",
      "Epoch 13 | Val Acc: 0.3548\n",
      "Epoch 14 | Val Acc: 0.3548\n",
      "Epoch 15 | Val Acc: 0.3677\n",
      "Epoch 16 | Val Acc: 0.3710\n",
      "Epoch 17 | Val Acc: 0.3726\n",
      "Epoch 18 | Val Acc: 0.3661\n",
      "Epoch 19 | Val Acc: 0.3742\n",
      "Early stopping\n",
      "Best accuracy (split 14): 0.3903 \n",
      "\n",
      "===== Split 15 =====\n",
      "Epoch 01 | Val Acc: 0.1484\n",
      "Epoch 02 | Val Acc: 0.3226\n",
      "Epoch 03 | Val Acc: 0.4581\n",
      "Epoch 04 | Val Acc: 0.4355\n",
      "Epoch 05 | Val Acc: 0.4855\n",
      "Epoch 06 | Val Acc: 0.5532\n",
      "Epoch 07 | Val Acc: 0.5774\n",
      "Epoch 08 | Val Acc: 0.5000\n",
      "Epoch 09 | Val Acc: 0.5887\n",
      "Epoch 10 | Val Acc: 0.6177\n",
      "Epoch 11 | Val Acc: 0.5548\n",
      "Epoch 12 | Val Acc: 0.6161\n",
      "Epoch 13 | Val Acc: 0.5774\n",
      "Epoch 14 | Val Acc: 0.5855\n",
      "Epoch 15 | Val Acc: 0.6323\n",
      "Epoch 16 | Val Acc: 0.5935\n",
      "Epoch 17 | Val Acc: 0.6048\n",
      "Epoch 18 | Val Acc: 0.5468\n",
      "Epoch 19 | Val Acc: 0.6032\n",
      "Epoch 20 | Val Acc: 0.6113\n",
      "Epoch 21 | Val Acc: 0.6226\n",
      "Epoch 22 | Val Acc: 0.6452\n",
      "Epoch 23 | Val Acc: 0.6000\n",
      "Epoch 24 | Val Acc: 0.6210\n",
      "Epoch 25 | Val Acc: 0.5984\n",
      "Epoch 26 | Val Acc: 0.6161\n",
      "Epoch 27 | Val Acc: 0.6355\n",
      "Epoch 28 | Val Acc: 0.5887\n",
      "Epoch 29 | Val Acc: 0.6065\n",
      "Early stopping\n",
      "Best accuracy (split 15): 0.6452 \n",
      "\n",
      "===== Split 16 =====\n",
      "Epoch 01 | Val Acc: 0.1419\n",
      "Epoch 02 | Val Acc: 0.3145\n",
      "Epoch 03 | Val Acc: 0.4290\n",
      "Epoch 04 | Val Acc: 0.5306\n",
      "Epoch 05 | Val Acc: 0.5532\n",
      "Epoch 06 | Val Acc: 0.5968\n",
      "Epoch 07 | Val Acc: 0.6113\n",
      "Epoch 08 | Val Acc: 0.6242\n",
      "Epoch 09 | Val Acc: 0.6597\n",
      "Epoch 10 | Val Acc: 0.6355\n",
      "Epoch 11 | Val Acc: 0.6597\n",
      "Epoch 12 | Val Acc: 0.6694\n",
      "Epoch 13 | Val Acc: 0.6016\n",
      "Epoch 14 | Val Acc: 0.6726\n",
      "Epoch 15 | Val Acc: 0.6452\n",
      "Epoch 16 | Val Acc: 0.6661\n",
      "Epoch 17 | Val Acc: 0.6919\n",
      "Epoch 18 | Val Acc: 0.6919\n",
      "Epoch 19 | Val Acc: 0.6919\n",
      "Epoch 20 | Val Acc: 0.7145\n",
      "Epoch 21 | Val Acc: 0.6629\n",
      "Epoch 22 | Val Acc: 0.7097\n",
      "Epoch 23 | Val Acc: 0.6726\n",
      "Epoch 24 | Val Acc: 0.6806\n",
      "Epoch 25 | Val Acc: 0.6694\n",
      "Epoch 26 | Val Acc: 0.6790\n",
      "Epoch 27 | Val Acc: 0.7226\n",
      "Epoch 28 | Val Acc: 0.7000\n",
      "Epoch 29 | Val Acc: 0.6968\n",
      "Epoch 30 | Val Acc: 0.7016\n",
      "Epoch 31 | Val Acc: 0.6371\n",
      "Epoch 32 | Val Acc: 0.6952\n",
      "Epoch 33 | Val Acc: 0.7048\n",
      "Epoch 34 | Val Acc: 0.7242\n",
      "Epoch 35 | Val Acc: 0.7129\n",
      "Epoch 36 | Val Acc: 0.6516\n",
      "Epoch 37 | Val Acc: 0.6548\n",
      "Epoch 38 | Val Acc: 0.7177\n",
      "Epoch 39 | Val Acc: 0.6581\n",
      "Epoch 40 | Val Acc: 0.6694\n",
      "Epoch 41 | Val Acc: 0.7065\n",
      "Early stopping\n",
      "Best accuracy (split 16): 0.7242 \n",
      "\n",
      "===== Split 17 =====\n",
      "Epoch 01 | Val Acc: 0.0887\n",
      "Epoch 02 | Val Acc: 0.2677\n",
      "Epoch 03 | Val Acc: 0.4694\n",
      "Epoch 04 | Val Acc: 0.5065\n",
      "Epoch 05 | Val Acc: 0.5000\n",
      "Epoch 06 | Val Acc: 0.5468\n",
      "Epoch 07 | Val Acc: 0.6032\n",
      "Epoch 08 | Val Acc: 0.5629\n",
      "Epoch 09 | Val Acc: 0.6081\n",
      "Epoch 10 | Val Acc: 0.6710\n",
      "Epoch 11 | Val Acc: 0.6177\n",
      "Epoch 12 | Val Acc: 0.6145\n",
      "Epoch 13 | Val Acc: 0.7097\n",
      "Epoch 14 | Val Acc: 0.6629\n",
      "Epoch 15 | Val Acc: 0.6629\n",
      "Epoch 16 | Val Acc: 0.6661\n",
      "Epoch 17 | Val Acc: 0.6065\n",
      "Epoch 18 | Val Acc: 0.6484\n",
      "Epoch 19 | Val Acc: 0.6516\n",
      "Epoch 20 | Val Acc: 0.6468\n",
      "Early stopping\n",
      "Best accuracy (split 17): 0.7097 \n",
      "\n",
      "===== Split 18 =====\n",
      "Epoch 01 | Val Acc: 0.1210\n",
      "Epoch 02 | Val Acc: 0.3371\n",
      "Epoch 03 | Val Acc: 0.3871\n",
      "Epoch 04 | Val Acc: 0.5000\n",
      "Epoch 05 | Val Acc: 0.4758\n",
      "Epoch 06 | Val Acc: 0.5677\n",
      "Epoch 07 | Val Acc: 0.5306\n",
      "Epoch 08 | Val Acc: 0.5887\n",
      "Epoch 09 | Val Acc: 0.5597\n",
      "Epoch 10 | Val Acc: 0.5516\n",
      "Epoch 11 | Val Acc: 0.5371\n",
      "Epoch 12 | Val Acc: 0.5984\n",
      "Epoch 13 | Val Acc: 0.6097\n",
      "Epoch 14 | Val Acc: 0.5871\n",
      "Epoch 15 | Val Acc: 0.6081\n",
      "Epoch 16 | Val Acc: 0.6032\n",
      "Epoch 17 | Val Acc: 0.5806\n",
      "Epoch 18 | Val Acc: 0.6371\n",
      "Epoch 19 | Val Acc: 0.6306\n",
      "Epoch 20 | Val Acc: 0.6145\n",
      "Epoch 21 | Val Acc: 0.6306\n",
      "Epoch 22 | Val Acc: 0.6081\n",
      "Epoch 23 | Val Acc: 0.6484\n",
      "Epoch 24 | Val Acc: 0.6387\n",
      "Epoch 25 | Val Acc: 0.6371\n",
      "Epoch 26 | Val Acc: 0.5935\n",
      "Epoch 27 | Val Acc: 0.6452\n",
      "Epoch 28 | Val Acc: 0.6355\n",
      "Epoch 29 | Val Acc: 0.6048\n",
      "Epoch 30 | Val Acc: 0.6516\n",
      "Epoch 31 | Val Acc: 0.6210\n",
      "Epoch 32 | Val Acc: 0.6452\n",
      "Epoch 33 | Val Acc: 0.6113\n",
      "Epoch 34 | Val Acc: 0.6500\n",
      "Epoch 35 | Val Acc: 0.6500\n",
      "Epoch 36 | Val Acc: 0.5952\n",
      "Epoch 37 | Val Acc: 0.6097\n",
      "Early stopping\n",
      "Best accuracy (split 18): 0.6516 \n",
      "\n",
      "===== Split 19 =====\n",
      "Epoch 01 | Val Acc: 0.0984\n",
      "Epoch 02 | Val Acc: 0.1968\n",
      "Epoch 03 | Val Acc: 0.2435\n",
      "Epoch 04 | Val Acc: 0.3871\n",
      "Epoch 05 | Val Acc: 0.4210\n",
      "Epoch 06 | Val Acc: 0.4419\n",
      "Epoch 07 | Val Acc: 0.4645\n",
      "Epoch 08 | Val Acc: 0.4694\n",
      "Epoch 09 | Val Acc: 0.4403\n",
      "Epoch 10 | Val Acc: 0.4532\n",
      "Epoch 11 | Val Acc: 0.4581\n",
      "Epoch 12 | Val Acc: 0.4806\n",
      "Epoch 13 | Val Acc: 0.4871\n",
      "Epoch 14 | Val Acc: 0.4839\n",
      "Epoch 15 | Val Acc: 0.4484\n",
      "Epoch 16 | Val Acc: 0.4774\n",
      "Epoch 17 | Val Acc: 0.5129\n",
      "Epoch 18 | Val Acc: 0.4629\n",
      "Epoch 19 | Val Acc: 0.4677\n",
      "Epoch 20 | Val Acc: 0.4806\n",
      "Epoch 21 | Val Acc: 0.4387\n",
      "Epoch 22 | Val Acc: 0.4500\n",
      "Epoch 23 | Val Acc: 0.4806\n",
      "Epoch 24 | Val Acc: 0.4677\n",
      "Early stopping\n",
      "Best accuracy (split 19): 0.5129 \n",
      "\n",
      "FINAL AVERAGE ACCURACY (CNN + CCE): 0.5936332767402377\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        X = np.load(x_path)          \n",
    "        y = np.load(y_path)           \n",
    "        for i in range(X.shape[0]):\n",
    "            for c in range(6):\n",
    "                X[i, :, c] = (X[i, :, c] - X[i, :, c].mean()) / (X[i, :, c].std() + 1e-8)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.argmax(y, axis=1), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = self.net(x)\n",
    "        return x.squeeze(-1)   \n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, encoder, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.encoder(x)\n",
    "        logits = self.classifier(emb)\n",
    "        return logits\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7):\n",
    "        self.patience = patience\n",
    "        self.best_acc = 0.0\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "            self.best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   epochs=500, patience=7):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.0005)\n",
    "    early_stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = model(x).argmax(1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:02d} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if early_stopper.step(val_acc, model):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    early_stopper.restore(model)\n",
    "    return early_stopper.best_acc\n",
    "\n",
    "BASE = \"models/Data/Data/62_classes/UserIndependent\"\n",
    "\n",
    "accs = []\n",
    "\n",
    "for split in range(1, 20):\n",
    "    print(f\"\\n===== Split {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "    model = FullModel(CNNEncoder(), num_classes=62).to(device)\n",
    "\n",
    "    acc = train_and_eval(model, train_loader, test_loader)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"Best accuracy (split {split}): {acc:.4f} \")\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY (CNN + CCE):\", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b2a8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "===== SPLIT 1 =====\n",
      "Epoch 001 | Val Acc: 0.0355\n",
      "Epoch 002 | Val Acc: 0.0500\n",
      "Epoch 003 | Val Acc: 0.1032\n",
      "Epoch 004 | Val Acc: 0.1839\n",
      "Epoch 005 | Val Acc: 0.1500\n",
      "Epoch 006 | Val Acc: 0.2371\n",
      "Epoch 007 | Val Acc: 0.2500\n",
      "Epoch 008 | Val Acc: 0.2855\n",
      "Epoch 009 | Val Acc: 0.4065\n",
      "Epoch 010 | Val Acc: 0.4484\n",
      "Epoch 011 | Val Acc: 0.4968\n",
      "Epoch 012 | Val Acc: 0.4419\n",
      "Epoch 013 | Val Acc: 0.5210\n",
      "Epoch 014 | Val Acc: 0.4855\n",
      "Epoch 015 | Val Acc: 0.5290\n",
      "Epoch 016 | Val Acc: 0.5242\n",
      "Epoch 017 | Val Acc: 0.5242\n",
      "Epoch 018 | Val Acc: 0.4935\n",
      "Epoch 019 | Val Acc: 0.5452\n",
      "Epoch 020 | Val Acc: 0.5306\n",
      "Epoch 021 | Val Acc: 0.5742\n",
      "Epoch 022 | Val Acc: 0.5823\n",
      "Epoch 023 | Val Acc: 0.5629\n",
      "Epoch 024 | Val Acc: 0.5790\n",
      "Epoch 025 | Val Acc: 0.5887\n",
      "Epoch 026 | Val Acc: 0.5871\n",
      "Epoch 027 | Val Acc: 0.5387\n",
      "Epoch 028 | Val Acc: 0.6016\n",
      "Epoch 029 | Val Acc: 0.6048\n",
      "Epoch 030 | Val Acc: 0.5758\n",
      "Epoch 031 | Val Acc: 0.6081\n",
      "Epoch 032 | Val Acc: 0.5823\n",
      "Epoch 033 | Val Acc: 0.6435\n",
      "Epoch 034 | Val Acc: 0.5871\n",
      "Epoch 035 | Val Acc: 0.5984\n",
      "Epoch 036 | Val Acc: 0.6355\n",
      "Epoch 037 | Val Acc: 0.5919\n",
      "Epoch 038 | Val Acc: 0.6161\n",
      "Epoch 039 | Val Acc: 0.6081\n",
      "Epoch 040 | Val Acc: 0.6290\n",
      "Epoch 041 | Val Acc: 0.5903\n",
      "Epoch 042 | Val Acc: 0.6097\n",
      "Epoch 043 | Val Acc: 0.6306\n",
      "Early stopping triggered\n",
      "Best accuracy (split 1): 0.6435\n",
      "\n",
      "===== SPLIT 2 =====\n",
      "Epoch 001 | Val Acc: 0.0258\n",
      "Epoch 002 | Val Acc: 0.0355\n",
      "Epoch 003 | Val Acc: 0.0484\n",
      "Epoch 004 | Val Acc: 0.1097\n",
      "Epoch 005 | Val Acc: 0.1839\n",
      "Epoch 006 | Val Acc: 0.2129\n",
      "Epoch 007 | Val Acc: 0.2290\n",
      "Epoch 008 | Val Acc: 0.2952\n",
      "Epoch 009 | Val Acc: 0.2952\n",
      "Epoch 010 | Val Acc: 0.4097\n",
      "Epoch 011 | Val Acc: 0.4226\n",
      "Epoch 012 | Val Acc: 0.3403\n",
      "Epoch 013 | Val Acc: 0.4532\n",
      "Epoch 014 | Val Acc: 0.4532\n",
      "Epoch 015 | Val Acc: 0.4468\n",
      "Epoch 016 | Val Acc: 0.4790\n",
      "Epoch 017 | Val Acc: 0.4194\n",
      "Epoch 018 | Val Acc: 0.4468\n",
      "Epoch 019 | Val Acc: 0.4355\n",
      "Epoch 020 | Val Acc: 0.4758\n",
      "Epoch 021 | Val Acc: 0.4419\n",
      "Epoch 022 | Val Acc: 0.4097\n",
      "Epoch 023 | Val Acc: 0.4774\n",
      "Epoch 024 | Val Acc: 0.4629\n",
      "Epoch 025 | Val Acc: 0.4403\n",
      "Epoch 026 | Val Acc: 0.4710\n",
      "Early stopping triggered\n",
      "Best accuracy (split 2): 0.4790\n",
      "\n",
      "===== SPLIT 3 =====\n",
      "Epoch 001 | Val Acc: 0.0355\n",
      "Epoch 002 | Val Acc: 0.0500\n",
      "Epoch 003 | Val Acc: 0.1194\n",
      "Epoch 004 | Val Acc: 0.1435\n",
      "Epoch 005 | Val Acc: 0.1758\n",
      "Epoch 006 | Val Acc: 0.2306\n",
      "Epoch 007 | Val Acc: 0.2758\n",
      "Epoch 008 | Val Acc: 0.3000\n",
      "Epoch 009 | Val Acc: 0.3339\n",
      "Epoch 010 | Val Acc: 0.2726\n",
      "Epoch 011 | Val Acc: 0.3839\n",
      "Epoch 012 | Val Acc: 0.4032\n",
      "Epoch 013 | Val Acc: 0.4258\n",
      "Epoch 014 | Val Acc: 0.4306\n",
      "Epoch 015 | Val Acc: 0.4532\n",
      "Epoch 016 | Val Acc: 0.4629\n",
      "Epoch 017 | Val Acc: 0.4145\n",
      "Epoch 018 | Val Acc: 0.4452\n",
      "Epoch 019 | Val Acc: 0.4419\n",
      "Epoch 020 | Val Acc: 0.5000\n",
      "Epoch 021 | Val Acc: 0.4742\n",
      "Epoch 022 | Val Acc: 0.4790\n",
      "Epoch 023 | Val Acc: 0.4694\n",
      "Epoch 024 | Val Acc: 0.4968\n",
      "Epoch 025 | Val Acc: 0.5081\n",
      "Epoch 026 | Val Acc: 0.4984\n",
      "Epoch 027 | Val Acc: 0.4952\n",
      "Epoch 028 | Val Acc: 0.5129\n",
      "Epoch 029 | Val Acc: 0.5387\n",
      "Epoch 030 | Val Acc: 0.5048\n",
      "Epoch 031 | Val Acc: 0.5081\n",
      "Epoch 032 | Val Acc: 0.4903\n",
      "Epoch 033 | Val Acc: 0.5210\n",
      "Epoch 034 | Val Acc: 0.4935\n",
      "Epoch 035 | Val Acc: 0.4952\n",
      "Epoch 036 | Val Acc: 0.5355\n",
      "Epoch 037 | Val Acc: 0.5161\n",
      "Epoch 038 | Val Acc: 0.5161\n",
      "Epoch 039 | Val Acc: 0.5032\n",
      "Early stopping triggered\n",
      "Best accuracy (split 3): 0.5387\n",
      "\n",
      "===== SPLIT 4 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.0194\n",
      "Epoch 003 | Val Acc: 0.0323\n",
      "Epoch 004 | Val Acc: 0.0629\n",
      "Epoch 005 | Val Acc: 0.1806\n",
      "Epoch 006 | Val Acc: 0.2113\n",
      "Epoch 007 | Val Acc: 0.2726\n",
      "Epoch 008 | Val Acc: 0.3468\n",
      "Epoch 009 | Val Acc: 0.3016\n",
      "Epoch 010 | Val Acc: 0.3774\n",
      "Epoch 011 | Val Acc: 0.4129\n",
      "Epoch 012 | Val Acc: 0.4806\n",
      "Epoch 013 | Val Acc: 0.5419\n",
      "Epoch 014 | Val Acc: 0.5129\n",
      "Epoch 015 | Val Acc: 0.4742\n",
      "Epoch 016 | Val Acc: 0.5226\n",
      "Epoch 017 | Val Acc: 0.5145\n",
      "Epoch 018 | Val Acc: 0.5048\n",
      "Epoch 019 | Val Acc: 0.5500\n",
      "Epoch 020 | Val Acc: 0.5161\n",
      "Epoch 021 | Val Acc: 0.5935\n",
      "Epoch 022 | Val Acc: 0.5823\n",
      "Epoch 023 | Val Acc: 0.5371\n",
      "Epoch 024 | Val Acc: 0.5565\n",
      "Epoch 025 | Val Acc: 0.5500\n",
      "Epoch 026 | Val Acc: 0.5887\n",
      "Epoch 027 | Val Acc: 0.5290\n",
      "Epoch 028 | Val Acc: 0.5758\n",
      "Epoch 029 | Val Acc: 0.5500\n",
      "Epoch 030 | Val Acc: 0.5710\n",
      "Epoch 031 | Val Acc: 0.5629\n",
      "Early stopping triggered\n",
      "Best accuracy (split 4): 0.5935\n",
      "\n",
      "===== SPLIT 5 =====\n",
      "Epoch 001 | Val Acc: 0.0468\n",
      "Epoch 002 | Val Acc: 0.0323\n",
      "Epoch 003 | Val Acc: 0.0790\n",
      "Epoch 004 | Val Acc: 0.1500\n",
      "Epoch 005 | Val Acc: 0.1806\n",
      "Epoch 006 | Val Acc: 0.2339\n",
      "Epoch 007 | Val Acc: 0.2871\n",
      "Epoch 008 | Val Acc: 0.2532\n",
      "Epoch 009 | Val Acc: 0.3371\n",
      "Epoch 010 | Val Acc: 0.3065\n",
      "Epoch 011 | Val Acc: 0.3290\n",
      "Epoch 012 | Val Acc: 0.3516\n",
      "Epoch 013 | Val Acc: 0.3790\n",
      "Epoch 014 | Val Acc: 0.3871\n",
      "Epoch 015 | Val Acc: 0.3806\n",
      "Epoch 016 | Val Acc: 0.3435\n",
      "Epoch 017 | Val Acc: 0.3016\n",
      "Epoch 018 | Val Acc: 0.3694\n",
      "Epoch 019 | Val Acc: 0.3823\n",
      "Epoch 020 | Val Acc: 0.4145\n",
      "Epoch 021 | Val Acc: 0.3581\n",
      "Epoch 022 | Val Acc: 0.4339\n",
      "Epoch 023 | Val Acc: 0.4290\n",
      "Epoch 024 | Val Acc: 0.4290\n",
      "Epoch 025 | Val Acc: 0.4452\n",
      "Epoch 026 | Val Acc: 0.4306\n",
      "Epoch 027 | Val Acc: 0.4387\n",
      "Epoch 028 | Val Acc: 0.4484\n",
      "Epoch 029 | Val Acc: 0.4435\n",
      "Epoch 030 | Val Acc: 0.4419\n",
      "Epoch 031 | Val Acc: 0.4113\n",
      "Epoch 032 | Val Acc: 0.4758\n",
      "Epoch 033 | Val Acc: 0.4258\n",
      "Epoch 034 | Val Acc: 0.4290\n",
      "Epoch 035 | Val Acc: 0.4484\n",
      "Epoch 036 | Val Acc: 0.4097\n",
      "Epoch 037 | Val Acc: 0.4306\n",
      "Epoch 038 | Val Acc: 0.4113\n",
      "Epoch 039 | Val Acc: 0.4323\n",
      "Epoch 040 | Val Acc: 0.4016\n",
      "Epoch 041 | Val Acc: 0.4258\n",
      "Epoch 042 | Val Acc: 0.4210\n",
      "Early stopping triggered\n",
      "Best accuracy (split 5): 0.4758\n",
      "\n",
      "===== SPLIT 6 =====\n",
      "Epoch 001 | Val Acc: 0.0387\n",
      "Epoch 002 | Val Acc: 0.0306\n",
      "Epoch 003 | Val Acc: 0.1258\n",
      "Epoch 004 | Val Acc: 0.2274\n",
      "Epoch 005 | Val Acc: 0.2694\n",
      "Epoch 006 | Val Acc: 0.2710\n",
      "Epoch 007 | Val Acc: 0.3306\n",
      "Epoch 008 | Val Acc: 0.3581\n",
      "Epoch 009 | Val Acc: 0.3903\n",
      "Epoch 010 | Val Acc: 0.4677\n",
      "Epoch 011 | Val Acc: 0.4839\n",
      "Epoch 012 | Val Acc: 0.4806\n",
      "Epoch 013 | Val Acc: 0.4952\n",
      "Epoch 014 | Val Acc: 0.4984\n",
      "Epoch 015 | Val Acc: 0.4823\n",
      "Epoch 016 | Val Acc: 0.5097\n",
      "Epoch 017 | Val Acc: 0.5484\n",
      "Epoch 018 | Val Acc: 0.5548\n",
      "Epoch 019 | Val Acc: 0.5629\n",
      "Epoch 020 | Val Acc: 0.5548\n",
      "Epoch 021 | Val Acc: 0.5839\n",
      "Epoch 022 | Val Acc: 0.5871\n",
      "Epoch 023 | Val Acc: 0.5597\n",
      "Epoch 024 | Val Acc: 0.5742\n",
      "Epoch 025 | Val Acc: 0.5629\n",
      "Epoch 026 | Val Acc: 0.6032\n",
      "Epoch 027 | Val Acc: 0.5790\n",
      "Epoch 028 | Val Acc: 0.6210\n",
      "Epoch 029 | Val Acc: 0.5839\n",
      "Epoch 030 | Val Acc: 0.6274\n",
      "Epoch 031 | Val Acc: 0.5355\n",
      "Epoch 032 | Val Acc: 0.5952\n",
      "Epoch 033 | Val Acc: 0.5887\n",
      "Epoch 034 | Val Acc: 0.5758\n",
      "Epoch 035 | Val Acc: 0.5823\n",
      "Epoch 036 | Val Acc: 0.5806\n",
      "Epoch 037 | Val Acc: 0.5419\n",
      "Epoch 038 | Val Acc: 0.5984\n",
      "Epoch 039 | Val Acc: 0.5694\n",
      "Epoch 040 | Val Acc: 0.5613\n",
      "Early stopping triggered\n",
      "Best accuracy (split 6): 0.6274\n",
      "\n",
      "===== SPLIT 7 =====\n",
      "Epoch 001 | Val Acc: 0.0629\n",
      "Epoch 002 | Val Acc: 0.0661\n",
      "Epoch 003 | Val Acc: 0.0758\n",
      "Epoch 004 | Val Acc: 0.1516\n",
      "Epoch 005 | Val Acc: 0.1565\n",
      "Epoch 006 | Val Acc: 0.2565\n",
      "Epoch 007 | Val Acc: 0.2290\n",
      "Epoch 008 | Val Acc: 0.3000\n",
      "Epoch 009 | Val Acc: 0.3081\n",
      "Epoch 010 | Val Acc: 0.3097\n",
      "Epoch 011 | Val Acc: 0.3597\n",
      "Epoch 012 | Val Acc: 0.3661\n",
      "Epoch 013 | Val Acc: 0.3645\n",
      "Epoch 014 | Val Acc: 0.3484\n",
      "Epoch 015 | Val Acc: 0.3823\n",
      "Epoch 016 | Val Acc: 0.2645\n",
      "Epoch 017 | Val Acc: 0.3613\n",
      "Epoch 018 | Val Acc: 0.4290\n",
      "Epoch 019 | Val Acc: 0.4065\n",
      "Epoch 020 | Val Acc: 0.3887\n",
      "Epoch 021 | Val Acc: 0.4129\n",
      "Epoch 022 | Val Acc: 0.3839\n",
      "Epoch 023 | Val Acc: 0.4226\n",
      "Epoch 024 | Val Acc: 0.3677\n",
      "Epoch 025 | Val Acc: 0.4145\n",
      "Epoch 026 | Val Acc: 0.3790\n",
      "Epoch 027 | Val Acc: 0.3758\n",
      "Epoch 028 | Val Acc: 0.3871\n",
      "Early stopping triggered\n",
      "Best accuracy (split 7): 0.4290\n",
      "\n",
      "===== SPLIT 8 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.1145\n",
      "Epoch 003 | Val Acc: 0.1677\n",
      "Epoch 004 | Val Acc: 0.2500\n",
      "Epoch 005 | Val Acc: 0.1597\n",
      "Epoch 006 | Val Acc: 0.2871\n",
      "Epoch 007 | Val Acc: 0.3613\n",
      "Epoch 008 | Val Acc: 0.4032\n",
      "Epoch 009 | Val Acc: 0.3968\n",
      "Epoch 010 | Val Acc: 0.3758\n",
      "Epoch 011 | Val Acc: 0.4597\n",
      "Epoch 012 | Val Acc: 0.4887\n",
      "Epoch 013 | Val Acc: 0.5145\n",
      "Epoch 014 | Val Acc: 0.4935\n",
      "Epoch 015 | Val Acc: 0.4403\n",
      "Epoch 016 | Val Acc: 0.5565\n",
      "Epoch 017 | Val Acc: 0.5823\n",
      "Epoch 018 | Val Acc: 0.5629\n",
      "Epoch 019 | Val Acc: 0.5048\n",
      "Epoch 020 | Val Acc: 0.5290\n",
      "Epoch 021 | Val Acc: 0.5258\n",
      "Epoch 022 | Val Acc: 0.5629\n",
      "Epoch 023 | Val Acc: 0.5742\n",
      "Epoch 024 | Val Acc: 0.5919\n",
      "Epoch 025 | Val Acc: 0.5597\n",
      "Epoch 026 | Val Acc: 0.5371\n",
      "Epoch 027 | Val Acc: 0.5516\n",
      "Epoch 028 | Val Acc: 0.5435\n",
      "Epoch 029 | Val Acc: 0.5629\n",
      "Epoch 030 | Val Acc: 0.5177\n",
      "Epoch 031 | Val Acc: 0.5387\n",
      "Epoch 032 | Val Acc: 0.4387\n",
      "Epoch 033 | Val Acc: 0.5500\n",
      "Epoch 034 | Val Acc: 0.5177\n",
      "Early stopping triggered\n",
      "Best accuracy (split 8): 0.5919\n",
      "\n",
      "===== SPLIT 9 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0597\n",
      "Epoch 003 | Val Acc: 0.0919\n",
      "Epoch 004 | Val Acc: 0.1516\n",
      "Epoch 005 | Val Acc: 0.1500\n",
      "Epoch 006 | Val Acc: 0.2113\n",
      "Epoch 007 | Val Acc: 0.2694\n",
      "Epoch 008 | Val Acc: 0.3161\n",
      "Epoch 009 | Val Acc: 0.3903\n",
      "Epoch 010 | Val Acc: 0.2935\n",
      "Epoch 011 | Val Acc: 0.4129\n",
      "Epoch 012 | Val Acc: 0.4177\n",
      "Epoch 013 | Val Acc: 0.2419\n",
      "Epoch 014 | Val Acc: 0.4968\n",
      "Epoch 015 | Val Acc: 0.4855\n",
      "Epoch 016 | Val Acc: 0.4871\n",
      "Epoch 017 | Val Acc: 0.4048\n",
      "Epoch 018 | Val Acc: 0.4210\n",
      "Epoch 019 | Val Acc: 0.3823\n",
      "Epoch 020 | Val Acc: 0.4210\n",
      "Epoch 021 | Val Acc: 0.4984\n",
      "Epoch 022 | Val Acc: 0.4903\n",
      "Epoch 023 | Val Acc: 0.4677\n",
      "Epoch 024 | Val Acc: 0.4806\n",
      "Epoch 025 | Val Acc: 0.4581\n",
      "Epoch 026 | Val Acc: 0.4290\n",
      "Epoch 027 | Val Acc: 0.4387\n",
      "Epoch 028 | Val Acc: 0.4823\n",
      "Epoch 029 | Val Acc: 0.4597\n",
      "Epoch 030 | Val Acc: 0.4532\n",
      "Epoch 031 | Val Acc: 0.5097\n",
      "Epoch 032 | Val Acc: 0.4726\n",
      "Epoch 033 | Val Acc: 0.4677\n",
      "Epoch 034 | Val Acc: 0.4548\n",
      "Epoch 035 | Val Acc: 0.4452\n",
      "Epoch 036 | Val Acc: 0.4581\n",
      "Epoch 037 | Val Acc: 0.5081\n",
      "Epoch 038 | Val Acc: 0.5000\n",
      "Epoch 039 | Val Acc: 0.4645\n",
      "Epoch 040 | Val Acc: 0.5048\n",
      "Epoch 041 | Val Acc: 0.4435\n",
      "Early stopping triggered\n",
      "Best accuracy (split 9): 0.5097\n",
      "\n",
      "===== SPLIT 10 =====\n",
      "Epoch 001 | Val Acc: 0.0435\n",
      "Epoch 002 | Val Acc: 0.0887\n",
      "Epoch 003 | Val Acc: 0.0403\n",
      "Epoch 004 | Val Acc: 0.1355\n",
      "Epoch 005 | Val Acc: 0.2081\n",
      "Epoch 006 | Val Acc: 0.2435\n",
      "Epoch 007 | Val Acc: 0.1903\n",
      "Epoch 008 | Val Acc: 0.3548\n",
      "Epoch 009 | Val Acc: 0.3565\n",
      "Epoch 010 | Val Acc: 0.4435\n",
      "Epoch 011 | Val Acc: 0.4290\n",
      "Epoch 012 | Val Acc: 0.4710\n",
      "Epoch 013 | Val Acc: 0.4952\n",
      "Epoch 014 | Val Acc: 0.5226\n",
      "Epoch 015 | Val Acc: 0.4823\n",
      "Epoch 016 | Val Acc: 0.4839\n",
      "Epoch 017 | Val Acc: 0.5177\n",
      "Epoch 018 | Val Acc: 0.5581\n",
      "Epoch 019 | Val Acc: 0.5435\n",
      "Epoch 020 | Val Acc: 0.5581\n",
      "Epoch 021 | Val Acc: 0.5742\n",
      "Epoch 022 | Val Acc: 0.5984\n",
      "Epoch 023 | Val Acc: 0.5710\n",
      "Epoch 024 | Val Acc: 0.5710\n",
      "Epoch 025 | Val Acc: 0.6016\n",
      "Epoch 026 | Val Acc: 0.5661\n",
      "Epoch 027 | Val Acc: 0.5452\n",
      "Epoch 028 | Val Acc: 0.5823\n",
      "Epoch 029 | Val Acc: 0.5871\n",
      "Epoch 030 | Val Acc: 0.5290\n",
      "Epoch 031 | Val Acc: 0.5581\n",
      "Epoch 032 | Val Acc: 0.5258\n",
      "Epoch 033 | Val Acc: 0.5710\n",
      "Epoch 034 | Val Acc: 0.5935\n",
      "Epoch 035 | Val Acc: 0.5710\n",
      "Early stopping triggered\n",
      "Best accuracy (split 10): 0.6016\n",
      "\n",
      "===== SPLIT 11 =====\n",
      "Epoch 001 | Val Acc: 0.0355\n",
      "Epoch 002 | Val Acc: 0.0855\n",
      "Epoch 003 | Val Acc: 0.0806\n",
      "Epoch 004 | Val Acc: 0.1645\n",
      "Epoch 005 | Val Acc: 0.2581\n",
      "Epoch 006 | Val Acc: 0.3742\n",
      "Epoch 007 | Val Acc: 0.3903\n",
      "Epoch 008 | Val Acc: 0.3645\n",
      "Epoch 009 | Val Acc: 0.4710\n",
      "Epoch 010 | Val Acc: 0.4710\n",
      "Epoch 011 | Val Acc: 0.3597\n",
      "Epoch 012 | Val Acc: 0.4710\n",
      "Epoch 013 | Val Acc: 0.4726\n",
      "Epoch 014 | Val Acc: 0.4855\n",
      "Epoch 015 | Val Acc: 0.5806\n",
      "Epoch 016 | Val Acc: 0.5629\n",
      "Epoch 017 | Val Acc: 0.5710\n",
      "Epoch 018 | Val Acc: 0.5887\n",
      "Epoch 019 | Val Acc: 0.5629\n",
      "Epoch 020 | Val Acc: 0.5081\n",
      "Epoch 021 | Val Acc: 0.6210\n",
      "Epoch 022 | Val Acc: 0.6403\n",
      "Epoch 023 | Val Acc: 0.5726\n",
      "Epoch 024 | Val Acc: 0.6613\n",
      "Epoch 025 | Val Acc: 0.5887\n",
      "Epoch 026 | Val Acc: 0.6210\n",
      "Epoch 027 | Val Acc: 0.6210\n",
      "Epoch 028 | Val Acc: 0.6274\n",
      "Epoch 029 | Val Acc: 0.6032\n",
      "Epoch 030 | Val Acc: 0.6419\n",
      "Epoch 031 | Val Acc: 0.5887\n",
      "Epoch 032 | Val Acc: 0.6210\n",
      "Epoch 033 | Val Acc: 0.5952\n",
      "Epoch 034 | Val Acc: 0.6032\n",
      "Early stopping triggered\n",
      "Best accuracy (split 11): 0.6613\n",
      "\n",
      "===== SPLIT 12 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.0629\n",
      "Epoch 003 | Val Acc: 0.1323\n",
      "Epoch 004 | Val Acc: 0.1032\n",
      "Epoch 005 | Val Acc: 0.2500\n",
      "Epoch 006 | Val Acc: 0.3097\n",
      "Epoch 007 | Val Acc: 0.3484\n",
      "Epoch 008 | Val Acc: 0.3371\n",
      "Epoch 009 | Val Acc: 0.4177\n",
      "Epoch 010 | Val Acc: 0.4581\n",
      "Epoch 011 | Val Acc: 0.5065\n",
      "Epoch 012 | Val Acc: 0.5097\n",
      "Epoch 013 | Val Acc: 0.5742\n",
      "Epoch 014 | Val Acc: 0.5935\n",
      "Epoch 015 | Val Acc: 0.5565\n",
      "Epoch 016 | Val Acc: 0.6226\n",
      "Epoch 017 | Val Acc: 0.5694\n",
      "Epoch 018 | Val Acc: 0.6065\n",
      "Epoch 019 | Val Acc: 0.5452\n",
      "Epoch 020 | Val Acc: 0.6355\n",
      "Epoch 021 | Val Acc: 0.6226\n",
      "Epoch 022 | Val Acc: 0.6306\n",
      "Epoch 023 | Val Acc: 0.6306\n",
      "Epoch 024 | Val Acc: 0.6452\n",
      "Epoch 025 | Val Acc: 0.6097\n",
      "Epoch 026 | Val Acc: 0.6161\n",
      "Epoch 027 | Val Acc: 0.6177\n",
      "Epoch 028 | Val Acc: 0.6226\n",
      "Epoch 029 | Val Acc: 0.6629\n",
      "Epoch 030 | Val Acc: 0.6661\n",
      "Epoch 031 | Val Acc: 0.6661\n",
      "Epoch 032 | Val Acc: 0.6726\n",
      "Epoch 033 | Val Acc: 0.6742\n",
      "Epoch 034 | Val Acc: 0.6887\n",
      "Epoch 035 | Val Acc: 0.6355\n",
      "Epoch 036 | Val Acc: 0.6242\n",
      "Epoch 037 | Val Acc: 0.6742\n",
      "Epoch 038 | Val Acc: 0.6677\n",
      "Epoch 039 | Val Acc: 0.6565\n",
      "Epoch 040 | Val Acc: 0.6758\n",
      "Epoch 041 | Val Acc: 0.6468\n",
      "Epoch 042 | Val Acc: 0.6823\n",
      "Epoch 043 | Val Acc: 0.6532\n",
      "Epoch 044 | Val Acc: 0.6823\n",
      "Early stopping triggered\n",
      "Best accuracy (split 12): 0.6887\n",
      "\n",
      "===== SPLIT 13 =====\n",
      "Epoch 001 | Val Acc: 0.0242\n",
      "Epoch 002 | Val Acc: 0.0839\n",
      "Epoch 003 | Val Acc: 0.1258\n",
      "Epoch 004 | Val Acc: 0.2113\n",
      "Epoch 005 | Val Acc: 0.2565\n",
      "Epoch 006 | Val Acc: 0.3339\n",
      "Epoch 007 | Val Acc: 0.3613\n",
      "Epoch 008 | Val Acc: 0.4242\n",
      "Epoch 009 | Val Acc: 0.4806\n",
      "Epoch 010 | Val Acc: 0.4694\n",
      "Epoch 011 | Val Acc: 0.4500\n",
      "Epoch 012 | Val Acc: 0.4097\n",
      "Epoch 013 | Val Acc: 0.5452\n",
      "Epoch 014 | Val Acc: 0.5629\n",
      "Epoch 015 | Val Acc: 0.5419\n",
      "Epoch 016 | Val Acc: 0.5565\n",
      "Epoch 017 | Val Acc: 0.6016\n",
      "Epoch 018 | Val Acc: 0.5887\n",
      "Epoch 019 | Val Acc: 0.6097\n",
      "Epoch 020 | Val Acc: 0.5758\n",
      "Epoch 021 | Val Acc: 0.6161\n",
      "Epoch 022 | Val Acc: 0.6435\n",
      "Epoch 023 | Val Acc: 0.6177\n",
      "Epoch 024 | Val Acc: 0.6565\n",
      "Epoch 025 | Val Acc: 0.6403\n",
      "Epoch 026 | Val Acc: 0.6016\n",
      "Epoch 027 | Val Acc: 0.6694\n",
      "Epoch 028 | Val Acc: 0.6677\n",
      "Epoch 029 | Val Acc: 0.6484\n",
      "Epoch 030 | Val Acc: 0.6274\n",
      "Epoch 031 | Val Acc: 0.6194\n",
      "Epoch 032 | Val Acc: 0.6548\n",
      "Epoch 033 | Val Acc: 0.6532\n",
      "Epoch 034 | Val Acc: 0.6403\n",
      "Epoch 035 | Val Acc: 0.6355\n",
      "Epoch 036 | Val Acc: 0.6500\n",
      "Epoch 037 | Val Acc: 0.6339\n",
      "Early stopping triggered\n",
      "Best accuracy (split 13): 0.6694\n",
      "\n",
      "===== SPLIT 14 =====\n",
      "Epoch 001 | Val Acc: 0.0177\n",
      "Epoch 002 | Val Acc: 0.0613\n",
      "Epoch 003 | Val Acc: 0.0565\n",
      "Epoch 004 | Val Acc: 0.0597\n",
      "Epoch 005 | Val Acc: 0.1371\n",
      "Epoch 006 | Val Acc: 0.1403\n",
      "Epoch 007 | Val Acc: 0.1468\n",
      "Epoch 008 | Val Acc: 0.2065\n",
      "Epoch 009 | Val Acc: 0.2226\n",
      "Epoch 010 | Val Acc: 0.1935\n",
      "Epoch 011 | Val Acc: 0.2500\n",
      "Epoch 012 | Val Acc: 0.2774\n",
      "Epoch 013 | Val Acc: 0.2194\n",
      "Epoch 014 | Val Acc: 0.2710\n",
      "Epoch 015 | Val Acc: 0.3000\n",
      "Epoch 016 | Val Acc: 0.2952\n",
      "Epoch 017 | Val Acc: 0.2952\n",
      "Epoch 018 | Val Acc: 0.2516\n",
      "Epoch 019 | Val Acc: 0.2823\n",
      "Epoch 020 | Val Acc: 0.3129\n",
      "Epoch 021 | Val Acc: 0.3032\n",
      "Epoch 022 | Val Acc: 0.2871\n",
      "Epoch 023 | Val Acc: 0.3016\n",
      "Epoch 024 | Val Acc: 0.3081\n",
      "Epoch 025 | Val Acc: 0.2694\n",
      "Epoch 026 | Val Acc: 0.3306\n",
      "Epoch 027 | Val Acc: 0.3403\n",
      "Epoch 028 | Val Acc: 0.3258\n",
      "Epoch 029 | Val Acc: 0.3484\n",
      "Epoch 030 | Val Acc: 0.3177\n",
      "Epoch 031 | Val Acc: 0.3484\n",
      "Epoch 032 | Val Acc: 0.3274\n",
      "Epoch 033 | Val Acc: 0.3677\n",
      "Epoch 034 | Val Acc: 0.3565\n",
      "Epoch 035 | Val Acc: 0.3581\n",
      "Epoch 036 | Val Acc: 0.3177\n",
      "Epoch 037 | Val Acc: 0.3645\n",
      "Epoch 038 | Val Acc: 0.3613\n",
      "Epoch 039 | Val Acc: 0.3435\n",
      "Epoch 040 | Val Acc: 0.3387\n",
      "Epoch 041 | Val Acc: 0.3597\n",
      "Epoch 042 | Val Acc: 0.3758\n",
      "Epoch 043 | Val Acc: 0.3290\n",
      "Epoch 044 | Val Acc: 0.3613\n",
      "Epoch 045 | Val Acc: 0.3355\n",
      "Epoch 046 | Val Acc: 0.3597\n",
      "Epoch 047 | Val Acc: 0.3677\n",
      "Epoch 048 | Val Acc: 0.3919\n",
      "Epoch 049 | Val Acc: 0.3468\n",
      "Epoch 050 | Val Acc: 0.3629\n",
      "Epoch 051 | Val Acc: 0.3597\n",
      "Epoch 052 | Val Acc: 0.3548\n",
      "Epoch 053 | Val Acc: 0.3339\n",
      "Epoch 054 | Val Acc: 0.3290\n",
      "Epoch 055 | Val Acc: 0.3726\n",
      "Epoch 056 | Val Acc: 0.3355\n",
      "Epoch 057 | Val Acc: 0.3258\n",
      "Epoch 058 | Val Acc: 0.3548\n",
      "Early stopping triggered\n",
      "Best accuracy (split 14): 0.3919\n",
      "\n",
      "===== SPLIT 15 =====\n",
      "Epoch 001 | Val Acc: 0.0548\n",
      "Epoch 002 | Val Acc: 0.0839\n",
      "Epoch 003 | Val Acc: 0.0710\n",
      "Epoch 004 | Val Acc: 0.2032\n",
      "Epoch 005 | Val Acc: 0.2758\n",
      "Epoch 006 | Val Acc: 0.3516\n",
      "Epoch 007 | Val Acc: 0.3823\n",
      "Epoch 008 | Val Acc: 0.3806\n",
      "Epoch 009 | Val Acc: 0.3919\n",
      "Epoch 010 | Val Acc: 0.4758\n",
      "Epoch 011 | Val Acc: 0.4468\n",
      "Epoch 012 | Val Acc: 0.5065\n",
      "Epoch 013 | Val Acc: 0.5274\n",
      "Epoch 014 | Val Acc: 0.5403\n",
      "Epoch 015 | Val Acc: 0.5855\n",
      "Epoch 016 | Val Acc: 0.5661\n",
      "Epoch 017 | Val Acc: 0.5629\n",
      "Epoch 018 | Val Acc: 0.5532\n",
      "Epoch 019 | Val Acc: 0.4919\n",
      "Epoch 020 | Val Acc: 0.6065\n",
      "Epoch 021 | Val Acc: 0.5000\n",
      "Epoch 022 | Val Acc: 0.5435\n",
      "Epoch 023 | Val Acc: 0.5194\n",
      "Epoch 024 | Val Acc: 0.5742\n",
      "Epoch 025 | Val Acc: 0.5339\n",
      "Epoch 026 | Val Acc: 0.5565\n",
      "Epoch 027 | Val Acc: 0.5645\n",
      "Epoch 028 | Val Acc: 0.5742\n",
      "Epoch 029 | Val Acc: 0.5968\n",
      "Epoch 030 | Val Acc: 0.6065\n",
      "Early stopping triggered\n",
      "Best accuracy (split 15): 0.6065\n",
      "\n",
      "===== SPLIT 16 =====\n",
      "Epoch 001 | Val Acc: 0.0274\n",
      "Epoch 002 | Val Acc: 0.0548\n",
      "Epoch 003 | Val Acc: 0.0903\n",
      "Epoch 004 | Val Acc: 0.2290\n",
      "Epoch 005 | Val Acc: 0.2661\n",
      "Epoch 006 | Val Acc: 0.3113\n",
      "Epoch 007 | Val Acc: 0.2855\n",
      "Epoch 008 | Val Acc: 0.4226\n",
      "Epoch 009 | Val Acc: 0.4823\n",
      "Epoch 010 | Val Acc: 0.5065\n",
      "Epoch 011 | Val Acc: 0.5532\n",
      "Epoch 012 | Val Acc: 0.5355\n",
      "Epoch 013 | Val Acc: 0.5919\n",
      "Epoch 014 | Val Acc: 0.6226\n",
      "Epoch 015 | Val Acc: 0.6097\n",
      "Epoch 016 | Val Acc: 0.6371\n",
      "Epoch 017 | Val Acc: 0.6516\n",
      "Epoch 018 | Val Acc: 0.6419\n",
      "Epoch 019 | Val Acc: 0.6548\n",
      "Epoch 020 | Val Acc: 0.5935\n",
      "Epoch 021 | Val Acc: 0.6726\n",
      "Epoch 022 | Val Acc: 0.6581\n",
      "Epoch 023 | Val Acc: 0.6677\n",
      "Epoch 024 | Val Acc: 0.6806\n",
      "Epoch 025 | Val Acc: 0.6726\n",
      "Epoch 026 | Val Acc: 0.6855\n",
      "Epoch 027 | Val Acc: 0.6629\n",
      "Epoch 028 | Val Acc: 0.6903\n",
      "Epoch 029 | Val Acc: 0.6806\n",
      "Epoch 030 | Val Acc: 0.6081\n",
      "Epoch 031 | Val Acc: 0.6419\n",
      "Epoch 032 | Val Acc: 0.6984\n",
      "Epoch 033 | Val Acc: 0.7016\n",
      "Epoch 034 | Val Acc: 0.6935\n",
      "Epoch 035 | Val Acc: 0.7097\n",
      "Epoch 036 | Val Acc: 0.7097\n",
      "Epoch 037 | Val Acc: 0.7194\n",
      "Epoch 038 | Val Acc: 0.6758\n",
      "Epoch 039 | Val Acc: 0.7048\n",
      "Epoch 040 | Val Acc: 0.6548\n",
      "Epoch 041 | Val Acc: 0.7097\n",
      "Epoch 042 | Val Acc: 0.7129\n",
      "Epoch 043 | Val Acc: 0.6742\n",
      "Epoch 044 | Val Acc: 0.7065\n",
      "Epoch 045 | Val Acc: 0.6790\n",
      "Epoch 046 | Val Acc: 0.7145\n",
      "Epoch 047 | Val Acc: 0.6968\n",
      "Early stopping triggered\n",
      "Best accuracy (split 16): 0.7194\n",
      "\n",
      "===== SPLIT 17 =====\n",
      "Epoch 001 | Val Acc: 0.0145\n",
      "Epoch 002 | Val Acc: 0.0468\n",
      "Epoch 003 | Val Acc: 0.1306\n",
      "Epoch 004 | Val Acc: 0.1613\n",
      "Epoch 005 | Val Acc: 0.1726\n",
      "Epoch 006 | Val Acc: 0.3016\n",
      "Epoch 007 | Val Acc: 0.2855\n",
      "Epoch 008 | Val Acc: 0.4274\n",
      "Epoch 009 | Val Acc: 0.4226\n",
      "Epoch 010 | Val Acc: 0.4371\n",
      "Epoch 011 | Val Acc: 0.5145\n",
      "Epoch 012 | Val Acc: 0.5726\n",
      "Epoch 013 | Val Acc: 0.5790\n",
      "Epoch 014 | Val Acc: 0.6565\n",
      "Epoch 015 | Val Acc: 0.5500\n",
      "Epoch 016 | Val Acc: 0.6000\n",
      "Epoch 017 | Val Acc: 0.4274\n",
      "Epoch 018 | Val Acc: 0.6097\n",
      "Epoch 019 | Val Acc: 0.6210\n",
      "Epoch 020 | Val Acc: 0.6065\n",
      "Epoch 021 | Val Acc: 0.6161\n",
      "Epoch 022 | Val Acc: 0.6468\n",
      "Epoch 023 | Val Acc: 0.5855\n",
      "Epoch 024 | Val Acc: 0.6032\n",
      "Early stopping triggered\n",
      "Best accuracy (split 17): 0.6565\n",
      "\n",
      "===== SPLIT 18 =====\n",
      "Epoch 001 | Val Acc: 0.0419\n",
      "Epoch 002 | Val Acc: 0.1113\n",
      "Epoch 003 | Val Acc: 0.1774\n",
      "Epoch 004 | Val Acc: 0.2484\n",
      "Epoch 005 | Val Acc: 0.2581\n",
      "Epoch 006 | Val Acc: 0.3000\n",
      "Epoch 007 | Val Acc: 0.3452\n",
      "Epoch 008 | Val Acc: 0.3597\n",
      "Epoch 009 | Val Acc: 0.4500\n",
      "Epoch 010 | Val Acc: 0.5435\n",
      "Epoch 011 | Val Acc: 0.5177\n",
      "Epoch 012 | Val Acc: 0.5806\n",
      "Epoch 013 | Val Acc: 0.6016\n",
      "Epoch 014 | Val Acc: 0.6210\n",
      "Epoch 015 | Val Acc: 0.5871\n",
      "Epoch 016 | Val Acc: 0.6355\n",
      "Epoch 017 | Val Acc: 0.6161\n",
      "Epoch 018 | Val Acc: 0.6516\n",
      "Epoch 019 | Val Acc: 0.5887\n",
      "Epoch 020 | Val Acc: 0.6226\n",
      "Epoch 021 | Val Acc: 0.6000\n",
      "Epoch 022 | Val Acc: 0.6613\n",
      "Epoch 023 | Val Acc: 0.6581\n",
      "Epoch 024 | Val Acc: 0.6339\n",
      "Epoch 025 | Val Acc: 0.6258\n",
      "Epoch 026 | Val Acc: 0.6468\n",
      "Epoch 027 | Val Acc: 0.6242\n",
      "Epoch 028 | Val Acc: 0.6048\n",
      "Epoch 029 | Val Acc: 0.6500\n",
      "Epoch 030 | Val Acc: 0.6081\n",
      "Epoch 031 | Val Acc: 0.6290\n",
      "Epoch 032 | Val Acc: 0.6323\n",
      "Early stopping triggered\n",
      "Best accuracy (split 18): 0.6613\n",
      "\n",
      "===== SPLIT 19 =====\n",
      "Epoch 001 | Val Acc: 0.0226\n",
      "Epoch 002 | Val Acc: 0.0532\n",
      "Epoch 003 | Val Acc: 0.0694\n",
      "Epoch 004 | Val Acc: 0.1435\n",
      "Epoch 005 | Val Acc: 0.1661\n",
      "Epoch 006 | Val Acc: 0.2210\n",
      "Epoch 007 | Val Acc: 0.2532\n",
      "Epoch 008 | Val Acc: 0.2887\n",
      "Epoch 009 | Val Acc: 0.3226\n",
      "Epoch 010 | Val Acc: 0.3468\n",
      "Epoch 011 | Val Acc: 0.3323\n",
      "Epoch 012 | Val Acc: 0.3790\n",
      "Epoch 013 | Val Acc: 0.3726\n",
      "Epoch 014 | Val Acc: 0.3597\n",
      "Epoch 015 | Val Acc: 0.3806\n",
      "Epoch 016 | Val Acc: 0.4065\n",
      "Epoch 017 | Val Acc: 0.4339\n",
      "Epoch 018 | Val Acc: 0.3790\n",
      "Epoch 019 | Val Acc: 0.4113\n",
      "Epoch 020 | Val Acc: 0.4081\n",
      "Epoch 021 | Val Acc: 0.3806\n",
      "Epoch 022 | Val Acc: 0.4097\n",
      "Epoch 023 | Val Acc: 0.4129\n",
      "Epoch 024 | Val Acc: 0.4355\n",
      "Epoch 025 | Val Acc: 0.4274\n",
      "Epoch 026 | Val Acc: 0.4258\n",
      "Epoch 027 | Val Acc: 0.4403\n",
      "Epoch 028 | Val Acc: 0.4452\n",
      "Epoch 029 | Val Acc: 0.4290\n",
      "Epoch 030 | Val Acc: 0.4371\n",
      "Epoch 031 | Val Acc: 0.4048\n",
      "Epoch 032 | Val Acc: 0.4145\n",
      "Epoch 033 | Val Acc: 0.4226\n",
      "Epoch 034 | Val Acc: 0.4339\n",
      "Epoch 035 | Val Acc: 0.3952\n",
      "Epoch 036 | Val Acc: 0.4000\n",
      "Epoch 037 | Val Acc: 0.4016\n",
      "Epoch 038 | Val Acc: 0.4210\n",
      "Early stopping triggered\n",
      "Best accuracy (split 19): 0.4452\n",
      "\n",
      "FINAL AVERAGE ACCURACY (CNN + BiLSTM + CCE): 0.5784380305602717\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        X = np.load(x_path)\n",
    "        y = np.load(y_path)\n",
    "\n",
    "        # channel-wise normalization (same as Keras)\n",
    "        for i in range(X.shape[0]):\n",
    "            for c in range(6):\n",
    "                X[i, :, c] = (X[i, :, c] - X[i, :, c].mean()) / (X[i, :, c].std() + 1e-8)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.argmax(y, axis=1), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ---------------- CNN + BiLSTM Model ----------------\n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN part (same filters as Keras)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # BiLSTM (same idea as Keras)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=256,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(512, num_classes)  # 256*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        x = x.permute(0, 2, 1)       # (B, C, T)\n",
    "        x = self.cnn(x)              # (B, 256, T')\n",
    "\n",
    "        x = x.permute(0, 2, 1)       # (B, T', 256)\n",
    "        out, _ = self.bilstm(x)      # (B, T', 512)\n",
    "\n",
    "        feat = out[:, -1, :]         # last timestep\n",
    "        feat = self.dropout(feat)\n",
    "        logits = self.classifier(feat)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# ---------------- Early Stopping ----------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.best_acc = 0.0\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "            self.best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   epochs=500, patience=10):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # evaluation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = model(x).argmax(dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ---------------- Main Loop ----------------\n",
    "BASE = \"models/Data/Data/62_classes/UserIndependent\"\n",
    "accs = []\n",
    "\n",
    "for split in range(1, 20):\n",
    "    print(f\"\\n===== SPLIT {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "    model = CNN_BiLSTM(num_classes=62).to(device)\n",
    "\n",
    "    acc = train_and_eval(model, train_loader, test_loader)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"Best accuracy (split {split}): {acc:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY (CNN + BiLSTM + CCE):\", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d55d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "===== SPLIT 1 =====\n",
      "Epoch 001 | Val Acc: 0.0274\n",
      "Epoch 002 | Val Acc: 0.0403\n",
      "Epoch 003 | Val Acc: 0.0484\n",
      "Epoch 004 | Val Acc: 0.1097\n",
      "Epoch 005 | Val Acc: 0.1242\n",
      "Epoch 006 | Val Acc: 0.1097\n",
      "Epoch 007 | Val Acc: 0.1339\n",
      "Epoch 008 | Val Acc: 0.1629\n",
      "Epoch 009 | Val Acc: 0.1661\n",
      "Epoch 010 | Val Acc: 0.1661\n",
      "Epoch 011 | Val Acc: 0.1629\n",
      "Epoch 012 | Val Acc: 0.1661\n",
      "Epoch 013 | Val Acc: 0.2048\n",
      "Epoch 014 | Val Acc: 0.2048\n",
      "Epoch 015 | Val Acc: 0.2419\n",
      "Epoch 016 | Val Acc: 0.2565\n",
      "Epoch 017 | Val Acc: 0.2855\n",
      "Epoch 018 | Val Acc: 0.2984\n",
      "Epoch 019 | Val Acc: 0.2823\n",
      "Epoch 020 | Val Acc: 0.2919\n",
      "Epoch 021 | Val Acc: 0.3000\n",
      "Epoch 022 | Val Acc: 0.3274\n",
      "Epoch 023 | Val Acc: 0.2984\n",
      "Epoch 024 | Val Acc: 0.3113\n",
      "Epoch 025 | Val Acc: 0.3258\n",
      "Epoch 026 | Val Acc: 0.3194\n",
      "Epoch 027 | Val Acc: 0.3274\n",
      "Epoch 028 | Val Acc: 0.3613\n",
      "Epoch 029 | Val Acc: 0.3677\n",
      "Epoch 030 | Val Acc: 0.3710\n",
      "Epoch 031 | Val Acc: 0.3516\n",
      "Epoch 032 | Val Acc: 0.3871\n",
      "Epoch 033 | Val Acc: 0.3710\n",
      "Epoch 034 | Val Acc: 0.3871\n",
      "Epoch 035 | Val Acc: 0.3597\n",
      "Epoch 036 | Val Acc: 0.3790\n",
      "Epoch 037 | Val Acc: 0.3823\n",
      "Epoch 038 | Val Acc: 0.4161\n",
      "Epoch 039 | Val Acc: 0.4323\n",
      "Epoch 040 | Val Acc: 0.4161\n",
      "Epoch 041 | Val Acc: 0.4274\n",
      "Epoch 042 | Val Acc: 0.4661\n",
      "Epoch 043 | Val Acc: 0.4500\n",
      "Epoch 044 | Val Acc: 0.4645\n",
      "Epoch 045 | Val Acc: 0.4597\n",
      "Epoch 046 | Val Acc: 0.4452\n",
      "Epoch 047 | Val Acc: 0.4387\n",
      "Epoch 048 | Val Acc: 0.4129\n",
      "Epoch 049 | Val Acc: 0.4403\n",
      "Early stopping\n",
      "Best accuracy (split 1): 0.4661\n",
      "\n",
      "===== SPLIT 2 =====\n",
      "Epoch 001 | Val Acc: 0.0194\n",
      "Epoch 002 | Val Acc: 0.0565\n",
      "Epoch 003 | Val Acc: 0.0484\n",
      "Epoch 004 | Val Acc: 0.0790\n",
      "Epoch 005 | Val Acc: 0.1145\n",
      "Epoch 006 | Val Acc: 0.1016\n",
      "Epoch 007 | Val Acc: 0.1242\n",
      "Epoch 008 | Val Acc: 0.1145\n",
      "Epoch 009 | Val Acc: 0.1548\n",
      "Epoch 010 | Val Acc: 0.1484\n",
      "Epoch 011 | Val Acc: 0.1726\n",
      "Epoch 012 | Val Acc: 0.1968\n",
      "Epoch 013 | Val Acc: 0.1629\n",
      "Epoch 014 | Val Acc: 0.1629\n",
      "Epoch 015 | Val Acc: 0.1952\n",
      "Epoch 016 | Val Acc: 0.1565\n",
      "Epoch 017 | Val Acc: 0.1758\n",
      "Epoch 018 | Val Acc: 0.1823\n",
      "Epoch 019 | Val Acc: 0.2113\n",
      "Epoch 020 | Val Acc: 0.1855\n",
      "Epoch 021 | Val Acc: 0.2000\n",
      "Epoch 022 | Val Acc: 0.2226\n",
      "Epoch 023 | Val Acc: 0.2113\n",
      "Epoch 024 | Val Acc: 0.2226\n",
      "Epoch 025 | Val Acc: 0.2452\n",
      "Epoch 026 | Val Acc: 0.2565\n",
      "Epoch 027 | Val Acc: 0.2661\n",
      "Epoch 028 | Val Acc: 0.2855\n",
      "Epoch 029 | Val Acc: 0.2645\n",
      "Epoch 030 | Val Acc: 0.3177\n",
      "Epoch 031 | Val Acc: 0.2839\n",
      "Epoch 032 | Val Acc: 0.2774\n",
      "Epoch 033 | Val Acc: 0.2887\n",
      "Epoch 034 | Val Acc: 0.2968\n",
      "Epoch 035 | Val Acc: 0.3258\n",
      "Epoch 036 | Val Acc: 0.3145\n",
      "Epoch 037 | Val Acc: 0.3323\n",
      "Epoch 038 | Val Acc: 0.3387\n",
      "Epoch 039 | Val Acc: 0.3129\n",
      "Epoch 040 | Val Acc: 0.3355\n",
      "Epoch 041 | Val Acc: 0.3210\n",
      "Epoch 042 | Val Acc: 0.3355\n",
      "Epoch 043 | Val Acc: 0.3258\n",
      "Epoch 044 | Val Acc: 0.3468\n",
      "Epoch 045 | Val Acc: 0.3758\n",
      "Epoch 046 | Val Acc: 0.3548\n",
      "Epoch 047 | Val Acc: 0.3645\n",
      "Epoch 048 | Val Acc: 0.3839\n",
      "Epoch 049 | Val Acc: 0.3855\n",
      "Epoch 050 | Val Acc: 0.3790\n",
      "Epoch 051 | Val Acc: 0.3629\n",
      "Epoch 052 | Val Acc: 0.3629\n",
      "Epoch 053 | Val Acc: 0.3613\n",
      "Epoch 054 | Val Acc: 0.3952\n",
      "Epoch 055 | Val Acc: 0.3758\n",
      "Epoch 056 | Val Acc: 0.3871\n",
      "Epoch 057 | Val Acc: 0.4016\n",
      "Epoch 058 | Val Acc: 0.3935\n",
      "Epoch 059 | Val Acc: 0.3710\n",
      "Epoch 060 | Val Acc: 0.4065\n",
      "Epoch 061 | Val Acc: 0.4258\n",
      "Epoch 062 | Val Acc: 0.4065\n",
      "Epoch 063 | Val Acc: 0.3806\n",
      "Epoch 064 | Val Acc: 0.3952\n",
      "Epoch 065 | Val Acc: 0.3694\n",
      "Epoch 066 | Val Acc: 0.4177\n",
      "Epoch 067 | Val Acc: 0.4000\n",
      "Epoch 068 | Val Acc: 0.4226\n",
      "Early stopping\n",
      "Best accuracy (split 2): 0.4258\n",
      "\n",
      "===== SPLIT 3 =====\n",
      "Epoch 001 | Val Acc: 0.0403\n",
      "Epoch 002 | Val Acc: 0.0468\n",
      "Epoch 003 | Val Acc: 0.0581\n",
      "Epoch 004 | Val Acc: 0.0935\n",
      "Epoch 005 | Val Acc: 0.0887\n",
      "Epoch 006 | Val Acc: 0.1290\n",
      "Epoch 007 | Val Acc: 0.1500\n",
      "Epoch 008 | Val Acc: 0.1645\n",
      "Epoch 009 | Val Acc: 0.1629\n",
      "Epoch 010 | Val Acc: 0.1790\n",
      "Epoch 011 | Val Acc: 0.2097\n",
      "Epoch 012 | Val Acc: 0.1919\n",
      "Epoch 013 | Val Acc: 0.2145\n",
      "Epoch 014 | Val Acc: 0.2274\n",
      "Epoch 015 | Val Acc: 0.1790\n",
      "Epoch 016 | Val Acc: 0.2000\n",
      "Epoch 017 | Val Acc: 0.2081\n",
      "Epoch 018 | Val Acc: 0.2371\n",
      "Epoch 019 | Val Acc: 0.2242\n",
      "Epoch 020 | Val Acc: 0.2355\n",
      "Epoch 021 | Val Acc: 0.2306\n",
      "Epoch 022 | Val Acc: 0.2532\n",
      "Epoch 023 | Val Acc: 0.2935\n",
      "Epoch 024 | Val Acc: 0.3081\n",
      "Epoch 025 | Val Acc: 0.2758\n",
      "Epoch 026 | Val Acc: 0.2968\n",
      "Epoch 027 | Val Acc: 0.2758\n",
      "Epoch 028 | Val Acc: 0.2774\n",
      "Epoch 029 | Val Acc: 0.2419\n",
      "Epoch 030 | Val Acc: 0.3065\n",
      "Epoch 031 | Val Acc: 0.2935\n",
      "Early stopping\n",
      "Best accuracy (split 3): 0.3081\n",
      "\n",
      "===== SPLIT 4 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0387\n",
      "Epoch 003 | Val Acc: 0.0339\n",
      "Epoch 004 | Val Acc: 0.0887\n",
      "Epoch 005 | Val Acc: 0.0774\n",
      "Epoch 006 | Val Acc: 0.0823\n",
      "Epoch 007 | Val Acc: 0.0984\n",
      "Epoch 008 | Val Acc: 0.1210\n",
      "Epoch 009 | Val Acc: 0.1403\n",
      "Epoch 010 | Val Acc: 0.1387\n",
      "Epoch 011 | Val Acc: 0.1274\n",
      "Epoch 012 | Val Acc: 0.1742\n",
      "Epoch 013 | Val Acc: 0.1823\n",
      "Epoch 014 | Val Acc: 0.1758\n",
      "Epoch 015 | Val Acc: 0.2306\n",
      "Epoch 016 | Val Acc: 0.2500\n",
      "Epoch 017 | Val Acc: 0.2339\n",
      "Epoch 018 | Val Acc: 0.2339\n",
      "Epoch 019 | Val Acc: 0.2661\n",
      "Epoch 020 | Val Acc: 0.2032\n",
      "Epoch 021 | Val Acc: 0.2839\n",
      "Epoch 022 | Val Acc: 0.2774\n",
      "Epoch 023 | Val Acc: 0.2661\n",
      "Epoch 024 | Val Acc: 0.2661\n",
      "Epoch 025 | Val Acc: 0.2935\n",
      "Epoch 026 | Val Acc: 0.2516\n",
      "Epoch 027 | Val Acc: 0.2468\n",
      "Epoch 028 | Val Acc: 0.3581\n",
      "Epoch 029 | Val Acc: 0.3016\n",
      "Epoch 030 | Val Acc: 0.2839\n",
      "Epoch 031 | Val Acc: 0.3468\n",
      "Epoch 032 | Val Acc: 0.3306\n",
      "Epoch 033 | Val Acc: 0.3484\n",
      "Epoch 034 | Val Acc: 0.3242\n",
      "Epoch 035 | Val Acc: 0.3387\n",
      "Early stopping\n",
      "Best accuracy (split 4): 0.3581\n",
      "\n",
      "===== SPLIT 5 =====\n",
      "Epoch 001 | Val Acc: 0.0290\n",
      "Epoch 002 | Val Acc: 0.0371\n",
      "Epoch 003 | Val Acc: 0.0613\n",
      "Epoch 004 | Val Acc: 0.0629\n",
      "Epoch 005 | Val Acc: 0.0984\n",
      "Epoch 006 | Val Acc: 0.1226\n",
      "Epoch 007 | Val Acc: 0.1258\n",
      "Epoch 008 | Val Acc: 0.1210\n",
      "Epoch 009 | Val Acc: 0.1468\n",
      "Epoch 010 | Val Acc: 0.1419\n",
      "Epoch 011 | Val Acc: 0.1258\n",
      "Epoch 012 | Val Acc: 0.1597\n",
      "Epoch 013 | Val Acc: 0.1581\n",
      "Epoch 014 | Val Acc: 0.1774\n",
      "Epoch 015 | Val Acc: 0.1565\n",
      "Epoch 016 | Val Acc: 0.1903\n",
      "Epoch 017 | Val Acc: 0.1613\n",
      "Epoch 018 | Val Acc: 0.1887\n",
      "Epoch 019 | Val Acc: 0.1887\n",
      "Epoch 020 | Val Acc: 0.1274\n",
      "Epoch 021 | Val Acc: 0.1742\n",
      "Epoch 022 | Val Acc: 0.2129\n",
      "Epoch 023 | Val Acc: 0.1952\n",
      "Epoch 024 | Val Acc: 0.2161\n",
      "Epoch 025 | Val Acc: 0.2113\n",
      "Epoch 026 | Val Acc: 0.1871\n",
      "Epoch 027 | Val Acc: 0.2048\n",
      "Epoch 028 | Val Acc: 0.2355\n",
      "Epoch 029 | Val Acc: 0.2419\n",
      "Epoch 030 | Val Acc: 0.2161\n",
      "Epoch 031 | Val Acc: 0.2323\n",
      "Epoch 032 | Val Acc: 0.2500\n",
      "Epoch 033 | Val Acc: 0.2339\n",
      "Epoch 034 | Val Acc: 0.2339\n",
      "Epoch 035 | Val Acc: 0.2403\n",
      "Epoch 036 | Val Acc: 0.2355\n",
      "Epoch 037 | Val Acc: 0.2661\n",
      "Epoch 038 | Val Acc: 0.2468\n",
      "Epoch 039 | Val Acc: 0.2548\n",
      "Epoch 040 | Val Acc: 0.2645\n",
      "Epoch 041 | Val Acc: 0.2726\n",
      "Epoch 042 | Val Acc: 0.2371\n",
      "Epoch 043 | Val Acc: 0.2661\n",
      "Epoch 044 | Val Acc: 0.2726\n",
      "Epoch 045 | Val Acc: 0.2903\n",
      "Epoch 046 | Val Acc: 0.2419\n",
      "Epoch 047 | Val Acc: 0.2532\n",
      "Epoch 048 | Val Acc: 0.2710\n",
      "Epoch 049 | Val Acc: 0.2968\n",
      "Epoch 050 | Val Acc: 0.2823\n",
      "Epoch 051 | Val Acc: 0.2726\n",
      "Epoch 052 | Val Acc: 0.2790\n",
      "Epoch 053 | Val Acc: 0.3032\n",
      "Epoch 054 | Val Acc: 0.2952\n",
      "Epoch 055 | Val Acc: 0.3081\n",
      "Epoch 056 | Val Acc: 0.3258\n",
      "Epoch 057 | Val Acc: 0.3113\n",
      "Epoch 058 | Val Acc: 0.3016\n",
      "Epoch 059 | Val Acc: 0.2952\n",
      "Epoch 060 | Val Acc: 0.2823\n",
      "Epoch 061 | Val Acc: 0.3065\n",
      "Epoch 062 | Val Acc: 0.2984\n",
      "Epoch 063 | Val Acc: 0.2903\n",
      "Early stopping\n",
      "Best accuracy (split 5): 0.3258\n",
      "\n",
      "===== SPLIT 6 =====\n",
      "Epoch 001 | Val Acc: 0.0306\n",
      "Epoch 002 | Val Acc: 0.0339\n",
      "Epoch 003 | Val Acc: 0.0548\n",
      "Epoch 004 | Val Acc: 0.1000\n",
      "Epoch 005 | Val Acc: 0.1113\n",
      "Epoch 006 | Val Acc: 0.1081\n",
      "Epoch 007 | Val Acc: 0.1323\n",
      "Epoch 008 | Val Acc: 0.1839\n",
      "Epoch 009 | Val Acc: 0.1903\n",
      "Epoch 010 | Val Acc: 0.1839\n",
      "Epoch 011 | Val Acc: 0.2161\n",
      "Epoch 012 | Val Acc: 0.1968\n",
      "Epoch 013 | Val Acc: 0.2435\n",
      "Epoch 014 | Val Acc: 0.2468\n",
      "Epoch 015 | Val Acc: 0.2645\n",
      "Epoch 016 | Val Acc: 0.2758\n",
      "Epoch 017 | Val Acc: 0.2710\n",
      "Epoch 018 | Val Acc: 0.2742\n",
      "Epoch 019 | Val Acc: 0.3161\n",
      "Epoch 020 | Val Acc: 0.3097\n",
      "Epoch 021 | Val Acc: 0.3258\n",
      "Epoch 022 | Val Acc: 0.2839\n",
      "Epoch 023 | Val Acc: 0.3306\n",
      "Epoch 024 | Val Acc: 0.3258\n",
      "Epoch 025 | Val Acc: 0.3371\n",
      "Epoch 026 | Val Acc: 0.3629\n",
      "Epoch 027 | Val Acc: 0.2935\n",
      "Epoch 028 | Val Acc: 0.3468\n",
      "Epoch 029 | Val Acc: 0.2887\n",
      "Epoch 030 | Val Acc: 0.2597\n",
      "Epoch 031 | Val Acc: 0.3645\n",
      "Epoch 032 | Val Acc: 0.3548\n",
      "Epoch 033 | Val Acc: 0.3774\n",
      "Epoch 034 | Val Acc: 0.3710\n",
      "Epoch 035 | Val Acc: 0.3758\n",
      "Epoch 036 | Val Acc: 0.3806\n",
      "Epoch 037 | Val Acc: 0.3645\n",
      "Epoch 038 | Val Acc: 0.3968\n",
      "Epoch 039 | Val Acc: 0.3839\n",
      "Epoch 040 | Val Acc: 0.3968\n",
      "Epoch 041 | Val Acc: 0.3774\n",
      "Epoch 042 | Val Acc: 0.4032\n",
      "Epoch 043 | Val Acc: 0.3694\n",
      "Epoch 044 | Val Acc: 0.4339\n",
      "Epoch 045 | Val Acc: 0.4419\n",
      "Epoch 046 | Val Acc: 0.3935\n",
      "Epoch 047 | Val Acc: 0.4274\n",
      "Epoch 048 | Val Acc: 0.4210\n",
      "Epoch 049 | Val Acc: 0.4065\n",
      "Epoch 050 | Val Acc: 0.4177\n",
      "Epoch 051 | Val Acc: 0.3984\n",
      "Epoch 052 | Val Acc: 0.4048\n",
      "Early stopping\n",
      "Best accuracy (split 6): 0.4419\n",
      "\n",
      "===== SPLIT 7 =====\n",
      "Epoch 001 | Val Acc: 0.0177\n",
      "Epoch 002 | Val Acc: 0.0339\n",
      "Epoch 003 | Val Acc: 0.0516\n",
      "Epoch 004 | Val Acc: 0.0548\n",
      "Epoch 005 | Val Acc: 0.0790\n",
      "Epoch 006 | Val Acc: 0.0919\n",
      "Epoch 007 | Val Acc: 0.1129\n",
      "Epoch 008 | Val Acc: 0.1210\n",
      "Epoch 009 | Val Acc: 0.0790\n",
      "Epoch 010 | Val Acc: 0.0806\n",
      "Epoch 011 | Val Acc: 0.1177\n",
      "Epoch 012 | Val Acc: 0.1306\n",
      "Epoch 013 | Val Acc: 0.0952\n",
      "Epoch 014 | Val Acc: 0.0984\n",
      "Epoch 015 | Val Acc: 0.1194\n",
      "Epoch 016 | Val Acc: 0.1177\n",
      "Epoch 017 | Val Acc: 0.1161\n",
      "Epoch 018 | Val Acc: 0.1306\n",
      "Epoch 019 | Val Acc: 0.1323\n",
      "Epoch 020 | Val Acc: 0.1468\n",
      "Epoch 021 | Val Acc: 0.1516\n",
      "Epoch 022 | Val Acc: 0.1532\n",
      "Epoch 023 | Val Acc: 0.1742\n",
      "Epoch 024 | Val Acc: 0.1629\n",
      "Epoch 025 | Val Acc: 0.1597\n",
      "Epoch 026 | Val Acc: 0.1839\n",
      "Epoch 027 | Val Acc: 0.1774\n",
      "Epoch 028 | Val Acc: 0.1823\n",
      "Epoch 029 | Val Acc: 0.1742\n",
      "Epoch 030 | Val Acc: 0.1968\n",
      "Epoch 031 | Val Acc: 0.2016\n",
      "Epoch 032 | Val Acc: 0.2145\n",
      "Epoch 033 | Val Acc: 0.2145\n",
      "Epoch 034 | Val Acc: 0.2210\n",
      "Epoch 035 | Val Acc: 0.2194\n",
      "Epoch 036 | Val Acc: 0.2048\n",
      "Epoch 037 | Val Acc: 0.2339\n",
      "Epoch 038 | Val Acc: 0.2371\n",
      "Epoch 039 | Val Acc: 0.2435\n",
      "Epoch 040 | Val Acc: 0.2371\n",
      "Epoch 041 | Val Acc: 0.2484\n",
      "Epoch 042 | Val Acc: 0.2355\n",
      "Epoch 043 | Val Acc: 0.2387\n",
      "Epoch 044 | Val Acc: 0.2161\n",
      "Epoch 045 | Val Acc: 0.2435\n",
      "Epoch 046 | Val Acc: 0.2677\n",
      "Epoch 047 | Val Acc: 0.2726\n",
      "Epoch 048 | Val Acc: 0.2516\n",
      "Epoch 049 | Val Acc: 0.2710\n",
      "Epoch 050 | Val Acc: 0.2403\n",
      "Epoch 051 | Val Acc: 0.2742\n",
      "Epoch 052 | Val Acc: 0.2758\n",
      "Epoch 053 | Val Acc: 0.2742\n",
      "Epoch 054 | Val Acc: 0.2968\n",
      "Epoch 055 | Val Acc: 0.2548\n",
      "Epoch 056 | Val Acc: 0.2903\n",
      "Epoch 057 | Val Acc: 0.2806\n",
      "Epoch 058 | Val Acc: 0.2661\n",
      "Epoch 059 | Val Acc: 0.2516\n",
      "Epoch 060 | Val Acc: 0.2774\n",
      "Epoch 061 | Val Acc: 0.2806\n",
      "Early stopping\n",
      "Best accuracy (split 7): 0.2968\n",
      "\n",
      "===== SPLIT 8 =====\n",
      "Epoch 001 | Val Acc: 0.0258\n",
      "Epoch 002 | Val Acc: 0.0532\n",
      "Epoch 003 | Val Acc: 0.0597\n",
      "Epoch 004 | Val Acc: 0.0452\n",
      "Epoch 005 | Val Acc: 0.0548\n",
      "Epoch 006 | Val Acc: 0.0726\n",
      "Epoch 007 | Val Acc: 0.0790\n",
      "Epoch 008 | Val Acc: 0.0726\n",
      "Epoch 009 | Val Acc: 0.1081\n",
      "Epoch 010 | Val Acc: 0.1419\n",
      "Epoch 011 | Val Acc: 0.1452\n",
      "Epoch 012 | Val Acc: 0.1081\n",
      "Epoch 013 | Val Acc: 0.1129\n",
      "Epoch 014 | Val Acc: 0.1548\n",
      "Epoch 015 | Val Acc: 0.1548\n",
      "Epoch 016 | Val Acc: 0.1323\n",
      "Epoch 017 | Val Acc: 0.1629\n",
      "Epoch 018 | Val Acc: 0.1242\n",
      "Epoch 019 | Val Acc: 0.1645\n",
      "Epoch 020 | Val Acc: 0.1871\n",
      "Epoch 021 | Val Acc: 0.2016\n",
      "Epoch 022 | Val Acc: 0.1952\n",
      "Epoch 023 | Val Acc: 0.2210\n",
      "Epoch 024 | Val Acc: 0.1887\n",
      "Epoch 025 | Val Acc: 0.2081\n",
      "Epoch 026 | Val Acc: 0.2258\n",
      "Epoch 027 | Val Acc: 0.2000\n",
      "Epoch 028 | Val Acc: 0.2242\n",
      "Epoch 029 | Val Acc: 0.1758\n",
      "Epoch 030 | Val Acc: 0.2194\n",
      "Epoch 031 | Val Acc: 0.2226\n",
      "Epoch 032 | Val Acc: 0.2484\n",
      "Epoch 033 | Val Acc: 0.2548\n",
      "Epoch 034 | Val Acc: 0.2694\n",
      "Epoch 035 | Val Acc: 0.2419\n",
      "Epoch 036 | Val Acc: 0.2210\n",
      "Epoch 037 | Val Acc: 0.3081\n",
      "Epoch 038 | Val Acc: 0.2565\n",
      "Epoch 039 | Val Acc: 0.3016\n",
      "Epoch 040 | Val Acc: 0.3065\n",
      "Epoch 041 | Val Acc: 0.2694\n",
      "Epoch 042 | Val Acc: 0.2887\n",
      "Epoch 043 | Val Acc: 0.3016\n",
      "Epoch 044 | Val Acc: 0.3210\n",
      "Epoch 045 | Val Acc: 0.3355\n",
      "Epoch 046 | Val Acc: 0.2758\n",
      "Epoch 047 | Val Acc: 0.2903\n",
      "Epoch 048 | Val Acc: 0.3274\n",
      "Epoch 049 | Val Acc: 0.3339\n",
      "Epoch 050 | Val Acc: 0.2548\n",
      "Epoch 051 | Val Acc: 0.3548\n",
      "Epoch 052 | Val Acc: 0.3403\n",
      "Epoch 053 | Val Acc: 0.3710\n",
      "Epoch 054 | Val Acc: 0.3548\n",
      "Epoch 055 | Val Acc: 0.3274\n",
      "Epoch 056 | Val Acc: 0.2710\n",
      "Epoch 057 | Val Acc: 0.3419\n",
      "Epoch 058 | Val Acc: 0.2935\n",
      "Epoch 059 | Val Acc: 0.3371\n",
      "Epoch 060 | Val Acc: 0.3323\n",
      "Early stopping\n",
      "Best accuracy (split 8): 0.3710\n",
      "\n",
      "===== SPLIT 9 =====\n",
      "Epoch 001 | Val Acc: 0.0290\n",
      "Epoch 002 | Val Acc: 0.0371\n",
      "Epoch 003 | Val Acc: 0.0645\n",
      "Epoch 004 | Val Acc: 0.0774\n",
      "Epoch 005 | Val Acc: 0.0871\n",
      "Epoch 006 | Val Acc: 0.0871\n",
      "Epoch 007 | Val Acc: 0.1161\n",
      "Epoch 008 | Val Acc: 0.1419\n",
      "Epoch 009 | Val Acc: 0.1194\n",
      "Epoch 010 | Val Acc: 0.1306\n",
      "Epoch 011 | Val Acc: 0.1419\n",
      "Epoch 012 | Val Acc: 0.1371\n",
      "Epoch 013 | Val Acc: 0.1532\n",
      "Epoch 014 | Val Acc: 0.1565\n",
      "Epoch 015 | Val Acc: 0.1419\n",
      "Epoch 016 | Val Acc: 0.1581\n",
      "Epoch 017 | Val Acc: 0.1532\n",
      "Epoch 018 | Val Acc: 0.1419\n",
      "Epoch 019 | Val Acc: 0.1435\n",
      "Epoch 020 | Val Acc: 0.1500\n",
      "Epoch 021 | Val Acc: 0.2016\n",
      "Epoch 022 | Val Acc: 0.1839\n",
      "Epoch 023 | Val Acc: 0.1677\n",
      "Epoch 024 | Val Acc: 0.2000\n",
      "Epoch 025 | Val Acc: 0.1565\n",
      "Epoch 026 | Val Acc: 0.1371\n",
      "Epoch 027 | Val Acc: 0.1468\n",
      "Epoch 028 | Val Acc: 0.1903\n",
      "Early stopping\n",
      "Best accuracy (split 9): 0.2016\n",
      "\n",
      "===== SPLIT 10 =====\n",
      "Epoch 001 | Val Acc: 0.0177\n",
      "Epoch 002 | Val Acc: 0.0532\n",
      "Epoch 003 | Val Acc: 0.0823\n",
      "Epoch 004 | Val Acc: 0.1016\n",
      "Epoch 005 | Val Acc: 0.1129\n",
      "Epoch 006 | Val Acc: 0.1452\n",
      "Epoch 007 | Val Acc: 0.1161\n",
      "Epoch 008 | Val Acc: 0.1323\n",
      "Epoch 009 | Val Acc: 0.1355\n",
      "Epoch 010 | Val Acc: 0.1242\n",
      "Epoch 011 | Val Acc: 0.1758\n",
      "Epoch 012 | Val Acc: 0.1968\n",
      "Epoch 013 | Val Acc: 0.2306\n",
      "Epoch 014 | Val Acc: 0.2468\n",
      "Epoch 015 | Val Acc: 0.2629\n",
      "Epoch 016 | Val Acc: 0.2484\n",
      "Epoch 017 | Val Acc: 0.2613\n",
      "Epoch 018 | Val Acc: 0.2532\n",
      "Epoch 019 | Val Acc: 0.2758\n",
      "Epoch 020 | Val Acc: 0.2613\n",
      "Epoch 021 | Val Acc: 0.2597\n",
      "Epoch 022 | Val Acc: 0.3000\n",
      "Epoch 023 | Val Acc: 0.2806\n",
      "Epoch 024 | Val Acc: 0.2919\n",
      "Epoch 025 | Val Acc: 0.2839\n",
      "Epoch 026 | Val Acc: 0.2935\n",
      "Epoch 027 | Val Acc: 0.3274\n",
      "Epoch 028 | Val Acc: 0.3161\n",
      "Epoch 029 | Val Acc: 0.2855\n",
      "Epoch 030 | Val Acc: 0.3048\n",
      "Epoch 031 | Val Acc: 0.2871\n",
      "Epoch 032 | Val Acc: 0.3145\n",
      "Epoch 033 | Val Acc: 0.3226\n",
      "Epoch 034 | Val Acc: 0.3500\n",
      "Epoch 035 | Val Acc: 0.3371\n",
      "Epoch 036 | Val Acc: 0.3516\n",
      "Epoch 037 | Val Acc: 0.3435\n",
      "Epoch 038 | Val Acc: 0.3565\n",
      "Epoch 039 | Val Acc: 0.3500\n",
      "Epoch 040 | Val Acc: 0.3355\n",
      "Epoch 041 | Val Acc: 0.3500\n",
      "Epoch 042 | Val Acc: 0.3403\n",
      "Epoch 043 | Val Acc: 0.3774\n",
      "Epoch 044 | Val Acc: 0.3871\n",
      "Epoch 045 | Val Acc: 0.3887\n",
      "Epoch 046 | Val Acc: 0.3581\n",
      "Epoch 047 | Val Acc: 0.3887\n",
      "Epoch 048 | Val Acc: 0.4113\n",
      "Epoch 049 | Val Acc: 0.3823\n",
      "Epoch 050 | Val Acc: 0.4016\n",
      "Epoch 051 | Val Acc: 0.4210\n",
      "Epoch 052 | Val Acc: 0.4226\n",
      "Epoch 053 | Val Acc: 0.3484\n",
      "Epoch 054 | Val Acc: 0.3968\n",
      "Epoch 055 | Val Acc: 0.3919\n",
      "Epoch 056 | Val Acc: 0.4032\n",
      "Epoch 057 | Val Acc: 0.4032\n",
      "Epoch 058 | Val Acc: 0.4032\n",
      "Epoch 059 | Val Acc: 0.3968\n",
      "Early stopping\n",
      "Best accuracy (split 10): 0.4226\n",
      "\n",
      "===== SPLIT 11 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0161\n",
      "Epoch 003 | Val Acc: 0.0516\n",
      "Epoch 004 | Val Acc: 0.0823\n",
      "Epoch 005 | Val Acc: 0.0871\n",
      "Epoch 006 | Val Acc: 0.0823\n",
      "Epoch 007 | Val Acc: 0.1226\n",
      "Epoch 008 | Val Acc: 0.1194\n",
      "Epoch 009 | Val Acc: 0.1016\n",
      "Epoch 010 | Val Acc: 0.1306\n",
      "Epoch 011 | Val Acc: 0.1629\n",
      "Epoch 012 | Val Acc: 0.1629\n",
      "Epoch 013 | Val Acc: 0.1790\n",
      "Epoch 014 | Val Acc: 0.2210\n",
      "Epoch 015 | Val Acc: 0.2371\n",
      "Epoch 016 | Val Acc: 0.2435\n",
      "Epoch 017 | Val Acc: 0.2726\n",
      "Epoch 018 | Val Acc: 0.2452\n",
      "Epoch 019 | Val Acc: 0.2081\n",
      "Epoch 020 | Val Acc: 0.1952\n",
      "Epoch 021 | Val Acc: 0.2226\n",
      "Epoch 022 | Val Acc: 0.2597\n",
      "Epoch 023 | Val Acc: 0.2210\n",
      "Epoch 024 | Val Acc: 0.2532\n",
      "Early stopping\n",
      "Best accuracy (split 11): 0.2726\n",
      "\n",
      "===== SPLIT 12 =====\n",
      "Epoch 001 | Val Acc: 0.0419\n",
      "Epoch 002 | Val Acc: 0.0435\n",
      "Epoch 003 | Val Acc: 0.0774\n",
      "Epoch 004 | Val Acc: 0.1048\n",
      "Epoch 005 | Val Acc: 0.1097\n",
      "Epoch 006 | Val Acc: 0.1129\n",
      "Epoch 007 | Val Acc: 0.0726\n",
      "Epoch 008 | Val Acc: 0.1516\n",
      "Epoch 009 | Val Acc: 0.1742\n",
      "Epoch 010 | Val Acc: 0.1597\n",
      "Epoch 011 | Val Acc: 0.1710\n",
      "Epoch 012 | Val Acc: 0.1806\n",
      "Epoch 013 | Val Acc: 0.1694\n",
      "Epoch 014 | Val Acc: 0.2065\n",
      "Epoch 015 | Val Acc: 0.1694\n",
      "Epoch 016 | Val Acc: 0.2081\n",
      "Epoch 017 | Val Acc: 0.2565\n",
      "Epoch 018 | Val Acc: 0.2387\n",
      "Epoch 019 | Val Acc: 0.2661\n",
      "Epoch 020 | Val Acc: 0.2710\n",
      "Epoch 021 | Val Acc: 0.2758\n",
      "Epoch 022 | Val Acc: 0.2839\n",
      "Epoch 023 | Val Acc: 0.2871\n",
      "Epoch 024 | Val Acc: 0.3129\n",
      "Epoch 025 | Val Acc: 0.2871\n",
      "Epoch 026 | Val Acc: 0.3306\n",
      "Epoch 027 | Val Acc: 0.3258\n",
      "Epoch 028 | Val Acc: 0.2597\n",
      "Epoch 029 | Val Acc: 0.3355\n",
      "Epoch 030 | Val Acc: 0.2516\n",
      "Epoch 031 | Val Acc: 0.3129\n",
      "Epoch 032 | Val Acc: 0.3355\n",
      "Epoch 033 | Val Acc: 0.3387\n",
      "Epoch 034 | Val Acc: 0.3661\n",
      "Epoch 035 | Val Acc: 0.3581\n",
      "Epoch 036 | Val Acc: 0.3210\n",
      "Epoch 037 | Val Acc: 0.3661\n",
      "Epoch 038 | Val Acc: 0.3677\n",
      "Epoch 039 | Val Acc: 0.3581\n",
      "Epoch 040 | Val Acc: 0.3726\n",
      "Epoch 041 | Val Acc: 0.3919\n",
      "Epoch 042 | Val Acc: 0.4065\n",
      "Epoch 043 | Val Acc: 0.4145\n",
      "Epoch 044 | Val Acc: 0.3871\n",
      "Epoch 045 | Val Acc: 0.4129\n",
      "Epoch 046 | Val Acc: 0.4210\n",
      "Epoch 047 | Val Acc: 0.4194\n",
      "Epoch 048 | Val Acc: 0.4032\n",
      "Epoch 049 | Val Acc: 0.4065\n",
      "Epoch 050 | Val Acc: 0.4226\n",
      "Epoch 051 | Val Acc: 0.4258\n",
      "Epoch 052 | Val Acc: 0.4613\n",
      "Epoch 053 | Val Acc: 0.4532\n",
      "Epoch 054 | Val Acc: 0.4419\n",
      "Epoch 055 | Val Acc: 0.4032\n",
      "Epoch 056 | Val Acc: 0.4532\n",
      "Epoch 057 | Val Acc: 0.4274\n",
      "Epoch 058 | Val Acc: 0.4242\n",
      "Epoch 059 | Val Acc: 0.4081\n",
      "Early stopping\n",
      "Best accuracy (split 12): 0.4613\n",
      "\n",
      "===== SPLIT 13 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0548\n",
      "Epoch 003 | Val Acc: 0.0710\n",
      "Epoch 004 | Val Acc: 0.1403\n",
      "Epoch 005 | Val Acc: 0.1323\n",
      "Epoch 006 | Val Acc: 0.1129\n",
      "Epoch 007 | Val Acc: 0.1355\n",
      "Epoch 008 | Val Acc: 0.1177\n",
      "Epoch 009 | Val Acc: 0.1532\n",
      "Epoch 010 | Val Acc: 0.1677\n",
      "Epoch 011 | Val Acc: 0.1790\n",
      "Epoch 012 | Val Acc: 0.2048\n",
      "Epoch 013 | Val Acc: 0.2258\n",
      "Epoch 014 | Val Acc: 0.2597\n",
      "Epoch 015 | Val Acc: 0.2403\n",
      "Epoch 016 | Val Acc: 0.2806\n",
      "Epoch 017 | Val Acc: 0.3113\n",
      "Epoch 018 | Val Acc: 0.2661\n",
      "Epoch 019 | Val Acc: 0.1935\n",
      "Epoch 020 | Val Acc: 0.2935\n",
      "Epoch 021 | Val Acc: 0.3161\n",
      "Epoch 022 | Val Acc: 0.3274\n",
      "Epoch 023 | Val Acc: 0.3242\n",
      "Epoch 024 | Val Acc: 0.3403\n",
      "Epoch 025 | Val Acc: 0.1484\n",
      "Epoch 026 | Val Acc: 0.2339\n",
      "Epoch 027 | Val Acc: 0.3339\n",
      "Epoch 028 | Val Acc: 0.3500\n",
      "Epoch 029 | Val Acc: 0.3855\n",
      "Epoch 030 | Val Acc: 0.4065\n",
      "Epoch 031 | Val Acc: 0.3855\n",
      "Epoch 032 | Val Acc: 0.3565\n",
      "Epoch 033 | Val Acc: 0.3726\n",
      "Epoch 034 | Val Acc: 0.3742\n",
      "Epoch 035 | Val Acc: 0.4000\n",
      "Epoch 036 | Val Acc: 0.4194\n",
      "Epoch 037 | Val Acc: 0.4145\n",
      "Epoch 038 | Val Acc: 0.4129\n",
      "Epoch 039 | Val Acc: 0.3952\n",
      "Epoch 040 | Val Acc: 0.4145\n",
      "Epoch 041 | Val Acc: 0.4355\n",
      "Epoch 042 | Val Acc: 0.4081\n",
      "Epoch 043 | Val Acc: 0.4129\n",
      "Epoch 044 | Val Acc: 0.3935\n",
      "Epoch 045 | Val Acc: 0.4661\n",
      "Epoch 046 | Val Acc: 0.4339\n",
      "Epoch 047 | Val Acc: 0.3855\n",
      "Epoch 048 | Val Acc: 0.4548\n",
      "Epoch 049 | Val Acc: 0.4806\n",
      "Epoch 050 | Val Acc: 0.4839\n",
      "Epoch 051 | Val Acc: 0.4726\n",
      "Epoch 052 | Val Acc: 0.4629\n",
      "Epoch 053 | Val Acc: 0.3919\n",
      "Epoch 054 | Val Acc: 0.4339\n",
      "Epoch 055 | Val Acc: 0.4823\n",
      "Epoch 056 | Val Acc: 0.4565\n",
      "Epoch 057 | Val Acc: 0.5113\n",
      "Epoch 058 | Val Acc: 0.4952\n",
      "Epoch 059 | Val Acc: 0.4565\n",
      "Epoch 060 | Val Acc: 0.4887\n",
      "Epoch 061 | Val Acc: 0.5081\n",
      "Epoch 062 | Val Acc: 0.5274\n",
      "Epoch 063 | Val Acc: 0.4919\n",
      "Epoch 064 | Val Acc: 0.5145\n",
      "Epoch 065 | Val Acc: 0.5000\n",
      "Epoch 066 | Val Acc: 0.4694\n",
      "Epoch 067 | Val Acc: 0.4597\n",
      "Epoch 068 | Val Acc: 0.4823\n",
      "Epoch 069 | Val Acc: 0.4935\n",
      "Early stopping\n",
      "Best accuracy (split 13): 0.5274\n",
      "\n",
      "===== SPLIT 14 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0339\n",
      "Epoch 003 | Val Acc: 0.0242\n",
      "Epoch 004 | Val Acc: 0.0468\n",
      "Epoch 005 | Val Acc: 0.0468\n",
      "Epoch 006 | Val Acc: 0.0629\n",
      "Epoch 007 | Val Acc: 0.0532\n",
      "Epoch 008 | Val Acc: 0.0661\n",
      "Epoch 009 | Val Acc: 0.0677\n",
      "Epoch 010 | Val Acc: 0.0645\n",
      "Epoch 011 | Val Acc: 0.0790\n",
      "Epoch 012 | Val Acc: 0.0887\n",
      "Epoch 013 | Val Acc: 0.1097\n",
      "Epoch 014 | Val Acc: 0.1161\n",
      "Epoch 015 | Val Acc: 0.1177\n",
      "Epoch 016 | Val Acc: 0.1194\n",
      "Epoch 017 | Val Acc: 0.0952\n",
      "Epoch 018 | Val Acc: 0.1177\n",
      "Epoch 019 | Val Acc: 0.1516\n",
      "Epoch 020 | Val Acc: 0.1113\n",
      "Epoch 021 | Val Acc: 0.1419\n",
      "Epoch 022 | Val Acc: 0.1242\n",
      "Epoch 023 | Val Acc: 0.1355\n",
      "Epoch 024 | Val Acc: 0.1403\n",
      "Epoch 025 | Val Acc: 0.1758\n",
      "Epoch 026 | Val Acc: 0.1323\n",
      "Epoch 027 | Val Acc: 0.1726\n",
      "Epoch 028 | Val Acc: 0.1774\n",
      "Epoch 029 | Val Acc: 0.1613\n",
      "Epoch 030 | Val Acc: 0.1581\n",
      "Epoch 031 | Val Acc: 0.1548\n",
      "Epoch 032 | Val Acc: 0.1403\n",
      "Epoch 033 | Val Acc: 0.1355\n",
      "Epoch 034 | Val Acc: 0.1532\n",
      "Epoch 035 | Val Acc: 0.1710\n",
      "Early stopping\n",
      "Best accuracy (split 14): 0.1774\n",
      "\n",
      "===== SPLIT 15 =====\n",
      "Epoch 001 | Val Acc: 0.0194\n",
      "Epoch 002 | Val Acc: 0.0613\n",
      "Epoch 003 | Val Acc: 0.0548\n",
      "Epoch 004 | Val Acc: 0.0661\n",
      "Epoch 005 | Val Acc: 0.0387\n",
      "Epoch 006 | Val Acc: 0.0839\n",
      "Epoch 007 | Val Acc: 0.0726\n",
      "Epoch 008 | Val Acc: 0.0710\n",
      "Epoch 009 | Val Acc: 0.0903\n",
      "Epoch 010 | Val Acc: 0.1065\n",
      "Epoch 011 | Val Acc: 0.1032\n",
      "Epoch 012 | Val Acc: 0.1065\n",
      "Epoch 013 | Val Acc: 0.1371\n",
      "Epoch 014 | Val Acc: 0.1500\n",
      "Epoch 015 | Val Acc: 0.1726\n",
      "Epoch 016 | Val Acc: 0.1952\n",
      "Epoch 017 | Val Acc: 0.2145\n",
      "Epoch 018 | Val Acc: 0.1790\n",
      "Epoch 019 | Val Acc: 0.2000\n",
      "Epoch 020 | Val Acc: 0.2065\n",
      "Epoch 021 | Val Acc: 0.2113\n",
      "Epoch 022 | Val Acc: 0.1984\n",
      "Epoch 023 | Val Acc: 0.2097\n",
      "Epoch 024 | Val Acc: 0.2516\n",
      "Epoch 025 | Val Acc: 0.2016\n",
      "Epoch 026 | Val Acc: 0.2048\n",
      "Epoch 027 | Val Acc: 0.2661\n",
      "Epoch 028 | Val Acc: 0.2516\n",
      "Epoch 029 | Val Acc: 0.2548\n",
      "Epoch 030 | Val Acc: 0.2823\n",
      "Epoch 031 | Val Acc: 0.2758\n",
      "Epoch 032 | Val Acc: 0.2839\n",
      "Epoch 033 | Val Acc: 0.2710\n",
      "Epoch 034 | Val Acc: 0.2919\n",
      "Epoch 035 | Val Acc: 0.3065\n",
      "Epoch 036 | Val Acc: 0.3194\n",
      "Epoch 037 | Val Acc: 0.3452\n",
      "Epoch 038 | Val Acc: 0.3016\n",
      "Epoch 039 | Val Acc: 0.3177\n",
      "Epoch 040 | Val Acc: 0.3194\n",
      "Epoch 041 | Val Acc: 0.3145\n",
      "Epoch 042 | Val Acc: 0.3613\n",
      "Epoch 043 | Val Acc: 0.3145\n",
      "Epoch 044 | Val Acc: 0.2984\n",
      "Epoch 045 | Val Acc: 0.3355\n",
      "Epoch 046 | Val Acc: 0.2871\n",
      "Epoch 047 | Val Acc: 0.3645\n",
      "Epoch 048 | Val Acc: 0.3677\n",
      "Epoch 049 | Val Acc: 0.3629\n",
      "Epoch 050 | Val Acc: 0.3887\n",
      "Epoch 051 | Val Acc: 0.3742\n",
      "Epoch 052 | Val Acc: 0.3806\n",
      "Epoch 053 | Val Acc: 0.3823\n",
      "Epoch 054 | Val Acc: 0.3629\n",
      "Epoch 055 | Val Acc: 0.3887\n",
      "Epoch 056 | Val Acc: 0.3661\n",
      "Epoch 057 | Val Acc: 0.3645\n",
      "Early stopping\n",
      "Best accuracy (split 15): 0.3887\n",
      "\n",
      "===== SPLIT 16 =====\n",
      "Epoch 001 | Val Acc: 0.0226\n",
      "Epoch 002 | Val Acc: 0.0419\n",
      "Epoch 003 | Val Acc: 0.0903\n",
      "Epoch 004 | Val Acc: 0.0984\n",
      "Epoch 005 | Val Acc: 0.1403\n",
      "Epoch 006 | Val Acc: 0.1661\n",
      "Epoch 007 | Val Acc: 0.1613\n",
      "Epoch 008 | Val Acc: 0.1774\n",
      "Epoch 009 | Val Acc: 0.2032\n",
      "Epoch 010 | Val Acc: 0.2355\n",
      "Epoch 011 | Val Acc: 0.2145\n",
      "Epoch 012 | Val Acc: 0.2226\n",
      "Epoch 013 | Val Acc: 0.2306\n",
      "Epoch 014 | Val Acc: 0.2952\n",
      "Epoch 015 | Val Acc: 0.2871\n",
      "Epoch 016 | Val Acc: 0.3097\n",
      "Epoch 017 | Val Acc: 0.2839\n",
      "Epoch 018 | Val Acc: 0.3194\n",
      "Epoch 019 | Val Acc: 0.3339\n",
      "Epoch 020 | Val Acc: 0.3129\n",
      "Epoch 021 | Val Acc: 0.3419\n",
      "Epoch 022 | Val Acc: 0.3419\n",
      "Epoch 023 | Val Acc: 0.3323\n",
      "Epoch 024 | Val Acc: 0.3629\n",
      "Epoch 025 | Val Acc: 0.3516\n",
      "Epoch 026 | Val Acc: 0.3081\n",
      "Epoch 027 | Val Acc: 0.3565\n",
      "Epoch 028 | Val Acc: 0.3694\n",
      "Epoch 029 | Val Acc: 0.3661\n",
      "Epoch 030 | Val Acc: 0.3871\n",
      "Epoch 031 | Val Acc: 0.3758\n",
      "Epoch 032 | Val Acc: 0.3758\n",
      "Epoch 033 | Val Acc: 0.3952\n",
      "Epoch 034 | Val Acc: 0.3790\n",
      "Epoch 035 | Val Acc: 0.3935\n",
      "Epoch 036 | Val Acc: 0.2435\n",
      "Epoch 037 | Val Acc: 0.3484\n",
      "Epoch 038 | Val Acc: 0.3726\n",
      "Epoch 039 | Val Acc: 0.3661\n",
      "Epoch 040 | Val Acc: 0.3726\n",
      "Early stopping\n",
      "Best accuracy (split 16): 0.3952\n",
      "\n",
      "===== SPLIT 17 =====\n",
      "Epoch 001 | Val Acc: 0.0258\n",
      "Epoch 002 | Val Acc: 0.0387\n",
      "Epoch 003 | Val Acc: 0.1016\n",
      "Epoch 004 | Val Acc: 0.1274\n",
      "Epoch 005 | Val Acc: 0.1323\n",
      "Epoch 006 | Val Acc: 0.1661\n",
      "Epoch 007 | Val Acc: 0.1806\n",
      "Epoch 008 | Val Acc: 0.1387\n",
      "Epoch 009 | Val Acc: 0.1613\n",
      "Epoch 010 | Val Acc: 0.1871\n",
      "Epoch 011 | Val Acc: 0.1597\n",
      "Epoch 012 | Val Acc: 0.1710\n",
      "Epoch 013 | Val Acc: 0.2258\n",
      "Epoch 014 | Val Acc: 0.2419\n",
      "Epoch 015 | Val Acc: 0.2581\n",
      "Epoch 016 | Val Acc: 0.2274\n",
      "Epoch 017 | Val Acc: 0.2210\n",
      "Epoch 018 | Val Acc: 0.2113\n",
      "Epoch 019 | Val Acc: 0.2677\n",
      "Epoch 020 | Val Acc: 0.2468\n",
      "Epoch 021 | Val Acc: 0.2306\n",
      "Epoch 022 | Val Acc: 0.2452\n",
      "Epoch 023 | Val Acc: 0.2516\n",
      "Epoch 024 | Val Acc: 0.2855\n",
      "Epoch 025 | Val Acc: 0.2839\n",
      "Epoch 026 | Val Acc: 0.2500\n",
      "Epoch 027 | Val Acc: 0.3048\n",
      "Epoch 028 | Val Acc: 0.3210\n",
      "Epoch 029 | Val Acc: 0.2629\n",
      "Epoch 030 | Val Acc: 0.2565\n",
      "Epoch 031 | Val Acc: 0.3177\n",
      "Epoch 032 | Val Acc: 0.3000\n",
      "Epoch 033 | Val Acc: 0.3000\n",
      "Epoch 034 | Val Acc: 0.3258\n",
      "Epoch 035 | Val Acc: 0.3081\n",
      "Epoch 036 | Val Acc: 0.3177\n",
      "Epoch 037 | Val Acc: 0.3758\n",
      "Epoch 038 | Val Acc: 0.3806\n",
      "Epoch 039 | Val Acc: 0.4113\n",
      "Epoch 040 | Val Acc: 0.4032\n",
      "Epoch 041 | Val Acc: 0.3903\n",
      "Epoch 042 | Val Acc: 0.3903\n",
      "Epoch 043 | Val Acc: 0.3935\n",
      "Epoch 044 | Val Acc: 0.4032\n",
      "Epoch 045 | Val Acc: 0.4339\n",
      "Epoch 046 | Val Acc: 0.4065\n",
      "Epoch 047 | Val Acc: 0.4306\n",
      "Epoch 048 | Val Acc: 0.4339\n",
      "Epoch 049 | Val Acc: 0.4081\n",
      "Epoch 050 | Val Acc: 0.3952\n",
      "Epoch 051 | Val Acc: 0.3355\n",
      "Epoch 052 | Val Acc: 0.4371\n",
      "Epoch 053 | Val Acc: 0.4274\n",
      "Epoch 054 | Val Acc: 0.4403\n",
      "Epoch 055 | Val Acc: 0.4484\n",
      "Epoch 056 | Val Acc: 0.4274\n",
      "Epoch 057 | Val Acc: 0.4274\n",
      "Epoch 058 | Val Acc: 0.4161\n",
      "Epoch 059 | Val Acc: 0.4516\n",
      "Epoch 060 | Val Acc: 0.4532\n",
      "Epoch 061 | Val Acc: 0.4565\n",
      "Epoch 062 | Val Acc: 0.4565\n",
      "Epoch 063 | Val Acc: 0.4532\n",
      "Epoch 064 | Val Acc: 0.4597\n",
      "Epoch 065 | Val Acc: 0.4774\n",
      "Epoch 066 | Val Acc: 0.5016\n",
      "Epoch 067 | Val Acc: 0.4935\n",
      "Epoch 068 | Val Acc: 0.4613\n",
      "Epoch 069 | Val Acc: 0.4952\n",
      "Epoch 070 | Val Acc: 0.5226\n",
      "Epoch 071 | Val Acc: 0.5016\n",
      "Epoch 072 | Val Acc: 0.4935\n",
      "Epoch 073 | Val Acc: 0.5274\n",
      "Epoch 074 | Val Acc: 0.4952\n",
      "Epoch 075 | Val Acc: 0.4968\n",
      "Epoch 076 | Val Acc: 0.4726\n",
      "Epoch 077 | Val Acc: 0.5048\n",
      "Epoch 078 | Val Acc: 0.5097\n",
      "Epoch 079 | Val Acc: 0.5145\n",
      "Epoch 080 | Val Acc: 0.5435\n",
      "Epoch 081 | Val Acc: 0.5258\n",
      "Epoch 082 | Val Acc: 0.5242\n",
      "Epoch 083 | Val Acc: 0.5419\n",
      "Epoch 084 | Val Acc: 0.5065\n",
      "Epoch 085 | Val Acc: 0.4935\n",
      "Epoch 086 | Val Acc: 0.5000\n",
      "Epoch 087 | Val Acc: 0.5081\n",
      "Early stopping\n",
      "Best accuracy (split 17): 0.5435\n",
      "\n",
      "===== SPLIT 18 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0290\n",
      "Epoch 003 | Val Acc: 0.0645\n",
      "Epoch 004 | Val Acc: 0.1016\n",
      "Epoch 005 | Val Acc: 0.1194\n",
      "Epoch 006 | Val Acc: 0.1645\n",
      "Epoch 007 | Val Acc: 0.1032\n",
      "Epoch 008 | Val Acc: 0.1306\n",
      "Epoch 009 | Val Acc: 0.1984\n",
      "Epoch 010 | Val Acc: 0.1952\n",
      "Epoch 011 | Val Acc: 0.2113\n",
      "Epoch 012 | Val Acc: 0.2290\n",
      "Epoch 013 | Val Acc: 0.2419\n",
      "Epoch 014 | Val Acc: 0.2274\n",
      "Epoch 015 | Val Acc: 0.2435\n",
      "Epoch 016 | Val Acc: 0.2242\n",
      "Epoch 017 | Val Acc: 0.2581\n",
      "Epoch 018 | Val Acc: 0.2452\n",
      "Epoch 019 | Val Acc: 0.2581\n",
      "Epoch 020 | Val Acc: 0.2581\n",
      "Epoch 021 | Val Acc: 0.2661\n",
      "Epoch 022 | Val Acc: 0.2661\n",
      "Epoch 023 | Val Acc: 0.2855\n",
      "Epoch 024 | Val Acc: 0.3468\n",
      "Epoch 025 | Val Acc: 0.3097\n",
      "Epoch 026 | Val Acc: 0.2468\n",
      "Epoch 027 | Val Acc: 0.2306\n",
      "Epoch 028 | Val Acc: 0.2742\n",
      "Epoch 029 | Val Acc: 0.3548\n",
      "Epoch 030 | Val Acc: 0.3323\n",
      "Epoch 031 | Val Acc: 0.2903\n",
      "Epoch 032 | Val Acc: 0.2839\n",
      "Epoch 033 | Val Acc: 0.3048\n",
      "Epoch 034 | Val Acc: 0.3435\n",
      "Epoch 035 | Val Acc: 0.3419\n",
      "Epoch 036 | Val Acc: 0.2952\n",
      "Early stopping\n",
      "Best accuracy (split 18): 0.3548\n",
      "\n",
      "===== SPLIT 19 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.0419\n",
      "Epoch 003 | Val Acc: 0.0532\n",
      "Epoch 004 | Val Acc: 0.0710\n",
      "Epoch 005 | Val Acc: 0.0742\n",
      "Epoch 006 | Val Acc: 0.0871\n",
      "Epoch 007 | Val Acc: 0.1032\n",
      "Epoch 008 | Val Acc: 0.1129\n",
      "Epoch 009 | Val Acc: 0.1387\n",
      "Epoch 010 | Val Acc: 0.1016\n",
      "Epoch 011 | Val Acc: 0.1500\n",
      "Epoch 012 | Val Acc: 0.1613\n",
      "Epoch 013 | Val Acc: 0.1855\n",
      "Epoch 014 | Val Acc: 0.1758\n",
      "Epoch 015 | Val Acc: 0.2081\n",
      "Epoch 016 | Val Acc: 0.1903\n",
      "Epoch 017 | Val Acc: 0.2113\n",
      "Epoch 018 | Val Acc: 0.2065\n",
      "Epoch 019 | Val Acc: 0.2113\n",
      "Epoch 020 | Val Acc: 0.1694\n",
      "Epoch 021 | Val Acc: 0.2548\n",
      "Epoch 022 | Val Acc: 0.2306\n",
      "Epoch 023 | Val Acc: 0.2532\n",
      "Epoch 024 | Val Acc: 0.2484\n",
      "Epoch 025 | Val Acc: 0.2371\n",
      "Epoch 026 | Val Acc: 0.2258\n",
      "Epoch 027 | Val Acc: 0.2403\n",
      "Epoch 028 | Val Acc: 0.2468\n",
      "Early stopping\n",
      "Best accuracy (split 19): 0.2548\n",
      "\n",
      "FINAL AVERAGE ACCURACY (BiLSTM): 0.36808149405772495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        X = np.load(x_path)                  # (N, T, C)\n",
    "        y = np.load(y_path)                  # (N, num_classes)\n",
    "\n",
    "        # per-sample, per-channel normalization\n",
    "        for i in range(X.shape[0]):\n",
    "            for c in range(X.shape[2]):\n",
    "                X[i, :, c] = (X[i, :, c] - X[i, :, c].mean()) / (X[i, :, c].std() + 1e-8)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.argmax(y, axis=1), dtype=torch.long)\n",
    "        self.num_classes = y.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ---------------- BiLSTM Encoder ----------------\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_dim=64, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        out, _ = self.lstm(x)          # (B, T, 2*hidden_dim)\n",
    "        emb = out.mean(dim=1)          # temporal mean pooling \n",
    "        return emb                     # (B, 2*hidden_dim)\n",
    "\n",
    "# ---------------- Full Model ----------------\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = BiLSTMEncoder(\n",
    "            input_dim=6,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=1,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.classifier = nn.Linear(2 * hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.encoder(x)\n",
    "        logits = self.classifier(emb)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Early Stopping ----------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "            self.best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ---------------- Training ----------------\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   epochs=300, patience=7):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # -------- Evaluation --------\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = model(x).argmax(dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ---------------- Main Loop ----------------\n",
    "BASE = \"models/Data/Data/62_classes/UserIndependent\"\n",
    "accs = []\n",
    "\n",
    "for split in range(1, 20):\n",
    "    print(f\"\\n===== SPLIT {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "    model = BiLSTMModel(\n",
    "        num_classes=train_ds.num_classes,\n",
    "        hidden_dim=64\n",
    "    ).to(device)\n",
    "\n",
    "    acc = train_and_eval(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader\n",
    "    )\n",
    "\n",
    "    accs.append(acc)\n",
    "    print(f\"Best accuracy (split {split}): {acc:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY (BiLSTM):\", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9304f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "===== SPLIT 1 =====\n",
      "Epoch 001 | Val Acc: 0.0419\n",
      "Epoch 002 | Val Acc: 0.0387\n",
      "Epoch 003 | Val Acc: 0.0597\n",
      "Epoch 004 | Val Acc: 0.0823\n",
      "Epoch 005 | Val Acc: 0.1032\n",
      "Epoch 006 | Val Acc: 0.1000\n",
      "Epoch 007 | Val Acc: 0.1097\n",
      "Epoch 008 | Val Acc: 0.1097\n",
      "Epoch 009 | Val Acc: 0.1081\n",
      "Epoch 010 | Val Acc: 0.1226\n",
      "Epoch 011 | Val Acc: 0.1468\n",
      "Epoch 012 | Val Acc: 0.1387\n",
      "Epoch 013 | Val Acc: 0.1661\n",
      "Epoch 014 | Val Acc: 0.1645\n",
      "Epoch 015 | Val Acc: 0.1677\n",
      "Epoch 016 | Val Acc: 0.1790\n",
      "Epoch 017 | Val Acc: 0.1742\n",
      "Epoch 018 | Val Acc: 0.1710\n",
      "Epoch 019 | Val Acc: 0.1839\n",
      "Epoch 020 | Val Acc: 0.2016\n",
      "Epoch 021 | Val Acc: 0.1984\n",
      "Epoch 022 | Val Acc: 0.2129\n",
      "Epoch 023 | Val Acc: 0.2258\n",
      "Epoch 024 | Val Acc: 0.2145\n",
      "Epoch 025 | Val Acc: 0.2177\n",
      "Epoch 026 | Val Acc: 0.2290\n",
      "Epoch 027 | Val Acc: 0.2371\n",
      "Epoch 028 | Val Acc: 0.2387\n",
      "Epoch 029 | Val Acc: 0.2355\n",
      "Epoch 030 | Val Acc: 0.2581\n",
      "Epoch 031 | Val Acc: 0.2532\n",
      "Epoch 032 | Val Acc: 0.2661\n",
      "Epoch 033 | Val Acc: 0.2484\n",
      "Epoch 034 | Val Acc: 0.2823\n",
      "Epoch 035 | Val Acc: 0.2839\n",
      "Epoch 036 | Val Acc: 0.2742\n",
      "Epoch 037 | Val Acc: 0.2919\n",
      "Epoch 038 | Val Acc: 0.2419\n",
      "Epoch 039 | Val Acc: 0.2677\n",
      "Epoch 040 | Val Acc: 0.2806\n",
      "Epoch 041 | Val Acc: 0.2903\n",
      "Epoch 042 | Val Acc: 0.2726\n",
      "Epoch 043 | Val Acc: 0.2919\n",
      "Epoch 044 | Val Acc: 0.2645\n",
      "Early stopping\n",
      "Best accuracy (split 1): 0.2919\n",
      "\n",
      "===== SPLIT 2 =====\n",
      "Epoch 001 | Val Acc: 0.0145\n",
      "Epoch 002 | Val Acc: 0.0242\n",
      "Epoch 003 | Val Acc: 0.0435\n",
      "Epoch 004 | Val Acc: 0.0290\n",
      "Epoch 005 | Val Acc: 0.0532\n",
      "Epoch 006 | Val Acc: 0.0452\n",
      "Epoch 007 | Val Acc: 0.0435\n",
      "Epoch 008 | Val Acc: 0.0435\n",
      "Epoch 009 | Val Acc: 0.0597\n",
      "Epoch 010 | Val Acc: 0.0758\n",
      "Epoch 011 | Val Acc: 0.0742\n",
      "Epoch 012 | Val Acc: 0.0645\n",
      "Epoch 013 | Val Acc: 0.0758\n",
      "Epoch 014 | Val Acc: 0.0855\n",
      "Epoch 015 | Val Acc: 0.0726\n",
      "Epoch 016 | Val Acc: 0.0871\n",
      "Epoch 017 | Val Acc: 0.1016\n",
      "Epoch 018 | Val Acc: 0.1048\n",
      "Epoch 019 | Val Acc: 0.1242\n",
      "Epoch 020 | Val Acc: 0.1290\n",
      "Epoch 021 | Val Acc: 0.1032\n",
      "Epoch 022 | Val Acc: 0.1129\n",
      "Epoch 023 | Val Acc: 0.1145\n",
      "Epoch 024 | Val Acc: 0.1161\n",
      "Epoch 025 | Val Acc: 0.1371\n",
      "Epoch 026 | Val Acc: 0.1032\n",
      "Epoch 027 | Val Acc: 0.1371\n",
      "Epoch 028 | Val Acc: 0.1468\n",
      "Epoch 029 | Val Acc: 0.1323\n",
      "Epoch 030 | Val Acc: 0.1355\n",
      "Epoch 031 | Val Acc: 0.1403\n",
      "Epoch 032 | Val Acc: 0.1323\n",
      "Epoch 033 | Val Acc: 0.1419\n",
      "Epoch 034 | Val Acc: 0.1629\n",
      "Epoch 035 | Val Acc: 0.1613\n",
      "Epoch 036 | Val Acc: 0.1726\n",
      "Epoch 037 | Val Acc: 0.1823\n",
      "Epoch 038 | Val Acc: 0.1742\n",
      "Epoch 039 | Val Acc: 0.1565\n",
      "Epoch 040 | Val Acc: 0.2000\n",
      "Epoch 041 | Val Acc: 0.1855\n",
      "Epoch 042 | Val Acc: 0.1597\n",
      "Epoch 043 | Val Acc: 0.1661\n",
      "Epoch 044 | Val Acc: 0.1952\n",
      "Epoch 045 | Val Acc: 0.1758\n",
      "Epoch 046 | Val Acc: 0.1903\n",
      "Epoch 047 | Val Acc: 0.2081\n",
      "Epoch 048 | Val Acc: 0.2129\n",
      "Epoch 049 | Val Acc: 0.2016\n",
      "Epoch 050 | Val Acc: 0.2032\n",
      "Epoch 051 | Val Acc: 0.2274\n",
      "Epoch 052 | Val Acc: 0.2081\n",
      "Epoch 053 | Val Acc: 0.2113\n",
      "Epoch 054 | Val Acc: 0.2177\n",
      "Epoch 055 | Val Acc: 0.2145\n",
      "Epoch 056 | Val Acc: 0.2274\n",
      "Epoch 057 | Val Acc: 0.2194\n",
      "Epoch 058 | Val Acc: 0.1903\n",
      "Early stopping\n",
      "Best accuracy (split 2): 0.2274\n",
      "\n",
      "===== SPLIT 3 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.0403\n",
      "Epoch 003 | Val Acc: 0.0435\n",
      "Epoch 004 | Val Acc: 0.0694\n",
      "Epoch 005 | Val Acc: 0.0645\n",
      "Epoch 006 | Val Acc: 0.0742\n",
      "Epoch 007 | Val Acc: 0.0823\n",
      "Epoch 008 | Val Acc: 0.0565\n",
      "Epoch 009 | Val Acc: 0.0952\n",
      "Epoch 010 | Val Acc: 0.0806\n",
      "Epoch 011 | Val Acc: 0.1274\n",
      "Epoch 012 | Val Acc: 0.1210\n",
      "Epoch 013 | Val Acc: 0.1226\n",
      "Epoch 014 | Val Acc: 0.1129\n",
      "Epoch 015 | Val Acc: 0.1258\n",
      "Epoch 016 | Val Acc: 0.1290\n",
      "Epoch 017 | Val Acc: 0.1355\n",
      "Epoch 018 | Val Acc: 0.1145\n",
      "Epoch 019 | Val Acc: 0.1403\n",
      "Epoch 020 | Val Acc: 0.1355\n",
      "Epoch 021 | Val Acc: 0.1306\n",
      "Epoch 022 | Val Acc: 0.1355\n",
      "Epoch 023 | Val Acc: 0.1694\n",
      "Epoch 024 | Val Acc: 0.1484\n",
      "Epoch 025 | Val Acc: 0.1565\n",
      "Epoch 026 | Val Acc: 0.1677\n",
      "Epoch 027 | Val Acc: 0.1742\n",
      "Epoch 028 | Val Acc: 0.1694\n",
      "Epoch 029 | Val Acc: 0.1823\n",
      "Epoch 030 | Val Acc: 0.1613\n",
      "Epoch 031 | Val Acc: 0.1565\n",
      "Epoch 032 | Val Acc: 0.1500\n",
      "Epoch 033 | Val Acc: 0.1726\n",
      "Epoch 034 | Val Acc: 0.1742\n",
      "Epoch 035 | Val Acc: 0.1613\n",
      "Epoch 036 | Val Acc: 0.2113\n",
      "Epoch 037 | Val Acc: 0.1790\n",
      "Epoch 038 | Val Acc: 0.1694\n",
      "Epoch 039 | Val Acc: 0.1871\n",
      "Epoch 040 | Val Acc: 0.1710\n",
      "Epoch 041 | Val Acc: 0.1855\n",
      "Epoch 042 | Val Acc: 0.1919\n",
      "Epoch 043 | Val Acc: 0.1919\n",
      "Early stopping\n",
      "Best accuracy (split 3): 0.2113\n",
      "\n",
      "===== SPLIT 4 =====\n",
      "Epoch 001 | Val Acc: 0.0226\n",
      "Epoch 002 | Val Acc: 0.0435\n",
      "Epoch 003 | Val Acc: 0.0468\n",
      "Epoch 004 | Val Acc: 0.0452\n",
      "Epoch 005 | Val Acc: 0.0613\n",
      "Epoch 006 | Val Acc: 0.0548\n",
      "Epoch 007 | Val Acc: 0.0484\n",
      "Epoch 008 | Val Acc: 0.0484\n",
      "Epoch 009 | Val Acc: 0.0661\n",
      "Epoch 010 | Val Acc: 0.0532\n",
      "Epoch 011 | Val Acc: 0.0645\n",
      "Epoch 012 | Val Acc: 0.0548\n",
      "Epoch 013 | Val Acc: 0.0661\n",
      "Epoch 014 | Val Acc: 0.0452\n",
      "Epoch 015 | Val Acc: 0.0403\n",
      "Epoch 016 | Val Acc: 0.0565\n",
      "Early stopping\n",
      "Best accuracy (split 4): 0.0661\n",
      "\n",
      "===== SPLIT 5 =====\n",
      "Epoch 001 | Val Acc: 0.0339\n",
      "Epoch 002 | Val Acc: 0.0371\n",
      "Epoch 003 | Val Acc: 0.0403\n",
      "Epoch 004 | Val Acc: 0.0645\n",
      "Epoch 005 | Val Acc: 0.0742\n",
      "Epoch 006 | Val Acc: 0.0758\n",
      "Epoch 007 | Val Acc: 0.0710\n",
      "Epoch 008 | Val Acc: 0.0774\n",
      "Epoch 009 | Val Acc: 0.0871\n",
      "Epoch 010 | Val Acc: 0.0871\n",
      "Epoch 011 | Val Acc: 0.1145\n",
      "Epoch 012 | Val Acc: 0.0855\n",
      "Epoch 013 | Val Acc: 0.0952\n",
      "Epoch 014 | Val Acc: 0.1065\n",
      "Epoch 015 | Val Acc: 0.1097\n",
      "Epoch 016 | Val Acc: 0.0984\n",
      "Epoch 017 | Val Acc: 0.1194\n",
      "Epoch 018 | Val Acc: 0.1016\n",
      "Epoch 019 | Val Acc: 0.0968\n",
      "Epoch 020 | Val Acc: 0.1081\n",
      "Epoch 021 | Val Acc: 0.0952\n",
      "Epoch 022 | Val Acc: 0.1065\n",
      "Epoch 023 | Val Acc: 0.0839\n",
      "Epoch 024 | Val Acc: 0.0887\n",
      "Early stopping\n",
      "Best accuracy (split 5): 0.1194\n",
      "\n",
      "===== SPLIT 6 =====\n",
      "Epoch 001 | Val Acc: 0.0306\n",
      "Epoch 002 | Val Acc: 0.0306\n",
      "Epoch 003 | Val Acc: 0.0323\n",
      "Epoch 004 | Val Acc: 0.0516\n",
      "Epoch 005 | Val Acc: 0.0565\n",
      "Epoch 006 | Val Acc: 0.0565\n",
      "Epoch 007 | Val Acc: 0.0532\n",
      "Epoch 008 | Val Acc: 0.0597\n",
      "Epoch 009 | Val Acc: 0.0484\n",
      "Epoch 010 | Val Acc: 0.0613\n",
      "Epoch 011 | Val Acc: 0.0694\n",
      "Epoch 012 | Val Acc: 0.0661\n",
      "Epoch 013 | Val Acc: 0.0823\n",
      "Epoch 014 | Val Acc: 0.0919\n",
      "Epoch 015 | Val Acc: 0.0597\n",
      "Epoch 016 | Val Acc: 0.0855\n",
      "Epoch 017 | Val Acc: 0.0935\n",
      "Epoch 018 | Val Acc: 0.1000\n",
      "Epoch 019 | Val Acc: 0.1113\n",
      "Epoch 020 | Val Acc: 0.1081\n",
      "Epoch 021 | Val Acc: 0.1258\n",
      "Epoch 022 | Val Acc: 0.1258\n",
      "Epoch 023 | Val Acc: 0.1177\n",
      "Epoch 024 | Val Acc: 0.1032\n",
      "Epoch 025 | Val Acc: 0.1032\n",
      "Epoch 026 | Val Acc: 0.1306\n",
      "Epoch 027 | Val Acc: 0.1145\n",
      "Epoch 028 | Val Acc: 0.1452\n",
      "Epoch 029 | Val Acc: 0.1177\n",
      "Epoch 030 | Val Acc: 0.1306\n",
      "Epoch 031 | Val Acc: 0.1387\n",
      "Epoch 032 | Val Acc: 0.1661\n",
      "Epoch 033 | Val Acc: 0.1484\n",
      "Epoch 034 | Val Acc: 0.1516\n",
      "Epoch 035 | Val Acc: 0.1532\n",
      "Epoch 036 | Val Acc: 0.1500\n",
      "Epoch 037 | Val Acc: 0.1532\n",
      "Epoch 038 | Val Acc: 0.1581\n",
      "Epoch 039 | Val Acc: 0.1548\n",
      "Early stopping\n",
      "Best accuracy (split 6): 0.1661\n",
      "\n",
      "===== SPLIT 7 =====\n",
      "Epoch 001 | Val Acc: 0.0323\n",
      "Epoch 002 | Val Acc: 0.0355\n",
      "Epoch 003 | Val Acc: 0.0516\n",
      "Epoch 004 | Val Acc: 0.0468\n",
      "Epoch 005 | Val Acc: 0.0532\n",
      "Epoch 006 | Val Acc: 0.0532\n",
      "Epoch 007 | Val Acc: 0.0597\n",
      "Epoch 008 | Val Acc: 0.0581\n",
      "Epoch 009 | Val Acc: 0.0645\n",
      "Epoch 010 | Val Acc: 0.0903\n",
      "Epoch 011 | Val Acc: 0.0952\n",
      "Epoch 012 | Val Acc: 0.1177\n",
      "Epoch 013 | Val Acc: 0.0903\n",
      "Epoch 014 | Val Acc: 0.0726\n",
      "Epoch 015 | Val Acc: 0.0919\n",
      "Epoch 016 | Val Acc: 0.0839\n",
      "Epoch 017 | Val Acc: 0.0871\n",
      "Epoch 018 | Val Acc: 0.0919\n",
      "Epoch 019 | Val Acc: 0.1032\n",
      "Early stopping\n",
      "Best accuracy (split 7): 0.1177\n",
      "\n",
      "===== SPLIT 8 =====\n",
      "Epoch 001 | Val Acc: 0.0177\n",
      "Epoch 002 | Val Acc: 0.0242\n",
      "Epoch 003 | Val Acc: 0.0226\n",
      "Epoch 004 | Val Acc: 0.0323\n",
      "Epoch 005 | Val Acc: 0.0274\n",
      "Epoch 006 | Val Acc: 0.0532\n",
      "Epoch 007 | Val Acc: 0.0484\n",
      "Epoch 008 | Val Acc: 0.0597\n",
      "Epoch 009 | Val Acc: 0.0758\n",
      "Epoch 010 | Val Acc: 0.0694\n",
      "Epoch 011 | Val Acc: 0.0516\n",
      "Epoch 012 | Val Acc: 0.0597\n",
      "Epoch 013 | Val Acc: 0.0581\n",
      "Epoch 014 | Val Acc: 0.0790\n",
      "Epoch 015 | Val Acc: 0.0742\n",
      "Epoch 016 | Val Acc: 0.0645\n",
      "Epoch 017 | Val Acc: 0.0710\n",
      "Epoch 018 | Val Acc: 0.0597\n",
      "Epoch 019 | Val Acc: 0.0742\n",
      "Epoch 020 | Val Acc: 0.0806\n",
      "Epoch 021 | Val Acc: 0.0726\n",
      "Epoch 022 | Val Acc: 0.0645\n",
      "Epoch 023 | Val Acc: 0.0500\n",
      "Epoch 024 | Val Acc: 0.0823\n",
      "Epoch 025 | Val Acc: 0.0774\n",
      "Epoch 026 | Val Acc: 0.0935\n",
      "Epoch 027 | Val Acc: 0.0710\n",
      "Epoch 028 | Val Acc: 0.0968\n",
      "Epoch 029 | Val Acc: 0.0903\n",
      "Epoch 030 | Val Acc: 0.0806\n",
      "Epoch 031 | Val Acc: 0.0952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 154\u001b[39m\n\u001b[32m    150\u001b[39m test_loader = DataLoader(test_ds, batch_size=\u001b[32m64\u001b[39m)\n\u001b[32m    152\u001b[39m model = BiLSTMModel(num_classes=train_ds.num_classes).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m acc = \u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m accs.append(acc)\n\u001b[32m    157\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest accuracy (split \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mtrain_and_eval\u001b[39m\u001b[34m(model, train_loader, test_loader, epochs, patience)\u001b[39m\n\u001b[32m    108\u001b[39m     optimizer.zero_grad()\n\u001b[32m    109\u001b[39m     loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# ---- Evaluation ----\u001b[39;00m\n\u001b[32m    113\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\winterIntern project\\.venv_gpu\\Lib\\site-packages\\torch\\optim\\adam.py:669\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[32m    665\u001b[39m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.compiler.is_compiling() \u001b[38;5;129;01mand\u001b[39;00m device_state_steps[\u001b[32m0\u001b[39m].is_cpu:\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_add_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_state_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    673\u001b[39m     torch._foreach_add_(device_state_steps, \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ===================== Dataset =====================\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path, downsample=4):\n",
    "        X = np.load(x_path)          # (N, T, C)\n",
    "        y = np.load(y_path)          # (N, num_classes)\n",
    "\n",
    "        #  downsample time axis (CRITICAL for BiLSTM)\n",
    "        X = X[:, ::downsample, :]\n",
    "\n",
    "        #  NO per-sample normalization (very important)\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.argmax(y, axis=1), dtype=torch.long)\n",
    "        self.num_classes = y.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ===================== BiLSTM Encoder =====================\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=6, proj_dim=32, hidden_dim=64):\n",
    "        super().__init__()\n",
    "\n",
    "        #  input projection (stabilizes learning)\n",
    "        self.input_proj = nn.Linear(input_dim, proj_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=proj_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, 6)\n",
    "        x = self.input_proj(x)           # (B, T, 32)\n",
    "        out, _ = self.lstm(x)            # (B, T, 128)\n",
    "        emb = out.mean(dim=1)            # temporal mean pooling \n",
    "        return emb                       # (B, 128)\n",
    "\n",
    "# ===================== Full Model =====================\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = BiLSTMEncoder()\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.encoder(x)\n",
    "        logits = self.classifier(emb)\n",
    "        return logits\n",
    "\n",
    "# ===================== Early Stopping =====================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "            self.best_state = {\n",
    "                k: v.detach().cpu().clone()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ===================== Training =====================\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   epochs=300, patience=7):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ---- Evaluation ----\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                preds = model(x).argmax(dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ===================== Main Loop =====================\n",
    "BASE = \"models/Data/Data/62_classes/UserIndependent\"\n",
    "accs = []\n",
    "\n",
    "for split in range(1, 20):\n",
    "    print(f\"\\n===== SPLIT {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    #  smaller batch size for LSTM\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "    model = BiLSTMModel(num_classes=train_ds.num_classes).to(device)\n",
    "\n",
    "    acc = train_and_eval(model, train_loader, test_loader)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"Best accuracy (split {split}): {acc:.4f}\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY (PATCHED BiLSTM):\", np.mean(accs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (winter_gpu)",
   "language": "python",
   "name": "winter_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
