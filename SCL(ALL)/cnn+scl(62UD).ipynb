{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21f9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "===== SPLIT 1 =====\n",
      "Epoch 01 | Val Acc: 0.0331\n",
      "Epoch 02 | Val Acc: 0.2548\n",
      "Epoch 03 | Val Acc: 0.4024\n",
      "Epoch 04 | Val Acc: 0.5000\n",
      "Epoch 05 | Val Acc: 0.5976\n",
      "Epoch 06 | Val Acc: 0.6266\n",
      "Epoch 07 | Val Acc: 0.6460\n",
      "Epoch 08 | Val Acc: 0.6984\n",
      "Epoch 09 | Val Acc: 0.7185\n",
      "Epoch 10 | Val Acc: 0.7024\n",
      "Epoch 11 | Val Acc: 0.7105\n",
      "Epoch 12 | Val Acc: 0.7427\n",
      "Epoch 13 | Val Acc: 0.7589\n",
      "Epoch 14 | Val Acc: 0.7589\n",
      "Epoch 15 | Val Acc: 0.7476\n",
      "Epoch 16 | Val Acc: 0.7605\n",
      "Epoch 17 | Val Acc: 0.7645\n",
      "Epoch 18 | Val Acc: 0.7766\n",
      "Epoch 19 | Val Acc: 0.7839\n",
      "Epoch 20 | Val Acc: 0.7742\n",
      "Epoch 21 | Val Acc: 0.7782\n",
      "Epoch 22 | Val Acc: 0.7710\n",
      "Epoch 23 | Val Acc: 0.7581\n",
      "Epoch 24 | Val Acc: 0.7694\n",
      "Epoch 25 | Val Acc: 0.7790\n",
      "Epoch 26 | Val Acc: 0.7782\n",
      "Epoch 27 | Val Acc: 0.7815\n",
      "Epoch 28 | Val Acc: 0.7798\n",
      "Epoch 29 | Val Acc: 0.7895\n",
      "Epoch 30 | Val Acc: 0.7677\n",
      "Epoch 31 | Val Acc: 0.7790\n",
      "Epoch 32 | Val Acc: 0.7790\n",
      "Epoch 33 | Val Acc: 0.7766\n",
      "Epoch 34 | Val Acc: 0.7782\n",
      "Epoch 35 | Val Acc: 0.7782\n",
      "Epoch 36 | Val Acc: 0.7815\n",
      "Epoch 37 | Val Acc: 0.7960\n",
      "Epoch 38 | Val Acc: 0.7863\n",
      "Epoch 39 | Val Acc: 0.7823\n",
      "Epoch 40 | Val Acc: 0.7927\n",
      "Epoch 41 | Val Acc: 0.7895\n",
      "Epoch 42 | Val Acc: 0.7718\n",
      "Epoch 43 | Val Acc: 0.7823\n",
      "Epoch 44 | Val Acc: 0.7879\n",
      "Epoch 45 | Val Acc: 0.7323\n",
      "Epoch 46 | Val Acc: 0.7589\n",
      "Epoch 47 | Val Acc: 0.7758\n",
      "Early stopping\n",
      "Split 1 Accuracy: 0.7960\n",
      "\n",
      "===== SPLIT 2 =====\n",
      "Epoch 01 | Val Acc: 0.0161\n",
      "Epoch 02 | Val Acc: 0.1427\n",
      "Epoch 03 | Val Acc: 0.3355\n",
      "Epoch 04 | Val Acc: 0.4266\n",
      "Epoch 05 | Val Acc: 0.5306\n",
      "Epoch 06 | Val Acc: 0.5968\n",
      "Epoch 07 | Val Acc: 0.5919\n",
      "Epoch 08 | Val Acc: 0.6960\n",
      "Epoch 09 | Val Acc: 0.7452\n",
      "Epoch 10 | Val Acc: 0.7387\n",
      "Epoch 11 | Val Acc: 0.7395\n",
      "Epoch 12 | Val Acc: 0.7581\n",
      "Epoch 13 | Val Acc: 0.7750\n",
      "Epoch 14 | Val Acc: 0.7935\n",
      "Epoch 15 | Val Acc: 0.7984\n",
      "Epoch 16 | Val Acc: 0.8000\n",
      "Epoch 17 | Val Acc: 0.8040\n",
      "Epoch 18 | Val Acc: 0.8105\n",
      "Epoch 19 | Val Acc: 0.8161\n",
      "Epoch 20 | Val Acc: 0.8097\n",
      "Epoch 21 | Val Acc: 0.7984\n",
      "Epoch 22 | Val Acc: 0.8185\n",
      "Epoch 23 | Val Acc: 0.8177\n",
      "Epoch 24 | Val Acc: 0.8000\n",
      "Epoch 25 | Val Acc: 0.8266\n",
      "Epoch 26 | Val Acc: 0.8129\n",
      "Epoch 27 | Val Acc: 0.8089\n",
      "Epoch 28 | Val Acc: 0.8177\n",
      "Epoch 29 | Val Acc: 0.8210\n",
      "Epoch 30 | Val Acc: 0.8226\n",
      "Epoch 31 | Val Acc: 0.8258\n",
      "Epoch 32 | Val Acc: 0.8242\n",
      "Epoch 33 | Val Acc: 0.8347\n",
      "Epoch 34 | Val Acc: 0.8427\n",
      "Epoch 35 | Val Acc: 0.8419\n",
      "Epoch 36 | Val Acc: 0.8339\n",
      "Epoch 37 | Val Acc: 0.8484\n",
      "Epoch 38 | Val Acc: 0.8444\n",
      "Epoch 39 | Val Acc: 0.8540\n",
      "Epoch 40 | Val Acc: 0.8476\n",
      "Epoch 41 | Val Acc: 0.8468\n",
      "Epoch 42 | Val Acc: 0.8411\n",
      "Epoch 43 | Val Acc: 0.8435\n",
      "Epoch 44 | Val Acc: 0.8315\n",
      "Epoch 45 | Val Acc: 0.8218\n",
      "Epoch 46 | Val Acc: 0.8306\n",
      "Epoch 47 | Val Acc: 0.8363\n",
      "Epoch 48 | Val Acc: 0.8411\n",
      "Epoch 49 | Val Acc: 0.8516\n",
      "Early stopping\n",
      "Split 2 Accuracy: 0.8540\n",
      "\n",
      "===== SPLIT 3 =====\n",
      "Epoch 01 | Val Acc: 0.0548\n",
      "Epoch 02 | Val Acc: 0.1863\n",
      "Epoch 03 | Val Acc: 0.4460\n",
      "Epoch 04 | Val Acc: 0.5565\n",
      "Epoch 05 | Val Acc: 0.5855\n",
      "Epoch 06 | Val Acc: 0.6444\n",
      "Epoch 07 | Val Acc: 0.6992\n",
      "Epoch 08 | Val Acc: 0.7274\n",
      "Epoch 09 | Val Acc: 0.7347\n",
      "Epoch 10 | Val Acc: 0.7677\n",
      "Epoch 11 | Val Acc: 0.7734\n",
      "Epoch 12 | Val Acc: 0.7653\n",
      "Epoch 13 | Val Acc: 0.7903\n",
      "Epoch 14 | Val Acc: 0.7750\n",
      "Epoch 15 | Val Acc: 0.7984\n",
      "Epoch 16 | Val Acc: 0.7847\n",
      "Epoch 17 | Val Acc: 0.8274\n",
      "Epoch 18 | Val Acc: 0.8210\n",
      "Epoch 19 | Val Acc: 0.8298\n",
      "Epoch 20 | Val Acc: 0.8266\n",
      "Epoch 21 | Val Acc: 0.8347\n",
      "Epoch 22 | Val Acc: 0.8371\n",
      "Epoch 23 | Val Acc: 0.8379\n",
      "Epoch 24 | Val Acc: 0.8427\n",
      "Epoch 25 | Val Acc: 0.8460\n",
      "Epoch 26 | Val Acc: 0.8403\n",
      "Epoch 27 | Val Acc: 0.8573\n",
      "Epoch 28 | Val Acc: 0.8500\n",
      "Epoch 29 | Val Acc: 0.8548\n",
      "Epoch 30 | Val Acc: 0.8524\n",
      "Epoch 31 | Val Acc: 0.8524\n",
      "Epoch 32 | Val Acc: 0.8435\n",
      "Epoch 33 | Val Acc: 0.8516\n",
      "Epoch 34 | Val Acc: 0.8548\n",
      "Epoch 35 | Val Acc: 0.8500\n",
      "Epoch 36 | Val Acc: 0.8645\n",
      "Epoch 37 | Val Acc: 0.8484\n",
      "Epoch 38 | Val Acc: 0.8427\n",
      "Epoch 39 | Val Acc: 0.8613\n",
      "Epoch 40 | Val Acc: 0.8573\n",
      "Epoch 41 | Val Acc: 0.8629\n",
      "Epoch 42 | Val Acc: 0.8653\n",
      "Epoch 43 | Val Acc: 0.8581\n",
      "Epoch 44 | Val Acc: 0.8524\n",
      "Epoch 45 | Val Acc: 0.8452\n",
      "Epoch 46 | Val Acc: 0.8218\n",
      "Epoch 47 | Val Acc: 0.8242\n",
      "Epoch 48 | Val Acc: 0.8403\n",
      "Epoch 49 | Val Acc: 0.8371\n",
      "Epoch 50 | Val Acc: 0.8581\n",
      "Split 3 Accuracy: 0.8653\n",
      "\n",
      "===== SPLIT 4 =====\n",
      "Epoch 01 | Val Acc: 0.0492\n",
      "Epoch 02 | Val Acc: 0.2355\n",
      "Epoch 03 | Val Acc: 0.5137\n",
      "Epoch 04 | Val Acc: 0.5758\n",
      "Epoch 05 | Val Acc: 0.6718\n",
      "Epoch 06 | Val Acc: 0.7218\n",
      "Epoch 07 | Val Acc: 0.7589\n",
      "Epoch 08 | Val Acc: 0.7653\n",
      "Epoch 09 | Val Acc: 0.7645\n",
      "Epoch 10 | Val Acc: 0.8032\n",
      "Epoch 11 | Val Acc: 0.8024\n",
      "Epoch 12 | Val Acc: 0.8468\n",
      "Epoch 13 | Val Acc: 0.8250\n",
      "Epoch 14 | Val Acc: 0.8403\n",
      "Epoch 15 | Val Acc: 0.8355\n",
      "Epoch 16 | Val Acc: 0.8484\n",
      "Epoch 17 | Val Acc: 0.8452\n",
      "Epoch 18 | Val Acc: 0.8629\n",
      "Epoch 19 | Val Acc: 0.8605\n",
      "Epoch 20 | Val Acc: 0.8637\n",
      "Epoch 21 | Val Acc: 0.8766\n",
      "Epoch 22 | Val Acc: 0.8758\n",
      "Epoch 23 | Val Acc: 0.8605\n",
      "Epoch 24 | Val Acc: 0.8855\n",
      "Epoch 25 | Val Acc: 0.8685\n",
      "Epoch 26 | Val Acc: 0.8766\n",
      "Epoch 27 | Val Acc: 0.8782\n",
      "Epoch 28 | Val Acc: 0.8831\n",
      "Epoch 29 | Val Acc: 0.8806\n",
      "Epoch 30 | Val Acc: 0.8815\n",
      "Epoch 31 | Val Acc: 0.8815\n",
      "Epoch 32 | Val Acc: 0.8903\n",
      "Epoch 33 | Val Acc: 0.8839\n",
      "Epoch 34 | Val Acc: 0.8839\n",
      "Epoch 35 | Val Acc: 0.8911\n",
      "Epoch 36 | Val Acc: 0.8815\n",
      "Epoch 37 | Val Acc: 0.8871\n",
      "Epoch 38 | Val Acc: 0.8952\n",
      "Epoch 39 | Val Acc: 0.8919\n",
      "Epoch 40 | Val Acc: 0.8823\n",
      "Epoch 41 | Val Acc: 0.8669\n",
      "Epoch 42 | Val Acc: 0.8919\n",
      "Epoch 43 | Val Acc: 0.8887\n",
      "Epoch 44 | Val Acc: 0.8927\n",
      "Epoch 45 | Val Acc: 0.8903\n",
      "Epoch 46 | Val Acc: 0.8734\n",
      "Epoch 47 | Val Acc: 0.8403\n",
      "Epoch 48 | Val Acc: 0.8395\n",
      "Early stopping\n",
      "Split 4 Accuracy: 0.8952\n",
      "\n",
      "===== SPLIT 5 =====\n",
      "Epoch 01 | Val Acc: 0.0548\n",
      "Epoch 02 | Val Acc: 0.2371\n",
      "Epoch 03 | Val Acc: 0.4290\n",
      "Epoch 04 | Val Acc: 0.5863\n",
      "Epoch 05 | Val Acc: 0.6331\n",
      "Epoch 06 | Val Acc: 0.6565\n",
      "Epoch 07 | Val Acc: 0.7250\n",
      "Epoch 08 | Val Acc: 0.7524\n",
      "Epoch 09 | Val Acc: 0.7782\n",
      "Epoch 10 | Val Acc: 0.8016\n",
      "Epoch 11 | Val Acc: 0.8056\n",
      "Epoch 12 | Val Acc: 0.8298\n",
      "Epoch 13 | Val Acc: 0.8331\n",
      "Epoch 14 | Val Acc: 0.8435\n",
      "Epoch 15 | Val Acc: 0.8194\n",
      "Epoch 16 | Val Acc: 0.8363\n",
      "Epoch 17 | Val Acc: 0.8581\n",
      "Epoch 18 | Val Acc: 0.8476\n",
      "Epoch 19 | Val Acc: 0.8548\n",
      "Epoch 20 | Val Acc: 0.8718\n",
      "Epoch 21 | Val Acc: 0.8581\n",
      "Epoch 22 | Val Acc: 0.8734\n",
      "Epoch 23 | Val Acc: 0.8573\n",
      "Epoch 24 | Val Acc: 0.8766\n",
      "Epoch 25 | Val Acc: 0.8702\n",
      "Epoch 26 | Val Acc: 0.8782\n",
      "Epoch 27 | Val Acc: 0.8766\n",
      "Epoch 28 | Val Acc: 0.8750\n",
      "Epoch 29 | Val Acc: 0.8758\n",
      "Epoch 30 | Val Acc: 0.8774\n",
      "Epoch 31 | Val Acc: 0.8694\n",
      "Epoch 32 | Val Acc: 0.8839\n",
      "Epoch 33 | Val Acc: 0.8645\n",
      "Epoch 34 | Val Acc: 0.8750\n",
      "Epoch 35 | Val Acc: 0.8863\n",
      "Epoch 36 | Val Acc: 0.8726\n",
      "Epoch 37 | Val Acc: 0.8766\n",
      "Epoch 38 | Val Acc: 0.8823\n",
      "Epoch 39 | Val Acc: 0.8815\n",
      "Epoch 40 | Val Acc: 0.8815\n",
      "Epoch 41 | Val Acc: 0.8839\n",
      "Epoch 42 | Val Acc: 0.8758\n",
      "Epoch 43 | Val Acc: 0.8427\n",
      "Epoch 44 | Val Acc: 0.8339\n",
      "Epoch 45 | Val Acc: 0.8637\n",
      "Early stopping\n",
      "Split 5 Accuracy: 0.8863\n",
      "\n",
      "===== SPLIT 6 =====\n",
      "Epoch 01 | Val Acc: 0.0306\n",
      "Epoch 02 | Val Acc: 0.1871\n",
      "Epoch 03 | Val Acc: 0.3944\n",
      "Epoch 04 | Val Acc: 0.5621\n",
      "Epoch 05 | Val Acc: 0.6073\n",
      "Epoch 06 | Val Acc: 0.6500\n",
      "Epoch 07 | Val Acc: 0.6847\n",
      "Epoch 08 | Val Acc: 0.7379\n",
      "Epoch 09 | Val Acc: 0.7677\n",
      "Epoch 10 | Val Acc: 0.7782\n",
      "Epoch 11 | Val Acc: 0.7968\n",
      "Epoch 12 | Val Acc: 0.7790\n",
      "Epoch 13 | Val Acc: 0.7863\n",
      "Epoch 14 | Val Acc: 0.8339\n",
      "Epoch 15 | Val Acc: 0.8282\n",
      "Epoch 16 | Val Acc: 0.8323\n",
      "Epoch 17 | Val Acc: 0.8395\n",
      "Epoch 18 | Val Acc: 0.8395\n",
      "Epoch 19 | Val Acc: 0.8460\n",
      "Epoch 20 | Val Acc: 0.8419\n",
      "Epoch 21 | Val Acc: 0.8379\n",
      "Epoch 22 | Val Acc: 0.8548\n",
      "Epoch 23 | Val Acc: 0.8565\n",
      "Epoch 24 | Val Acc: 0.8532\n",
      "Epoch 25 | Val Acc: 0.8516\n",
      "Epoch 26 | Val Acc: 0.8726\n",
      "Epoch 27 | Val Acc: 0.8532\n",
      "Epoch 28 | Val Acc: 0.8573\n",
      "Epoch 29 | Val Acc: 0.8694\n",
      "Epoch 30 | Val Acc: 0.8661\n",
      "Epoch 31 | Val Acc: 0.8629\n",
      "Epoch 32 | Val Acc: 0.8653\n",
      "Epoch 33 | Val Acc: 0.8702\n",
      "Epoch 34 | Val Acc: 0.8589\n",
      "Epoch 35 | Val Acc: 0.8847\n",
      "Epoch 36 | Val Acc: 0.8621\n",
      "Epoch 37 | Val Acc: 0.8677\n",
      "Epoch 38 | Val Acc: 0.8653\n",
      "Epoch 39 | Val Acc: 0.8847\n",
      "Epoch 40 | Val Acc: 0.8750\n",
      "Epoch 41 | Val Acc: 0.8718\n",
      "Epoch 42 | Val Acc: 0.8831\n",
      "Epoch 43 | Val Acc: 0.8831\n",
      "Epoch 44 | Val Acc: 0.8637\n",
      "Epoch 45 | Val Acc: 0.8782\n",
      "Early stopping\n",
      "Split 6 Accuracy: 0.8847\n",
      "\n",
      "===== SPLIT 7 =====\n",
      "Epoch 01 | Val Acc: 0.0452\n",
      "Epoch 02 | Val Acc: 0.2758\n",
      "Epoch 03 | Val Acc: 0.4492\n",
      "Epoch 04 | Val Acc: 0.5806\n",
      "Epoch 05 | Val Acc: 0.6645\n",
      "Epoch 06 | Val Acc: 0.6879\n",
      "Epoch 07 | Val Acc: 0.7371\n",
      "Epoch 08 | Val Acc: 0.7694\n",
      "Epoch 09 | Val Acc: 0.7726\n",
      "Epoch 10 | Val Acc: 0.8024\n",
      "Epoch 11 | Val Acc: 0.8000\n",
      "Epoch 12 | Val Acc: 0.8161\n",
      "Epoch 13 | Val Acc: 0.7935\n",
      "Epoch 14 | Val Acc: 0.8177\n",
      "Epoch 15 | Val Acc: 0.8435\n",
      "Epoch 16 | Val Acc: 0.8419\n",
      "Epoch 17 | Val Acc: 0.8371\n",
      "Epoch 18 | Val Acc: 0.8589\n",
      "Epoch 19 | Val Acc: 0.8427\n",
      "Epoch 20 | Val Acc: 0.8597\n",
      "Epoch 21 | Val Acc: 0.8621\n",
      "Epoch 22 | Val Acc: 0.8573\n",
      "Epoch 23 | Val Acc: 0.8573\n",
      "Epoch 24 | Val Acc: 0.8532\n",
      "Epoch 25 | Val Acc: 0.8581\n",
      "Epoch 26 | Val Acc: 0.8565\n",
      "Epoch 27 | Val Acc: 0.8734\n",
      "Epoch 28 | Val Acc: 0.8774\n",
      "Epoch 29 | Val Acc: 0.8782\n",
      "Epoch 30 | Val Acc: 0.8863\n",
      "Epoch 31 | Val Acc: 0.8774\n",
      "Epoch 32 | Val Acc: 0.8806\n",
      "Epoch 33 | Val Acc: 0.8847\n",
      "Epoch 34 | Val Acc: 0.8669\n",
      "Epoch 35 | Val Acc: 0.8758\n",
      "Epoch 36 | Val Acc: 0.8839\n",
      "Epoch 37 | Val Acc: 0.8863\n",
      "Epoch 38 | Val Acc: 0.8863\n",
      "Epoch 39 | Val Acc: 0.8863\n",
      "Epoch 40 | Val Acc: 0.8831\n",
      "Early stopping\n",
      "Split 7 Accuracy: 0.8863\n",
      "\n",
      "===== SPLIT 8 =====\n",
      "Epoch 01 | Val Acc: 0.0669\n",
      "Epoch 02 | Val Acc: 0.3347\n",
      "Epoch 03 | Val Acc: 0.5484\n",
      "Epoch 04 | Val Acc: 0.6097\n",
      "Epoch 05 | Val Acc: 0.6702\n",
      "Epoch 06 | Val Acc: 0.7185\n",
      "Epoch 07 | Val Acc: 0.7702\n",
      "Epoch 08 | Val Acc: 0.7734\n",
      "Epoch 09 | Val Acc: 0.7532\n",
      "Epoch 10 | Val Acc: 0.8000\n",
      "Epoch 11 | Val Acc: 0.8129\n",
      "Epoch 12 | Val Acc: 0.8024\n",
      "Epoch 13 | Val Acc: 0.8169\n",
      "Epoch 14 | Val Acc: 0.8347\n",
      "Epoch 15 | Val Acc: 0.8024\n",
      "Epoch 16 | Val Acc: 0.8427\n",
      "Epoch 17 | Val Acc: 0.8290\n",
      "Epoch 18 | Val Acc: 0.8476\n",
      "Epoch 19 | Val Acc: 0.8339\n",
      "Epoch 20 | Val Acc: 0.8452\n",
      "Epoch 21 | Val Acc: 0.8476\n",
      "Epoch 22 | Val Acc: 0.8460\n",
      "Epoch 23 | Val Acc: 0.8645\n",
      "Epoch 24 | Val Acc: 0.8492\n",
      "Epoch 25 | Val Acc: 0.8613\n",
      "Epoch 26 | Val Acc: 0.8540\n",
      "Epoch 27 | Val Acc: 0.8556\n",
      "Epoch 28 | Val Acc: 0.8589\n",
      "Epoch 29 | Val Acc: 0.8347\n",
      "Epoch 30 | Val Acc: 0.8411\n",
      "Epoch 31 | Val Acc: 0.8661\n",
      "Epoch 32 | Val Acc: 0.8589\n",
      "Epoch 33 | Val Acc: 0.8613\n",
      "Epoch 34 | Val Acc: 0.8605\n",
      "Epoch 35 | Val Acc: 0.8621\n",
      "Epoch 36 | Val Acc: 0.8653\n",
      "Epoch 37 | Val Acc: 0.8694\n",
      "Epoch 38 | Val Acc: 0.8653\n",
      "Epoch 39 | Val Acc: 0.8750\n",
      "Epoch 40 | Val Acc: 0.8694\n",
      "Epoch 41 | Val Acc: 0.8621\n",
      "Epoch 42 | Val Acc: 0.8605\n",
      "Epoch 43 | Val Acc: 0.8694\n",
      "Epoch 44 | Val Acc: 0.8581\n",
      "Epoch 45 | Val Acc: 0.8661\n",
      "Epoch 46 | Val Acc: 0.7855\n",
      "Epoch 47 | Val Acc: 0.8177\n",
      "Epoch 48 | Val Acc: 0.8403\n",
      "Epoch 49 | Val Acc: 0.8637\n",
      "Early stopping\n",
      "Split 8 Accuracy: 0.8750\n",
      "\n",
      "===== SPLIT 9 =====\n",
      "Epoch 01 | Val Acc: 0.0710\n",
      "Epoch 02 | Val Acc: 0.3089\n",
      "Epoch 03 | Val Acc: 0.5226\n",
      "Epoch 04 | Val Acc: 0.5758\n",
      "Epoch 05 | Val Acc: 0.6476\n",
      "Epoch 06 | Val Acc: 0.7073\n",
      "Epoch 07 | Val Acc: 0.7492\n",
      "Epoch 08 | Val Acc: 0.7710\n",
      "Epoch 09 | Val Acc: 0.7903\n",
      "Epoch 10 | Val Acc: 0.7903\n",
      "Epoch 11 | Val Acc: 0.8000\n",
      "Epoch 12 | Val Acc: 0.8145\n",
      "Epoch 13 | Val Acc: 0.8274\n",
      "Epoch 14 | Val Acc: 0.8306\n",
      "Epoch 15 | Val Acc: 0.8532\n",
      "Epoch 16 | Val Acc: 0.8387\n",
      "Epoch 17 | Val Acc: 0.8492\n",
      "Epoch 18 | Val Acc: 0.8476\n",
      "Epoch 19 | Val Acc: 0.8452\n",
      "Epoch 20 | Val Acc: 0.8605\n",
      "Epoch 21 | Val Acc: 0.8185\n",
      "Epoch 22 | Val Acc: 0.8556\n",
      "Epoch 23 | Val Acc: 0.8637\n",
      "Epoch 24 | Val Acc: 0.8621\n",
      "Epoch 25 | Val Acc: 0.8798\n",
      "Epoch 26 | Val Acc: 0.8702\n",
      "Epoch 27 | Val Acc: 0.8669\n",
      "Epoch 28 | Val Acc: 0.8798\n",
      "Epoch 29 | Val Acc: 0.8782\n",
      "Epoch 30 | Val Acc: 0.8621\n",
      "Epoch 31 | Val Acc: 0.8774\n",
      "Epoch 32 | Val Acc: 0.8629\n",
      "Epoch 33 | Val Acc: 0.8718\n",
      "Epoch 34 | Val Acc: 0.8863\n",
      "Epoch 35 | Val Acc: 0.8887\n",
      "Epoch 36 | Val Acc: 0.8887\n",
      "Epoch 37 | Val Acc: 0.8976\n",
      "Epoch 38 | Val Acc: 0.8782\n",
      "Epoch 39 | Val Acc: 0.8790\n",
      "Epoch 40 | Val Acc: 0.8863\n",
      "Epoch 41 | Val Acc: 0.8677\n",
      "Epoch 42 | Val Acc: 0.8435\n",
      "Epoch 43 | Val Acc: 0.8524\n",
      "Epoch 44 | Val Acc: 0.8661\n",
      "Epoch 45 | Val Acc: 0.8863\n",
      "Epoch 46 | Val Acc: 0.8960\n",
      "Epoch 47 | Val Acc: 0.8919\n",
      "Early stopping\n",
      "Split 9 Accuracy: 0.8976\n",
      "\n",
      "===== SPLIT 10 =====\n",
      "Epoch 01 | Val Acc: 0.0419\n",
      "Epoch 02 | Val Acc: 0.1911\n",
      "Epoch 03 | Val Acc: 0.4218\n",
      "Epoch 04 | Val Acc: 0.5524\n",
      "Epoch 05 | Val Acc: 0.6065\n",
      "Epoch 06 | Val Acc: 0.6815\n",
      "Epoch 07 | Val Acc: 0.6468\n",
      "Epoch 08 | Val Acc: 0.7258\n",
      "Epoch 09 | Val Acc: 0.7653\n",
      "Epoch 10 | Val Acc: 0.7653\n",
      "Epoch 11 | Val Acc: 0.7589\n",
      "Epoch 12 | Val Acc: 0.7726\n",
      "Epoch 13 | Val Acc: 0.7855\n",
      "Epoch 14 | Val Acc: 0.7871\n",
      "Epoch 15 | Val Acc: 0.7960\n",
      "Epoch 16 | Val Acc: 0.8177\n",
      "Epoch 17 | Val Acc: 0.8153\n",
      "Epoch 18 | Val Acc: 0.8298\n",
      "Epoch 19 | Val Acc: 0.8177\n",
      "Epoch 20 | Val Acc: 0.8290\n",
      "Epoch 21 | Val Acc: 0.8339\n",
      "Epoch 22 | Val Acc: 0.8403\n",
      "Epoch 23 | Val Acc: 0.8403\n",
      "Epoch 24 | Val Acc: 0.8379\n",
      "Epoch 25 | Val Acc: 0.8427\n",
      "Epoch 26 | Val Acc: 0.8476\n",
      "Epoch 27 | Val Acc: 0.8452\n",
      "Epoch 28 | Val Acc: 0.8500\n",
      "Epoch 29 | Val Acc: 0.8565\n",
      "Epoch 30 | Val Acc: 0.8371\n",
      "Epoch 31 | Val Acc: 0.8427\n",
      "Epoch 32 | Val Acc: 0.8339\n",
      "Epoch 33 | Val Acc: 0.8476\n",
      "Epoch 34 | Val Acc: 0.8492\n",
      "Epoch 35 | Val Acc: 0.8621\n",
      "Epoch 36 | Val Acc: 0.8581\n",
      "Epoch 37 | Val Acc: 0.8548\n",
      "Epoch 38 | Val Acc: 0.8573\n",
      "Epoch 39 | Val Acc: 0.8508\n",
      "Epoch 40 | Val Acc: 0.8532\n",
      "Epoch 41 | Val Acc: 0.8500\n",
      "Epoch 42 | Val Acc: 0.8468\n",
      "Epoch 43 | Val Acc: 0.8492\n",
      "Epoch 44 | Val Acc: 0.8540\n",
      "Epoch 45 | Val Acc: 0.8589\n",
      "Early stopping\n",
      "Split 10 Accuracy: 0.8621\n",
      "\n",
      "FINAL AVERAGE ACCURACY: 0.8702419354838709\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from pytorch_metric_learning.losses import SupConLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        self.X = np.load(x_path)\n",
    "        self.y = np.argmax(np.load(y_path), axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        )\n",
    "\n",
    "# ---------------- ENCODER ----------------\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)      # (B, C, T)\n",
    "        x = self.features(x).squeeze(-1)\n",
    "        z = self.fc(x)\n",
    "        return z                   # (B, emb_dim)\n",
    "\n",
    "# ---------------- CLASSIFIER ----------------\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, emb_dim=256, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)\n",
    "\n",
    "# ---------------- FULL MODEL ----------------\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, emb_dim=256, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder(emb_dim)\n",
    "        self.classifier = Classifier(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.classifier(z)\n",
    "        return z, logits\n",
    "\n",
    "# ---------------- EARLY STOPPING ----------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ---------------- TRAIN + EVAL ----------------\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   supcon_loss, alpha=1.0,\n",
    "                   epochs=500, patience=10):\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            z, logits = model(x)\n",
    "\n",
    "            z_norm = F.normalize(z, dim=1)   # ðŸ”¥ REQUIRED for SupCon\n",
    "\n",
    "            loss = ce_loss(logits, y) + alpha * supcon_loss(z_norm, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ---- EVAL ----\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, logits = model(x)\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:02d} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ---------------- MAIN LOOP ----------------\n",
    "BASE = \"models/Data/Data/62_classes/UserDependenet\"\n",
    "supcon_loss = SupConLoss(temperature=0.1)\n",
    "\n",
    "all_accs = []\n",
    "\n",
    "for split in range(1, 11):\n",
    "    print(f\"\\n===== SPLIT {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = FullModel(emb_dim=256, num_classes=62).to(device)\n",
    "\n",
    "    acc = train_and_eval(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        supcon_loss,\n",
    "        alpha=1.0,\n",
    "        epochs=500,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    print(f\"Split {split} Accuracy: {acc:.4f}\")\n",
    "    all_accs.append(acc)\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY:\", np.mean(all_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dff3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "===== SPLIT 1 =====\n",
      "Epoch 001 | Val Acc: 0.0218\n",
      "Epoch 002 | Val Acc: 0.0605\n",
      "Epoch 003 | Val Acc: 0.1000\n",
      "Epoch 004 | Val Acc: 0.1282\n",
      "Epoch 005 | Val Acc: 0.1589\n",
      "Epoch 006 | Val Acc: 0.1992\n",
      "Epoch 007 | Val Acc: 0.2710\n",
      "Epoch 008 | Val Acc: 0.2839\n",
      "Epoch 009 | Val Acc: 0.3847\n",
      "Epoch 010 | Val Acc: 0.4298\n",
      "Epoch 011 | Val Acc: 0.4677\n",
      "Epoch 012 | Val Acc: 0.5185\n",
      "Epoch 013 | Val Acc: 0.6024\n",
      "Epoch 014 | Val Acc: 0.6048\n",
      "Epoch 015 | Val Acc: 0.6226\n",
      "Epoch 016 | Val Acc: 0.6492\n",
      "Epoch 017 | Val Acc: 0.6492\n",
      "Epoch 018 | Val Acc: 0.6669\n",
      "Epoch 019 | Val Acc: 0.6532\n",
      "Epoch 020 | Val Acc: 0.6863\n",
      "Epoch 021 | Val Acc: 0.6790\n",
      "Epoch 022 | Val Acc: 0.6798\n",
      "Epoch 023 | Val Acc: 0.6887\n",
      "Epoch 024 | Val Acc: 0.6855\n",
      "Epoch 025 | Val Acc: 0.6710\n",
      "Epoch 026 | Val Acc: 0.7048\n",
      "Epoch 027 | Val Acc: 0.7000\n",
      "Epoch 028 | Val Acc: 0.7097\n",
      "Epoch 029 | Val Acc: 0.7097\n",
      "Epoch 030 | Val Acc: 0.7113\n",
      "Epoch 031 | Val Acc: 0.7089\n",
      "Epoch 032 | Val Acc: 0.6944\n",
      "Epoch 033 | Val Acc: 0.7218\n",
      "Epoch 034 | Val Acc: 0.7177\n",
      "Epoch 035 | Val Acc: 0.7226\n",
      "Epoch 036 | Val Acc: 0.6992\n",
      "Epoch 037 | Val Acc: 0.7081\n",
      "Epoch 038 | Val Acc: 0.6927\n",
      "Epoch 039 | Val Acc: 0.7137\n",
      "Epoch 040 | Val Acc: 0.7161\n",
      "Epoch 041 | Val Acc: 0.7250\n",
      "Epoch 042 | Val Acc: 0.7218\n",
      "Epoch 043 | Val Acc: 0.7250\n",
      "Epoch 044 | Val Acc: 0.7226\n",
      "Epoch 045 | Val Acc: 0.7379\n",
      "Epoch 046 | Val Acc: 0.7194\n",
      "Epoch 047 | Val Acc: 0.7258\n",
      "Epoch 048 | Val Acc: 0.7185\n",
      "Epoch 049 | Val Acc: 0.7153\n",
      "Epoch 050 | Val Acc: 0.7008\n",
      "Epoch 051 | Val Acc: 0.7129\n",
      "Epoch 052 | Val Acc: 0.7315\n",
      "Epoch 053 | Val Acc: 0.7395\n",
      "Epoch 054 | Val Acc: 0.7395\n",
      "Epoch 055 | Val Acc: 0.7000\n",
      "Epoch 056 | Val Acc: 0.7177\n",
      "Epoch 057 | Val Acc: 0.7411\n",
      "Epoch 058 | Val Acc: 0.7153\n",
      "Epoch 059 | Val Acc: 0.7258\n",
      "Epoch 060 | Val Acc: 0.7323\n",
      "Epoch 061 | Val Acc: 0.7347\n",
      "Epoch 062 | Val Acc: 0.7040\n",
      "Epoch 063 | Val Acc: 0.7153\n",
      "Epoch 064 | Val Acc: 0.7363\n",
      "Epoch 065 | Val Acc: 0.7452\n",
      "Epoch 066 | Val Acc: 0.7242\n",
      "Epoch 067 | Val Acc: 0.7371\n",
      "Epoch 068 | Val Acc: 0.7040\n",
      "Epoch 069 | Val Acc: 0.7266\n",
      "Epoch 070 | Val Acc: 0.7371\n",
      "Epoch 071 | Val Acc: 0.7403\n",
      "Epoch 072 | Val Acc: 0.7387\n",
      "Epoch 073 | Val Acc: 0.7492\n",
      "Epoch 074 | Val Acc: 0.7226\n",
      "Epoch 075 | Val Acc: 0.7323\n",
      "Epoch 076 | Val Acc: 0.7137\n",
      "Epoch 077 | Val Acc: 0.7250\n",
      "Epoch 078 | Val Acc: 0.7363\n",
      "Epoch 079 | Val Acc: 0.7395\n",
      "Epoch 080 | Val Acc: 0.7040\n",
      "Epoch 081 | Val Acc: 0.7097\n",
      "Epoch 082 | Val Acc: 0.7460\n",
      "Epoch 083 | Val Acc: 0.7266\n",
      "Early stopping\n",
      "Split 1 Accuracy: 0.7492\n",
      "\n",
      "===== SPLIT 2 =====\n",
      "Epoch 001 | Val Acc: 0.0258\n",
      "Epoch 002 | Val Acc: 0.0395\n",
      "Epoch 003 | Val Acc: 0.0492\n",
      "Epoch 004 | Val Acc: 0.0702\n",
      "Epoch 005 | Val Acc: 0.1097\n",
      "Epoch 006 | Val Acc: 0.1742\n",
      "Epoch 007 | Val Acc: 0.2508\n",
      "Epoch 008 | Val Acc: 0.3129\n",
      "Epoch 009 | Val Acc: 0.3637\n",
      "Epoch 010 | Val Acc: 0.5024\n",
      "Epoch 011 | Val Acc: 0.5306\n",
      "Epoch 012 | Val Acc: 0.6153\n",
      "Epoch 013 | Val Acc: 0.5919\n",
      "Epoch 014 | Val Acc: 0.6484\n",
      "Epoch 015 | Val Acc: 0.6984\n",
      "Epoch 016 | Val Acc: 0.6879\n",
      "Epoch 017 | Val Acc: 0.7194\n",
      "Epoch 018 | Val Acc: 0.7363\n",
      "Epoch 019 | Val Acc: 0.7185\n",
      "Epoch 020 | Val Acc: 0.7339\n",
      "Epoch 021 | Val Acc: 0.7508\n",
      "Epoch 022 | Val Acc: 0.7500\n",
      "Epoch 023 | Val Acc: 0.7532\n",
      "Epoch 024 | Val Acc: 0.7573\n",
      "Epoch 025 | Val Acc: 0.7565\n",
      "Epoch 026 | Val Acc: 0.7637\n",
      "Epoch 027 | Val Acc: 0.7669\n",
      "Epoch 028 | Val Acc: 0.7766\n",
      "Epoch 029 | Val Acc: 0.7629\n",
      "Epoch 030 | Val Acc: 0.7774\n",
      "Epoch 031 | Val Acc: 0.7790\n",
      "Epoch 032 | Val Acc: 0.7815\n",
      "Epoch 033 | Val Acc: 0.7589\n",
      "Epoch 034 | Val Acc: 0.7766\n",
      "Epoch 035 | Val Acc: 0.7694\n",
      "Epoch 036 | Val Acc: 0.7976\n",
      "Epoch 037 | Val Acc: 0.7968\n",
      "Epoch 038 | Val Acc: 0.7685\n",
      "Epoch 039 | Val Acc: 0.7774\n",
      "Epoch 040 | Val Acc: 0.7782\n",
      "Epoch 041 | Val Acc: 0.7839\n",
      "Epoch 042 | Val Acc: 0.7702\n",
      "Epoch 043 | Val Acc: 0.7944\n",
      "Epoch 044 | Val Acc: 0.8000\n",
      "Epoch 045 | Val Acc: 0.7790\n",
      "Epoch 046 | Val Acc: 0.7903\n",
      "Epoch 047 | Val Acc: 0.7847\n",
      "Epoch 048 | Val Acc: 0.7685\n",
      "Epoch 049 | Val Acc: 0.7839\n",
      "Epoch 050 | Val Acc: 0.7968\n",
      "Epoch 051 | Val Acc: 0.8089\n",
      "Epoch 052 | Val Acc: 0.8024\n",
      "Epoch 053 | Val Acc: 0.8040\n",
      "Epoch 054 | Val Acc: 0.7944\n",
      "Epoch 055 | Val Acc: 0.7911\n",
      "Epoch 056 | Val Acc: 0.7968\n",
      "Epoch 057 | Val Acc: 0.8024\n",
      "Epoch 058 | Val Acc: 0.8016\n",
      "Epoch 059 | Val Acc: 0.8097\n",
      "Epoch 060 | Val Acc: 0.8016\n",
      "Epoch 061 | Val Acc: 0.8008\n",
      "Epoch 062 | Val Acc: 0.8306\n",
      "Epoch 063 | Val Acc: 0.7669\n",
      "Epoch 064 | Val Acc: 0.7863\n",
      "Epoch 065 | Val Acc: 0.8032\n",
      "Epoch 066 | Val Acc: 0.8008\n",
      "Epoch 067 | Val Acc: 0.7879\n",
      "Epoch 068 | Val Acc: 0.7927\n",
      "Epoch 069 | Val Acc: 0.8073\n",
      "Epoch 070 | Val Acc: 0.7919\n",
      "Epoch 071 | Val Acc: 0.8040\n",
      "Epoch 072 | Val Acc: 0.8056\n",
      "Early stopping\n",
      "Split 2 Accuracy: 0.8306\n",
      "\n",
      "===== SPLIT 3 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0613\n",
      "Epoch 003 | Val Acc: 0.0976\n",
      "Epoch 004 | Val Acc: 0.1331\n",
      "Epoch 005 | Val Acc: 0.2315\n",
      "Epoch 006 | Val Acc: 0.3266\n",
      "Epoch 007 | Val Acc: 0.3605\n",
      "Epoch 008 | Val Acc: 0.4573\n",
      "Epoch 009 | Val Acc: 0.5218\n",
      "Epoch 010 | Val Acc: 0.5871\n",
      "Epoch 011 | Val Acc: 0.6008\n",
      "Epoch 012 | Val Acc: 0.6532\n",
      "Epoch 013 | Val Acc: 0.6790\n",
      "Epoch 014 | Val Acc: 0.6984\n",
      "Epoch 015 | Val Acc: 0.7081\n",
      "Epoch 016 | Val Acc: 0.7234\n",
      "Epoch 017 | Val Acc: 0.7355\n",
      "Epoch 018 | Val Acc: 0.7339\n",
      "Epoch 019 | Val Acc: 0.7605\n",
      "Epoch 020 | Val Acc: 0.7556\n",
      "Epoch 021 | Val Acc: 0.7702\n",
      "Epoch 022 | Val Acc: 0.7790\n",
      "Epoch 023 | Val Acc: 0.7685\n",
      "Epoch 024 | Val Acc: 0.7613\n",
      "Epoch 025 | Val Acc: 0.7774\n",
      "Epoch 026 | Val Acc: 0.7726\n",
      "Epoch 027 | Val Acc: 0.7960\n",
      "Epoch 028 | Val Acc: 0.7815\n",
      "Epoch 029 | Val Acc: 0.7661\n",
      "Epoch 030 | Val Acc: 0.7952\n",
      "Epoch 031 | Val Acc: 0.8121\n",
      "Epoch 032 | Val Acc: 0.7976\n",
      "Epoch 033 | Val Acc: 0.7669\n",
      "Epoch 034 | Val Acc: 0.7984\n",
      "Epoch 035 | Val Acc: 0.8056\n",
      "Epoch 036 | Val Acc: 0.7871\n",
      "Epoch 037 | Val Acc: 0.7984\n",
      "Epoch 038 | Val Acc: 0.8056\n",
      "Epoch 039 | Val Acc: 0.7944\n",
      "Epoch 040 | Val Acc: 0.8121\n",
      "Epoch 041 | Val Acc: 0.8137\n",
      "Epoch 042 | Val Acc: 0.8347\n",
      "Epoch 043 | Val Acc: 0.8177\n",
      "Epoch 044 | Val Acc: 0.8298\n",
      "Epoch 045 | Val Acc: 0.8113\n",
      "Epoch 046 | Val Acc: 0.8258\n",
      "Epoch 047 | Val Acc: 0.7903\n",
      "Epoch 048 | Val Acc: 0.8306\n",
      "Epoch 049 | Val Acc: 0.8129\n",
      "Epoch 050 | Val Acc: 0.8137\n",
      "Epoch 051 | Val Acc: 0.8258\n",
      "Epoch 052 | Val Acc: 0.8008\n",
      "Early stopping\n",
      "Split 3 Accuracy: 0.8347\n",
      "\n",
      "===== SPLIT 4 =====\n",
      "Epoch 001 | Val Acc: 0.0169\n",
      "Epoch 002 | Val Acc: 0.0573\n",
      "Epoch 003 | Val Acc: 0.0855\n",
      "Epoch 004 | Val Acc: 0.1016\n",
      "Epoch 005 | Val Acc: 0.1565\n",
      "Epoch 006 | Val Acc: 0.1274\n",
      "Epoch 007 | Val Acc: 0.2226\n",
      "Epoch 008 | Val Acc: 0.2815\n",
      "Epoch 009 | Val Acc: 0.3161\n",
      "Epoch 010 | Val Acc: 0.3839\n",
      "Epoch 011 | Val Acc: 0.4613\n",
      "Epoch 012 | Val Acc: 0.5121\n",
      "Epoch 013 | Val Acc: 0.5823\n",
      "Epoch 014 | Val Acc: 0.6000\n",
      "Epoch 015 | Val Acc: 0.6637\n",
      "Epoch 016 | Val Acc: 0.6556\n",
      "Epoch 017 | Val Acc: 0.6806\n",
      "Epoch 018 | Val Acc: 0.6984\n",
      "Epoch 019 | Val Acc: 0.7274\n",
      "Epoch 020 | Val Acc: 0.7121\n",
      "Epoch 021 | Val Acc: 0.7395\n",
      "Epoch 022 | Val Acc: 0.7419\n",
      "Epoch 023 | Val Acc: 0.7460\n",
      "Epoch 024 | Val Acc: 0.7637\n",
      "Epoch 025 | Val Acc: 0.7363\n",
      "Epoch 026 | Val Acc: 0.7935\n",
      "Epoch 027 | Val Acc: 0.7806\n",
      "Epoch 028 | Val Acc: 0.7952\n",
      "Epoch 029 | Val Acc: 0.7960\n",
      "Epoch 030 | Val Acc: 0.7718\n",
      "Epoch 031 | Val Acc: 0.7774\n",
      "Epoch 032 | Val Acc: 0.8024\n",
      "Epoch 033 | Val Acc: 0.8024\n",
      "Epoch 034 | Val Acc: 0.7815\n",
      "Epoch 035 | Val Acc: 0.8113\n",
      "Epoch 036 | Val Acc: 0.8129\n",
      "Epoch 037 | Val Acc: 0.8218\n",
      "Epoch 038 | Val Acc: 0.8250\n",
      "Epoch 039 | Val Acc: 0.7976\n",
      "Epoch 040 | Val Acc: 0.8274\n",
      "Epoch 041 | Val Acc: 0.8323\n",
      "Epoch 042 | Val Acc: 0.8177\n",
      "Epoch 043 | Val Acc: 0.8226\n",
      "Epoch 044 | Val Acc: 0.8250\n",
      "Epoch 045 | Val Acc: 0.8065\n",
      "Epoch 046 | Val Acc: 0.8250\n",
      "Epoch 047 | Val Acc: 0.8129\n",
      "Epoch 048 | Val Acc: 0.8387\n",
      "Epoch 049 | Val Acc: 0.8411\n",
      "Epoch 050 | Val Acc: 0.8266\n",
      "Epoch 051 | Val Acc: 0.8274\n",
      "Epoch 052 | Val Acc: 0.8258\n",
      "Epoch 053 | Val Acc: 0.8315\n",
      "Epoch 054 | Val Acc: 0.8387\n",
      "Epoch 055 | Val Acc: 0.8427\n",
      "Epoch 056 | Val Acc: 0.8371\n",
      "Epoch 057 | Val Acc: 0.8500\n",
      "Epoch 058 | Val Acc: 0.8468\n",
      "Epoch 059 | Val Acc: 0.8266\n",
      "Epoch 060 | Val Acc: 0.8242\n",
      "Epoch 061 | Val Acc: 0.8242\n",
      "Epoch 062 | Val Acc: 0.8452\n",
      "Epoch 063 | Val Acc: 0.8621\n",
      "Epoch 064 | Val Acc: 0.8597\n",
      "Epoch 065 | Val Acc: 0.8419\n",
      "Epoch 066 | Val Acc: 0.8452\n",
      "Epoch 067 | Val Acc: 0.8129\n",
      "Epoch 068 | Val Acc: 0.8323\n",
      "Epoch 069 | Val Acc: 0.8250\n",
      "Epoch 070 | Val Acc: 0.8274\n",
      "Epoch 071 | Val Acc: 0.8145\n",
      "Epoch 072 | Val Acc: 0.8306\n",
      "Epoch 073 | Val Acc: 0.8476\n",
      "Early stopping\n",
      "Split 4 Accuracy: 0.8621\n",
      "\n",
      "===== SPLIT 5 =====\n",
      "Epoch 001 | Val Acc: 0.0153\n",
      "Epoch 002 | Val Acc: 0.0379\n",
      "Epoch 003 | Val Acc: 0.0871\n",
      "Epoch 004 | Val Acc: 0.1218\n",
      "Epoch 005 | Val Acc: 0.1984\n",
      "Epoch 006 | Val Acc: 0.2798\n",
      "Epoch 007 | Val Acc: 0.3823\n",
      "Epoch 008 | Val Acc: 0.4532\n",
      "Epoch 009 | Val Acc: 0.4960\n",
      "Epoch 010 | Val Acc: 0.6202\n",
      "Epoch 011 | Val Acc: 0.6556\n",
      "Epoch 012 | Val Acc: 0.6718\n",
      "Epoch 013 | Val Acc: 0.7032\n",
      "Epoch 014 | Val Acc: 0.7048\n",
      "Epoch 015 | Val Acc: 0.7185\n",
      "Epoch 016 | Val Acc: 0.7363\n",
      "Epoch 017 | Val Acc: 0.7532\n",
      "Epoch 018 | Val Acc: 0.7653\n",
      "Epoch 019 | Val Acc: 0.7492\n",
      "Epoch 020 | Val Acc: 0.7565\n",
      "Epoch 021 | Val Acc: 0.7758\n",
      "Epoch 022 | Val Acc: 0.7685\n",
      "Epoch 023 | Val Acc: 0.7742\n",
      "Epoch 024 | Val Acc: 0.7887\n",
      "Epoch 025 | Val Acc: 0.7806\n",
      "Epoch 026 | Val Acc: 0.7960\n",
      "Epoch 027 | Val Acc: 0.7952\n",
      "Epoch 028 | Val Acc: 0.7952\n",
      "Epoch 029 | Val Acc: 0.8040\n",
      "Epoch 030 | Val Acc: 0.7911\n",
      "Epoch 031 | Val Acc: 0.8105\n",
      "Epoch 032 | Val Acc: 0.8073\n",
      "Epoch 033 | Val Acc: 0.7976\n",
      "Epoch 034 | Val Acc: 0.8185\n",
      "Epoch 035 | Val Acc: 0.8258\n",
      "Epoch 036 | Val Acc: 0.8105\n",
      "Epoch 037 | Val Acc: 0.8081\n",
      "Epoch 038 | Val Acc: 0.8194\n",
      "Epoch 039 | Val Acc: 0.8089\n",
      "Epoch 040 | Val Acc: 0.8258\n",
      "Epoch 041 | Val Acc: 0.8331\n",
      "Epoch 042 | Val Acc: 0.8298\n",
      "Epoch 043 | Val Acc: 0.8258\n",
      "Epoch 044 | Val Acc: 0.8137\n",
      "Epoch 045 | Val Acc: 0.8476\n",
      "Epoch 046 | Val Acc: 0.8290\n",
      "Epoch 047 | Val Acc: 0.8145\n",
      "Epoch 048 | Val Acc: 0.8363\n",
      "Epoch 049 | Val Acc: 0.8347\n",
      "Epoch 050 | Val Acc: 0.8226\n",
      "Epoch 051 | Val Acc: 0.8202\n",
      "Epoch 052 | Val Acc: 0.8258\n",
      "Epoch 053 | Val Acc: 0.8250\n",
      "Epoch 054 | Val Acc: 0.8089\n",
      "Epoch 055 | Val Acc: 0.8266\n",
      "Early stopping\n",
      "Split 5 Accuracy: 0.8476\n",
      "\n",
      "===== SPLIT 6 =====\n",
      "Epoch 001 | Val Acc: 0.0226\n",
      "Epoch 002 | Val Acc: 0.0379\n",
      "Epoch 003 | Val Acc: 0.0597\n",
      "Epoch 004 | Val Acc: 0.0871\n",
      "Epoch 005 | Val Acc: 0.0927\n",
      "Epoch 006 | Val Acc: 0.1653\n",
      "Epoch 007 | Val Acc: 0.2226\n",
      "Epoch 008 | Val Acc: 0.3161\n",
      "Epoch 009 | Val Acc: 0.4113\n",
      "Epoch 010 | Val Acc: 0.4452\n",
      "Epoch 011 | Val Acc: 0.5548\n",
      "Epoch 012 | Val Acc: 0.6040\n",
      "Epoch 013 | Val Acc: 0.6484\n",
      "Epoch 014 | Val Acc: 0.6677\n",
      "Epoch 015 | Val Acc: 0.6927\n",
      "Epoch 016 | Val Acc: 0.6669\n",
      "Epoch 017 | Val Acc: 0.7234\n",
      "Epoch 018 | Val Acc: 0.7290\n",
      "Epoch 019 | Val Acc: 0.7105\n",
      "Epoch 020 | Val Acc: 0.7411\n",
      "Epoch 021 | Val Acc: 0.7581\n",
      "Epoch 022 | Val Acc: 0.7548\n",
      "Epoch 023 | Val Acc: 0.7815\n",
      "Epoch 024 | Val Acc: 0.7815\n",
      "Epoch 025 | Val Acc: 0.7710\n",
      "Epoch 026 | Val Acc: 0.7847\n",
      "Epoch 027 | Val Acc: 0.7895\n",
      "Epoch 028 | Val Acc: 0.7919\n",
      "Epoch 029 | Val Acc: 0.7839\n",
      "Epoch 030 | Val Acc: 0.7968\n",
      "Epoch 031 | Val Acc: 0.7919\n",
      "Epoch 032 | Val Acc: 0.8008\n",
      "Epoch 033 | Val Acc: 0.8024\n",
      "Epoch 034 | Val Acc: 0.8065\n",
      "Epoch 035 | Val Acc: 0.7992\n",
      "Epoch 036 | Val Acc: 0.8274\n",
      "Epoch 037 | Val Acc: 0.8177\n",
      "Epoch 038 | Val Acc: 0.8056\n",
      "Epoch 039 | Val Acc: 0.7927\n",
      "Epoch 040 | Val Acc: 0.8282\n",
      "Epoch 041 | Val Acc: 0.8065\n",
      "Epoch 042 | Val Acc: 0.8153\n",
      "Epoch 043 | Val Acc: 0.8153\n",
      "Epoch 044 | Val Acc: 0.8266\n",
      "Epoch 045 | Val Acc: 0.8323\n",
      "Epoch 046 | Val Acc: 0.8266\n",
      "Epoch 047 | Val Acc: 0.8411\n",
      "Epoch 048 | Val Acc: 0.8315\n",
      "Epoch 049 | Val Acc: 0.8137\n",
      "Epoch 050 | Val Acc: 0.8089\n",
      "Epoch 051 | Val Acc: 0.8185\n",
      "Epoch 052 | Val Acc: 0.8121\n",
      "Epoch 053 | Val Acc: 0.8339\n",
      "Epoch 054 | Val Acc: 0.8218\n",
      "Epoch 055 | Val Acc: 0.8242\n",
      "Epoch 056 | Val Acc: 0.8234\n",
      "Epoch 057 | Val Acc: 0.8282\n",
      "Early stopping\n",
      "Split 6 Accuracy: 0.8411\n",
      "\n",
      "===== SPLIT 7 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0508\n",
      "Epoch 003 | Val Acc: 0.0855\n",
      "Epoch 004 | Val Acc: 0.1282\n",
      "Epoch 005 | Val Acc: 0.1984\n",
      "Epoch 006 | Val Acc: 0.2315\n",
      "Epoch 007 | Val Acc: 0.2895\n",
      "Epoch 008 | Val Acc: 0.3734\n",
      "Epoch 009 | Val Acc: 0.4000\n",
      "Epoch 010 | Val Acc: 0.5266\n",
      "Epoch 011 | Val Acc: 0.5573\n",
      "Epoch 012 | Val Acc: 0.6226\n",
      "Epoch 013 | Val Acc: 0.6282\n",
      "Epoch 014 | Val Acc: 0.6581\n",
      "Epoch 015 | Val Acc: 0.6984\n",
      "Epoch 016 | Val Acc: 0.6976\n",
      "Epoch 017 | Val Acc: 0.7234\n",
      "Epoch 018 | Val Acc: 0.7371\n",
      "Epoch 019 | Val Acc: 0.7323\n",
      "Epoch 020 | Val Acc: 0.7548\n",
      "Epoch 021 | Val Acc: 0.7403\n",
      "Epoch 022 | Val Acc: 0.7540\n",
      "Epoch 023 | Val Acc: 0.7387\n",
      "Epoch 024 | Val Acc: 0.7597\n",
      "Epoch 025 | Val Acc: 0.7629\n",
      "Epoch 026 | Val Acc: 0.7710\n",
      "Epoch 027 | Val Acc: 0.7685\n",
      "Epoch 028 | Val Acc: 0.7919\n",
      "Epoch 029 | Val Acc: 0.7685\n",
      "Epoch 030 | Val Acc: 0.7766\n",
      "Epoch 031 | Val Acc: 0.7782\n",
      "Epoch 032 | Val Acc: 0.8000\n",
      "Epoch 033 | Val Acc: 0.7871\n",
      "Epoch 034 | Val Acc: 0.7984\n",
      "Epoch 035 | Val Acc: 0.8065\n",
      "Epoch 036 | Val Acc: 0.8081\n",
      "Epoch 037 | Val Acc: 0.8065\n",
      "Epoch 038 | Val Acc: 0.8282\n",
      "Epoch 039 | Val Acc: 0.8274\n",
      "Epoch 040 | Val Acc: 0.8266\n",
      "Epoch 041 | Val Acc: 0.8290\n",
      "Epoch 042 | Val Acc: 0.8298\n",
      "Epoch 043 | Val Acc: 0.8274\n",
      "Epoch 044 | Val Acc: 0.8169\n",
      "Epoch 045 | Val Acc: 0.8073\n",
      "Epoch 046 | Val Acc: 0.8169\n",
      "Epoch 047 | Val Acc: 0.8056\n",
      "Epoch 048 | Val Acc: 0.8298\n",
      "Epoch 049 | Val Acc: 0.8129\n",
      "Epoch 050 | Val Acc: 0.8129\n",
      "Epoch 051 | Val Acc: 0.8242\n",
      "Epoch 052 | Val Acc: 0.8218\n",
      "Early stopping\n",
      "Split 7 Accuracy: 0.8298\n",
      "\n",
      "===== SPLIT 8 =====\n",
      "Epoch 001 | Val Acc: 0.0169\n",
      "Epoch 002 | Val Acc: 0.0468\n",
      "Epoch 003 | Val Acc: 0.0863\n",
      "Epoch 004 | Val Acc: 0.1540\n",
      "Epoch 005 | Val Acc: 0.1847\n",
      "Epoch 006 | Val Acc: 0.2573\n",
      "Epoch 007 | Val Acc: 0.3702\n",
      "Epoch 008 | Val Acc: 0.4395\n",
      "Epoch 009 | Val Acc: 0.5105\n",
      "Epoch 010 | Val Acc: 0.5661\n",
      "Epoch 011 | Val Acc: 0.6153\n",
      "Epoch 012 | Val Acc: 0.6435\n",
      "Epoch 013 | Val Acc: 0.6419\n",
      "Epoch 014 | Val Acc: 0.6524\n",
      "Epoch 015 | Val Acc: 0.6976\n",
      "Epoch 016 | Val Acc: 0.7032\n",
      "Epoch 017 | Val Acc: 0.7250\n",
      "Epoch 018 | Val Acc: 0.7347\n",
      "Epoch 019 | Val Acc: 0.7460\n",
      "Epoch 020 | Val Acc: 0.7500\n",
      "Epoch 021 | Val Acc: 0.7597\n",
      "Epoch 022 | Val Acc: 0.7685\n",
      "Epoch 023 | Val Acc: 0.7653\n",
      "Epoch 024 | Val Acc: 0.7508\n",
      "Epoch 025 | Val Acc: 0.7855\n",
      "Epoch 026 | Val Acc: 0.7839\n",
      "Epoch 027 | Val Acc: 0.7944\n",
      "Epoch 028 | Val Acc: 0.7879\n",
      "Epoch 029 | Val Acc: 0.7653\n",
      "Epoch 030 | Val Acc: 0.7677\n",
      "Epoch 031 | Val Acc: 0.7887\n",
      "Epoch 032 | Val Acc: 0.8024\n",
      "Epoch 033 | Val Acc: 0.8024\n",
      "Epoch 034 | Val Acc: 0.7935\n",
      "Epoch 035 | Val Acc: 0.7863\n",
      "Epoch 036 | Val Acc: 0.8040\n",
      "Epoch 037 | Val Acc: 0.7984\n",
      "Epoch 038 | Val Acc: 0.8024\n",
      "Epoch 039 | Val Acc: 0.8032\n",
      "Epoch 040 | Val Acc: 0.7984\n",
      "Epoch 041 | Val Acc: 0.7903\n",
      "Epoch 042 | Val Acc: 0.7879\n",
      "Epoch 043 | Val Acc: 0.8161\n",
      "Epoch 044 | Val Acc: 0.8153\n",
      "Epoch 045 | Val Acc: 0.8153\n",
      "Epoch 046 | Val Acc: 0.8153\n",
      "Epoch 047 | Val Acc: 0.8016\n",
      "Epoch 048 | Val Acc: 0.8226\n",
      "Epoch 049 | Val Acc: 0.8194\n",
      "Epoch 050 | Val Acc: 0.8137\n",
      "Epoch 051 | Val Acc: 0.8105\n",
      "Epoch 052 | Val Acc: 0.8081\n",
      "Epoch 053 | Val Acc: 0.8089\n",
      "Epoch 054 | Val Acc: 0.8105\n",
      "Epoch 055 | Val Acc: 0.8194\n",
      "Epoch 056 | Val Acc: 0.8145\n",
      "Epoch 057 | Val Acc: 0.8323\n",
      "Epoch 058 | Val Acc: 0.8306\n",
      "Epoch 059 | Val Acc: 0.8452\n",
      "Epoch 060 | Val Acc: 0.8468\n",
      "Epoch 061 | Val Acc: 0.8242\n",
      "Epoch 062 | Val Acc: 0.8194\n",
      "Epoch 063 | Val Acc: 0.8024\n",
      "Epoch 064 | Val Acc: 0.8153\n",
      "Epoch 065 | Val Acc: 0.8315\n",
      "Epoch 066 | Val Acc: 0.8347\n",
      "Epoch 067 | Val Acc: 0.8363\n",
      "Epoch 068 | Val Acc: 0.8121\n",
      "Epoch 069 | Val Acc: 0.8226\n",
      "Epoch 070 | Val Acc: 0.8290\n",
      "Early stopping\n",
      "Split 8 Accuracy: 0.8468\n",
      "\n",
      "===== SPLIT 9 =====\n",
      "Epoch 001 | Val Acc: 0.0161\n",
      "Epoch 002 | Val Acc: 0.0411\n",
      "Epoch 003 | Val Acc: 0.0556\n",
      "Epoch 004 | Val Acc: 0.0815\n",
      "Epoch 005 | Val Acc: 0.0871\n",
      "Epoch 006 | Val Acc: 0.1129\n",
      "Epoch 007 | Val Acc: 0.1895\n",
      "Epoch 008 | Val Acc: 0.2685\n",
      "Epoch 009 | Val Acc: 0.2718\n",
      "Epoch 010 | Val Acc: 0.3419\n",
      "Epoch 011 | Val Acc: 0.3685\n",
      "Epoch 012 | Val Acc: 0.3855\n",
      "Epoch 013 | Val Acc: 0.4202\n",
      "Epoch 014 | Val Acc: 0.5113\n",
      "Epoch 015 | Val Acc: 0.4895\n",
      "Epoch 016 | Val Acc: 0.5710\n",
      "Epoch 017 | Val Acc: 0.5903\n",
      "Epoch 018 | Val Acc: 0.6218\n",
      "Epoch 019 | Val Acc: 0.6177\n",
      "Epoch 020 | Val Acc: 0.6661\n",
      "Epoch 021 | Val Acc: 0.6782\n",
      "Epoch 022 | Val Acc: 0.6944\n",
      "Epoch 023 | Val Acc: 0.7024\n",
      "Epoch 024 | Val Acc: 0.7379\n",
      "Epoch 025 | Val Acc: 0.6798\n",
      "Epoch 026 | Val Acc: 0.7516\n",
      "Epoch 027 | Val Acc: 0.7315\n",
      "Epoch 028 | Val Acc: 0.7468\n",
      "Epoch 029 | Val Acc: 0.7589\n",
      "Epoch 030 | Val Acc: 0.7556\n",
      "Epoch 031 | Val Acc: 0.7573\n",
      "Epoch 032 | Val Acc: 0.7702\n",
      "Epoch 033 | Val Acc: 0.7919\n",
      "Epoch 034 | Val Acc: 0.7798\n",
      "Epoch 035 | Val Acc: 0.7831\n",
      "Epoch 036 | Val Acc: 0.7726\n",
      "Epoch 037 | Val Acc: 0.7661\n",
      "Epoch 038 | Val Acc: 0.7919\n",
      "Epoch 039 | Val Acc: 0.7952\n",
      "Epoch 040 | Val Acc: 0.7758\n",
      "Epoch 041 | Val Acc: 0.8081\n",
      "Epoch 042 | Val Acc: 0.7806\n",
      "Epoch 043 | Val Acc: 0.8081\n",
      "Epoch 044 | Val Acc: 0.7944\n",
      "Epoch 045 | Val Acc: 0.7782\n",
      "Epoch 046 | Val Acc: 0.7992\n",
      "Epoch 047 | Val Acc: 0.8105\n",
      "Epoch 048 | Val Acc: 0.8129\n",
      "Epoch 049 | Val Acc: 0.8073\n",
      "Epoch 050 | Val Acc: 0.8073\n",
      "Epoch 051 | Val Acc: 0.7935\n",
      "Epoch 052 | Val Acc: 0.7944\n",
      "Epoch 053 | Val Acc: 0.8145\n",
      "Epoch 054 | Val Acc: 0.8040\n",
      "Epoch 055 | Val Acc: 0.7887\n",
      "Epoch 056 | Val Acc: 0.8218\n",
      "Epoch 057 | Val Acc: 0.8153\n",
      "Epoch 058 | Val Acc: 0.8032\n",
      "Epoch 059 | Val Acc: 0.7984\n",
      "Epoch 060 | Val Acc: 0.8202\n",
      "Epoch 061 | Val Acc: 0.8048\n",
      "Epoch 062 | Val Acc: 0.8137\n",
      "Epoch 063 | Val Acc: 0.8129\n",
      "Epoch 064 | Val Acc: 0.8048\n",
      "Epoch 065 | Val Acc: 0.7992\n",
      "Epoch 066 | Val Acc: 0.8000\n",
      "Early stopping\n",
      "Split 9 Accuracy: 0.8218\n",
      "\n",
      "===== SPLIT 10 =====\n",
      "Epoch 001 | Val Acc: 0.0242\n",
      "Epoch 002 | Val Acc: 0.0516\n",
      "Epoch 003 | Val Acc: 0.0589\n",
      "Epoch 004 | Val Acc: 0.1105\n",
      "Epoch 005 | Val Acc: 0.1621\n",
      "Epoch 006 | Val Acc: 0.2185\n",
      "Epoch 007 | Val Acc: 0.3202\n",
      "Epoch 008 | Val Acc: 0.4468\n",
      "Epoch 009 | Val Acc: 0.4919\n",
      "Epoch 010 | Val Acc: 0.5306\n",
      "Epoch 011 | Val Acc: 0.6008\n",
      "Epoch 012 | Val Acc: 0.6056\n",
      "Epoch 013 | Val Acc: 0.6387\n",
      "Epoch 014 | Val Acc: 0.6702\n",
      "Epoch 015 | Val Acc: 0.6798\n",
      "Epoch 016 | Val Acc: 0.6887\n",
      "Epoch 017 | Val Acc: 0.6968\n",
      "Epoch 018 | Val Acc: 0.7048\n",
      "Epoch 019 | Val Acc: 0.7177\n",
      "Epoch 020 | Val Acc: 0.7218\n",
      "Epoch 021 | Val Acc: 0.7161\n",
      "Epoch 022 | Val Acc: 0.7266\n",
      "Epoch 023 | Val Acc: 0.7387\n",
      "Epoch 024 | Val Acc: 0.7194\n",
      "Epoch 025 | Val Acc: 0.7524\n",
      "Epoch 026 | Val Acc: 0.7476\n",
      "Epoch 027 | Val Acc: 0.7573\n",
      "Epoch 028 | Val Acc: 0.7202\n",
      "Epoch 029 | Val Acc: 0.7411\n",
      "Epoch 030 | Val Acc: 0.7581\n",
      "Epoch 031 | Val Acc: 0.7484\n",
      "Epoch 032 | Val Acc: 0.7702\n",
      "Epoch 033 | Val Acc: 0.7645\n",
      "Epoch 034 | Val Acc: 0.7613\n",
      "Epoch 035 | Val Acc: 0.7613\n",
      "Epoch 036 | Val Acc: 0.7476\n",
      "Epoch 037 | Val Acc: 0.7645\n",
      "Epoch 038 | Val Acc: 0.7774\n",
      "Epoch 039 | Val Acc: 0.7613\n",
      "Epoch 040 | Val Acc: 0.7758\n",
      "Epoch 041 | Val Acc: 0.7435\n",
      "Epoch 042 | Val Acc: 0.7863\n",
      "Epoch 043 | Val Acc: 0.7927\n",
      "Epoch 044 | Val Acc: 0.7532\n",
      "Epoch 045 | Val Acc: 0.7790\n",
      "Epoch 046 | Val Acc: 0.7831\n",
      "Epoch 047 | Val Acc: 0.7863\n",
      "Epoch 048 | Val Acc: 0.8016\n",
      "Epoch 049 | Val Acc: 0.7798\n",
      "Epoch 050 | Val Acc: 0.7831\n",
      "Epoch 051 | Val Acc: 0.7895\n",
      "Epoch 052 | Val Acc: 0.7758\n",
      "Epoch 053 | Val Acc: 0.7903\n",
      "Epoch 054 | Val Acc: 0.7839\n",
      "Epoch 055 | Val Acc: 0.7935\n",
      "Epoch 056 | Val Acc: 0.7774\n",
      "Epoch 057 | Val Acc: 0.7710\n",
      "Epoch 058 | Val Acc: 0.7766\n",
      "Early stopping\n",
      "Split 10 Accuracy: 0.8016\n",
      "\n",
      "FINAL AVERAGE ACCURACY: 0.826532258064516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from pytorch_metric_learning.losses import SupConLoss\n",
    "\n",
    "# ---------------- Setup ----------------\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path):\n",
    "        X = np.load(x_path)\n",
    "        y = np.argmax(np.load(y_path), axis=1)\n",
    "\n",
    "        # channel-wise normalization (MATCHES KERAS)\n",
    "        for i in range(X.shape[0]):\n",
    "            for c in range(6):\n",
    "                X[i, :, c] = (X[i, :, c] - X[i, :, c].mean()) / (X[i, :, c].std() + 1e-8)\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ---------------- CNN + BiLSTM ENCODER ----------------\n",
    "class CNN_BiLSTM_Encoder(nn.Module):\n",
    "    def __init__(self, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN (same as your Keras)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(6, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(64, 256, kernel_size=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # BiLSTM (same idea as Keras)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(256, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)        # (B, C, T)\n",
    "        x = self.cnn(x)               # (B, 256, T')\n",
    "        x = x.permute(0, 2, 1)        # (B, T', 256)\n",
    "\n",
    "        lstm_out, _ = self.bilstm(x)  # (B, T', 256)\n",
    "        feat = lstm_out[:, -1, :]     # last timestep\n",
    "\n",
    "        z = self.fc(feat)             # (B, emb_dim)\n",
    "        return z\n",
    "\n",
    "# ---------------- CLASSIFIER ----------------\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, emb_dim=256, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)\n",
    "\n",
    "# ---------------- FULL MODEL ----------------\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, emb_dim=256, num_classes=62):\n",
    "        super().__init__()\n",
    "        self.encoder = CNN_BiLSTM_Encoder(emb_dim)\n",
    "        self.classifier = Classifier(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        logits = self.classifier(z)\n",
    "        return z, logits\n",
    "\n",
    "# ---------------- EARLY STOPPING ----------------\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.best_acc = -1\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, acc, model):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience\n",
    "\n",
    "    def restore(self, model):\n",
    "        model.load_state_dict(self.best_state)\n",
    "\n",
    "# ---------------- TRAIN + EVAL ----------------\n",
    "def train_and_eval(model, train_loader, test_loader,\n",
    "                   supcon_loss, alpha=1.0,\n",
    "                   epochs=500, patience=10):\n",
    "\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "    stopper = EarlyStopping(patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            z, logits = model(x)\n",
    "            z = F.normalize(z, dim=1)  # REQUIRED FOR SUPCON\n",
    "\n",
    "            loss = ce_loss(logits, y) + alpha * supcon_loss(z, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # -------- Validation --------\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, logits = model(x)\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1:03d} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if stopper.step(acc, model):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    stopper.restore(model)\n",
    "    return stopper.best_acc\n",
    "\n",
    "# ---------------- MAIN LOOP ----------------\n",
    "BASE = \"models/Data/Data/62_classes/UserDependenet\"\n",
    "supcon_loss = SupConLoss(temperature=0.1)\n",
    "\n",
    "all_accs = []\n",
    "\n",
    "for split in range(1, 11):\n",
    "    print(f\"\\n===== SPLIT {split} =====\")\n",
    "\n",
    "    train_ds = EMGDataset(\n",
    "        f\"{BASE}/Train/X_train_{split}.npy\",\n",
    "        f\"{BASE}/Train/y_train_{split}.npy\"\n",
    "    )\n",
    "    test_ds = EMGDataset(\n",
    "        f\"{BASE}/Test/X_test_{split}.npy\",\n",
    "        f\"{BASE}/Test/y_test_{split}.npy\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=128)\n",
    "\n",
    "    model = FullModel(emb_dim=256, num_classes=62).to(device)\n",
    "\n",
    "    acc = train_and_eval(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        supcon_loss,\n",
    "        alpha=1.0,\n",
    "        epochs=500,\n",
    "        patience=10\n",
    "    )\n",
    "\n",
    "    print(f\"Split {split} Accuracy: {acc:.4f}\")\n",
    "    all_accs.append(acc)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\nFINAL AVERAGE ACCURACY:\", np.mean(all_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (winter_gpu)",
   "language": "python",
   "name": "winter_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
